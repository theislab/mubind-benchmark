{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilibarra/workspace/theislab/mubind-benchmark/notebooks/pipeline_bulk\n"
     ]
    }
   ],
   "source": [
    "cd ~/workspace/theislab/mubind-benchmark/notebooks/pipeline_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bindome as bd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to stop cleanly\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "def stop_if_path_exists(path):\n",
    "    if os.path.exists(path):\n",
    "        print(f'Path {path} exists. Stopping.')\n",
    "        raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "Skip to Analysis section if scraped data is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://motifcentral.org/fit/'\n",
    "DRIVER = webdriver.Firefox # TODO change to Chrome/Firefox/Safari based on local availability\n",
    "SCRAPE_RESULTS_DIR = '../../data/motifcentral' # /home/icb/ege.erdogan'\n",
    "bd.constants.ANNOTATIONS_DIRECTORY = '/home/ilibarra/annotations' # '/lustre/groups/ml01/datasets/annotations'\n",
    "MUBIND_RESULTS_DIR = '/home/icb/ege.erdogan/mubind-pipeline/OUTPUTS/23-01-09_151632/snakemake'\n",
    "\n",
    "data_keys = [\n",
    "    'Pearson\\'s r2 (k-mer)',\n",
    "    'Pearson\\'s r2 (affinity-binned)',\n",
    "    'Maximum predicted bin enrichment',\n",
    "    'Maximum observed bin enrichment',\n",
    "    'Partial Pearson\\'s r2',\n",
    "    'Predicted partial max bin enrichment',\n",
    "    'Observed partial max bin enrichment',\n",
    "    'R2',\n",
    "    'Enrichment',\n",
    "    'R2, partial',\n",
    "    'Enrichment, partial',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell fills `ids` to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/motifcentral/probound_ids.pkl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{SCRAPE_RESULTS_DIR}/probound_ids.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path ../../data/motifcentral/probound_ids.pkl exists. Stopping.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    browser = None\n",
    "    stop_if_path_exists(f'{SCRAPE_RESULTS_DIR}/probound_ids.pkl')\n",
    "    browser = DRIVER()\n",
    "    browser.get('https://motifcentral.org/home')\n",
    "\n",
    "    el = WebDriverWait(browser, timeout=10).until(\n",
    "        EC.text_to_be_present_in_element((By.TAG_NAME, 'body'), 'Complex')\n",
    "    )\n",
    "\n",
    "    num_pages = int(re.search('Number of Pages: [0-9]+', browser.page_source).group(0).split(' ')[-1])\n",
    "    print('num_pages', int(num_pages))\n",
    "    ids = []\n",
    "    for page in tqdm(range(num_pages)):\n",
    "        b1 = browser.find_elements(By.XPATH, '//span[@class = \"badge badge-pill badge-success\"]')\n",
    "        b2 = browser.find_elements(By.XPATH, '//span[@class = \"badge badge-pill badge-dark\"]')\n",
    "        b3 = browser.find_elements(By.XPATH, '//span[@class = \"badge badge-pill badge-light ng-star-inserted\"]')\n",
    "        b4 = browser.find_elements(By.XPATH, '//span[@class = \"badge badge-pill badge-primary\"]')\n",
    "        for a, b, c, d in zip(b1, b2, b3, b4):\n",
    "            val = (d.text, a.text, b.text, int(c.text[1:]))\n",
    "            print(val)\n",
    "            ids.append(val)\n",
    "        \n",
    "        # click next page\n",
    "        if page != num_pages - 1: # don't click next page on last page\n",
    "            button = browser.find_element(By.XPATH, '//button[@aria-label = \"Next page\"]')\n",
    "            button.click()\n",
    "        time.sleep(2)\n",
    "        if page == 3: \n",
    "            break\n",
    "            \n",
    "    browser.quit()\n",
    "    with open(f'{SCRAPE_RESULTS_DIR}/probound_ids.pkl', 'wb+') as f:\n",
    "        pickle.dump(ids, f)\n",
    "    print(f'Collected {len(ids)} ids')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    if browser is not None:\n",
    "        browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse useful values from HTML page for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path ../../data/motifcentral/probound_id_results.pkl exists. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "browser = None\n",
    "stop_if_path_exists(f'{SCRAPE_RESULTS_DIR}/probound_id_results.pkl')\n",
    "browser = DRIVER()\n",
    "\n",
    "id_results = dict() # (int, dict) dict\n",
    "try:\n",
    "    for x, y, id in tqdm(ids):\n",
    "        if id in id_results.keys():\n",
    "            continue\n",
    "\n",
    "            browser.get(base_url + str(id))\n",
    "\n",
    "            el = WebDriverWait(browser, timeout=20).until(\n",
    "                EC.text_to_be_present_in_element((By.ID, 'selexKMerPrediction'), 'Pearson')\n",
    "            )\n",
    "\n",
    "            rows = browser.find_elements(By.CLASS_NAME, \"row\")\n",
    "\n",
    "            # collect rows containing the lines from data_keys\n",
    "            result_rows = set()\n",
    "            for key in data_keys:\n",
    "                for r in rows:\n",
    "                    if key in r.text and '_' not in r.text: \n",
    "                        if key == 'Predicted partial max bin enrichment':\n",
    "                            # hacky fix because colon is missing from webpage\n",
    "                            idx = r.text.index('nt') + 2\n",
    "                            result_rows.add(r.text[:idx] + ':' + r.text[idx:])\n",
    "                        else:\n",
    "                            result_rows.add(r.text)\n",
    "\n",
    "            results = dict() # (str, str) dict\n",
    "            for row in result_rows:\n",
    "                k, v = row.split(':')\n",
    "                results[k] = v.strip()\n",
    "\n",
    "            id_results[id] = results\n",
    "            time.sleep(2)\n",
    "\n",
    "    with open(f'{SCRAPE_RESULTS_PATH}/probound_id_results.pkl', 'wb') as f:\n",
    "        pickle.dump(id_results, f)\n",
    "        print(f'Total collected: {len(id_results)}')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell loads the scraped data and defines some simple helper methods. No need to modify data-loading code unless scraping method changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 872 entries, 0 to 871\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   tf       872 non-null    object\n",
      " 1   study    872 non-null    object\n",
      " 2   library  872 non-null    object\n",
      " 3   id       872 non-null    int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 27.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 872 entries, 0 to 871\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     872 non-null    int64 \n",
      " 1   enrichment             872 non-null    object\n",
      " 2   enr_partial            872 non-null    object\n",
      " 3   max_obs_bin_enr        872 non-null    object\n",
      " 4   max_pred_bin_enr       872 non-null    object\n",
      " 5   obs_part_max_bin_enr   872 non-null    object\n",
      " 6   part_pearson_r2        872 non-null    object\n",
      " 7   pearson_r2_affinity    872 non-null    object\n",
      " 8   pearson_r2_kmer        872 non-null    object\n",
      " 9   pred_part_max_bin_enr  872 non-null    object\n",
      " 10  r2                     872 non-null    object\n",
      " 11  r2_partial             872 non-null    object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 81.9+ KB\n",
      "None\n",
      "simulated\n",
      "# filenames 40\n",
      "(40, 2)\n",
      "PRJEB3289\n",
      "# filenames 73\n",
      "(73, 2)\n",
      "cardiac_complexes\n",
      "# filenames 22\n",
      "(22, 2)\n",
      "PRJEB14744\n",
      "# filenames 13\n",
      "(13, 2)\n",
      "PRJEB20112\n",
      "# filenames 47\n",
      "(47, 2)\n",
      "PRJEB9797\n",
      "# filenames 222\n",
      "(222, 2)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{SCRAPE_RESULTS_DIR}/probound_ids.pkl', 'rb+') as f:\n",
    "    ids = pd.DataFrame(pickle.load(f), columns=['tf', 'study', 'library', 'id'])\n",
    "    print(ids.info())\n",
    "\n",
    "cols = [\n",
    "    'id', # the rest is sorted alphabetically\n",
    "    'enrichment',\n",
    "    'enr_partial',\n",
    "    'max_obs_bin_enr',\n",
    "    'max_pred_bin_enr',\n",
    "    'obs_part_max_bin_enr',\n",
    "    'part_pearson_r2',\n",
    "    'pearson_r2_affinity',\n",
    "    'pearson_r2_kmer',\n",
    "    'pred_part_max_bin_enr',\n",
    "    'r2',\n",
    "    'r2_partial'\n",
    "]\n",
    "    \n",
    "with open(f'{SCRAPE_RESULTS_DIR}/probound_id_results.pkl', 'rb+') as f:\n",
    "    id_results = pickle.load(f)\n",
    "    # since we know the first item contains all common keys\n",
    "    valid_keys = list(id_results.values())[0].keys()\n",
    "    \n",
    "    # remove keys not present in all values from id_results and sort remaining ones\n",
    "    for k1, v1 in id_results.items():\n",
    "        del_keys = [k2 for k2 in v1.keys() if k2 not in valid_keys]\n",
    "        for k in del_keys:\n",
    "            del v1[k]\n",
    "        id_results[k1] = sorted(v1.items())\n",
    "    \n",
    "    # we have a dict with ids as keys; convert it to list of lists with ids as the first elements for each item\n",
    "    as_tuple_list = [[k] + [x[1] for x in v] for k, v in id_results.items()]\n",
    "    pb_results = pd.DataFrame(as_tuple_list, columns=cols)\n",
    "    print(pb_results.info())\n",
    "    \n",
    "assert len(ids) == len(pb_results)\n",
    "\n",
    "bd_data = bd.bindome.datasets.SELEX.get_data()\n",
    "\n",
    "def tfs_in_study(study):\n",
    "    return ids[ids['study'].str.contains(study)]['tf']\n",
    "\n",
    "\n",
    "def id_results(id):\n",
    "    return pb_results[pb_results['id'] == int(id)]\n",
    "\n",
    "\n",
    "def mubind_tf_results(tf, dataset='SELEX', sep=','):\n",
    "    path = f'{MUBIND_RESULTS_DIR}/{tf}/{dataset}/fit_model/metrics.tsv'\n",
    "    return pd.read_csv(path, sep=sep)\n",
    "\n",
    "\n",
    "def pb_tf_results(tf):\n",
    "    tf_ids = ids[ids['tf'] == tf]['id']\n",
    "    return pb_results[pb_results['id'].isin(tf_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main Mubind snakemake pipeline is based on these gene_names\n",
    "gene_names = set(ids['tf'])\n",
    "len(gene_names)\n",
    "\n",
    "gene_names_path = '../../gene_names_all.txt'\n",
    "if not os.path.exists(gene_names_path):\n",
    "    writer = open(gene_names_path, 'w')\n",
    "    for g in gene_names:\n",
    "        writer.write(g + '\\n')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>enrichment</th>\n",
       "      <th>enr_partial</th>\n",
       "      <th>max_obs_bin_enr</th>\n",
       "      <th>max_pred_bin_enr</th>\n",
       "      <th>obs_part_max_bin_enr</th>\n",
       "      <th>part_pearson_r2</th>\n",
       "      <th>pearson_r2_affinity</th>\n",
       "      <th>pearson_r2_kmer</th>\n",
       "      <th>pred_part_max_bin_enr</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_partial</th>\n",
       "      <th>tf</th>\n",
       "      <th>study</th>\n",
       "      <th>library</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15412</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.26, 4.76, 5.78</td>\n",
       "      <td>20.57</td>\n",
       "      <td>16.60</td>\n",
       "      <td>21.40, 9.79, 16.05</td>\n",
       "      <td>0.99, 0.96, 0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.73</td>\n",
       "      <td>16.75, 11.00, 14.61</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.90, 0.92, -0.00</td>\n",
       "      <td>abd-A</td>\n",
       "      <td>Nitta2015</td>\n",
       "      <td>abd-A_KU_TCACTT40NTTG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11232</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.61, 2.27, 2.35</td>\n",
       "      <td>8.32</td>\n",
       "      <td>9.89</td>\n",
       "      <td>14.77, 5.76</td>\n",
       "      <td>0.97, 0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.79, 6.28</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97, 0.93</td>\n",
       "      <td>Abd-B</td>\n",
       "      <td>Slattery2011</td>\n",
       "      <td>AbdB.16mer2_rep1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16273</td>\n",
       "      <td>35.00</td>\n",
       "      <td>38.26, 46.63, 35.50, 3.25</td>\n",
       "      <td>11.69</td>\n",
       "      <td>12.80</td>\n",
       "      <td>81.47, 78.61, 68.65, 5.87</td>\n",
       "      <td>0.97, 0.99, 0.99, 0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>143.58, 121.44, 31.27, 4.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.79, 0.93, 0.98, 0.77</td>\n",
       "      <td>AC020909.1</td>\n",
       "      <td>Jolma2013</td>\n",
       "      <td>SPIB_ESAK_TGTCTA20NTCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16388</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.46, 3.72, 2.29</td>\n",
       "      <td>54.99</td>\n",
       "      <td>46.98</td>\n",
       "      <td>76.73, 47.90, 25.55</td>\n",
       "      <td>0.99, 0.99, 0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.75</td>\n",
       "      <td>94.89, 71.81, 8.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98, 0.98, 0.96</td>\n",
       "      <td>Aef1</td>\n",
       "      <td>Nitta2015</td>\n",
       "      <td>Aef1_KY_TCGAGT40NACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15421</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.82, 2.92, 2.71</td>\n",
       "      <td>13.74</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.85, 12.86, 10.28</td>\n",
       "      <td>0.97, 0.98, 0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>14.24, 7.68, 8.38</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98, 0.98, 0.98</td>\n",
       "      <td>al</td>\n",
       "      <td>Nitta2015</td>\n",
       "      <td>al_KY_TTTCAA40NTGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>18320</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00, 13.10, 38.92, 1.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.34</td>\n",
       "      <td>2.25, 119.67, 85.14, 34.09</td>\n",
       "      <td>0.61, 0.94, 0.99, 0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.26, 23.93, 61.26, 12.70</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.53, 0.64, 0.95, 0.98</td>\n",
       "      <td>ZSCAN16</td>\n",
       "      <td>Yin2017</td>\n",
       "      <td>ZSCAN16_eDBD_KR_TCCACC40N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>18619</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.00, 1.00, 9.66, 17.92</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2.74, 4.52, 13.90, 22.50</td>\n",
       "      <td>0.83, 0.91, 0.94, 0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.18, 3.36, 10.97, 19.12</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.01, 0.44, 0.86, 0.95</td>\n",
       "      <td>ZSCAN23</td>\n",
       "      <td>Yin2017</td>\n",
       "      <td>ZSCAN23_eDBD_KR_TACTAC40N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>17002</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1029.37, 18.72, 18.16, 6.81</td>\n",
       "      <td>13.54</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1827.18, 30.51, 29.71, 15.14</td>\n",
       "      <td>0.98, 0.99, 0.99, 0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>121.45, 28.68, 20.74, 13.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.25, 0.98, 0.89</td>\n",
       "      <td>ZSCAN4</td>\n",
       "      <td>Yin2017</td>\n",
       "      <td>ZSCAN4_eDBD_KP_TAGAGA40NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>17295</td>\n",
       "      <td>26.00</td>\n",
       "      <td>259.66, 26.60, 6.14, 2.33</td>\n",
       "      <td>20.19</td>\n",
       "      <td>20.25</td>\n",
       "      <td>378.93, 45.74, 19.96, 7.81</td>\n",
       "      <td>0.97, 0.99, 0.96, 0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.87</td>\n",
       "      <td>62.99, 106.59, 35.99, 7.34</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90, 0.98, 0.97, 0.94</td>\n",
       "      <td>ZSCAN5</td>\n",
       "      <td>Yin2017</td>\n",
       "      <td>ZSCAN5_eDBD_KR_TCGCCC40NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>17296</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00, 1.00, 4.13, 10.32</td>\n",
       "      <td>11.88</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.94, 6.77, 109.12, 93.11</td>\n",
       "      <td>0.72, 0.91, 0.99, 0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.32, 4.24, 62.18, 55.49</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.00, 0.39, 0.98, 0.97</td>\n",
       "      <td>ZSCAN9</td>\n",
       "      <td>Yin2017</td>\n",
       "      <td>ZSCAN9_eDBD_KR_TAAATT40NC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id enrichment                  enr_partial max_obs_bin_enr  \\\n",
       "0    15412       8.00             8.26, 4.76, 5.78           20.57   \n",
       "1    11232       2.00             2.61, 2.27, 2.35            8.32   \n",
       "2    16273      35.00    38.26, 46.63, 35.50, 3.25           11.69   \n",
       "3    16388      40.00            40.46, 3.72, 2.29           54.99   \n",
       "4    15421       2.00             2.82, 2.92, 2.71           13.74   \n",
       "..     ...        ...                          ...             ...   \n",
       "867  18320       9.00     1.00, 13.10, 38.92, 1.00           10.20   \n",
       "868  18619      17.00      1.00, 1.00, 9.66, 17.92            9.10   \n",
       "869  17002       9.00  1029.37, 18.72, 18.16, 6.81           13.54   \n",
       "870  17295      26.00    259.66, 26.60, 6.14, 2.33           20.19   \n",
       "871  17296      10.00      1.00, 1.00, 4.13, 10.32           11.88   \n",
       "\n",
       "    max_pred_bin_enr          obs_part_max_bin_enr         part_pearson_r2  \\\n",
       "0              16.60            21.40, 9.79, 16.05        0.99, 0.96, 0.98   \n",
       "1               9.89                   14.77, 5.76              0.97, 0.94   \n",
       "2              12.80     81.47, 78.61, 68.65, 5.87  0.97, 0.99, 0.99, 0.87   \n",
       "3              46.98           76.73, 47.90, 25.55        0.99, 0.99, 0.94   \n",
       "4              12.61           12.85, 12.86, 10.28        0.97, 0.98, 0.98   \n",
       "..               ...                           ...                     ...   \n",
       "867            10.34    2.25, 119.67, 85.14, 34.09  0.61, 0.94, 0.99, 0.88   \n",
       "868             8.21      2.74, 4.52, 13.90, 22.50  0.83, 0.91, 0.94, 0.95   \n",
       "869            14.70  1827.18, 30.51, 29.71, 15.14  0.98, 0.99, 0.99, 0.98   \n",
       "870            20.25    378.93, 45.74, 19.96, 7.81  0.97, 0.99, 0.96, 0.91   \n",
       "871            11.84     1.94, 6.77, 109.12, 93.11  0.72, 0.91, 0.99, 0.97   \n",
       "\n",
       "    pearson_r2_affinity pearson_r2_kmer        pred_part_max_bin_enr     r2  \\\n",
       "0                  0.99            0.73          16.75, 11.00, 14.61  -0.00   \n",
       "1                  0.99            0.50                  13.79, 6.28   0.97   \n",
       "2                  1.00            0.81  143.58, 121.44, 31.27, 4.95   0.98   \n",
       "3                  0.99            0.75           94.89, 71.81, 8.99   0.98   \n",
       "4                  0.99            0.60            14.24, 7.68, 8.38   0.98   \n",
       "..                  ...             ...                          ...    ...   \n",
       "867                1.00            0.89    2.26, 23.93, 61.26, 12.70   0.95   \n",
       "868                0.99            0.66     2.18, 3.36, 10.97, 19.12   0.96   \n",
       "869                1.00            0.88  121.45, 28.68, 20.74, 13.68   0.90   \n",
       "870                0.98            0.87   62.99, 106.59, 35.99, 7.34   0.99   \n",
       "871                1.00            0.88     2.32, 4.24, 62.18, 55.49   0.98   \n",
       "\n",
       "                  r2_partial          tf         study  \\\n",
       "0          0.90, 0.92, -0.00       abd-A     Nitta2015   \n",
       "1                 0.97, 0.93       Abd-B  Slattery2011   \n",
       "2     0.79, 0.93, 0.98, 0.77  AC020909.1     Jolma2013   \n",
       "3           0.98, 0.98, 0.96        Aef1     Nitta2015   \n",
       "4           0.98, 0.98, 0.98          al     Nitta2015   \n",
       "..                       ...         ...           ...   \n",
       "867   0.53, 0.64, 0.95, 0.98     ZSCAN16       Yin2017   \n",
       "868   0.01, 0.44, 0.86, 0.95     ZSCAN23       Yin2017   \n",
       "869         0.25, 0.98, 0.89      ZSCAN4       Yin2017   \n",
       "870   0.90, 0.98, 0.97, 0.94      ZSCAN5       Yin2017   \n",
       "871  -0.00, 0.39, 0.98, 0.97      ZSCAN9       Yin2017   \n",
       "\n",
       "                          library  \n",
       "0           abd-A_KU_TCACTT40NTTG  \n",
       "1                AbdB.16mer2_rep1  \n",
       "2          SPIB_ESAK_TGTCTA20NTCG  \n",
       "3            Aef1_KY_TCGAGT40NACT  \n",
       "4              al_KY_TTTCAA40NTGA  \n",
       "..                            ...  \n",
       "867  ZSCAN16_eDBD_KR_TCCACC40N...  \n",
       "868  ZSCAN23_eDBD_KR_TACTAC40N...  \n",
       "869  ZSCAN4_eDBD_KP_TAGAGA40NC...  \n",
       "870  ZSCAN5_eDBD_KR_TCGCCC40NC...  \n",
       "871  ZSCAN9_eDBD_KR_TAAATT40NC...  \n",
       "\n",
       "[872 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = pb_results.merge(ids, on ='id')\n",
    "pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total study counts in probound\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "study\n",
       "Yin2017                                                   309\n",
       "Nitta2015                                                 181\n",
       "Yang2017                                                  174\n",
       "Jolma2013                                                  76\n",
       "Rodriguez2017                                              41\n",
       "Isakova2017                                                28\n",
       "Jolma2013,Yang2017,Yin2017                                 25\n",
       "Slattery2011                                               12\n",
       "Jolma2013,Isakova2017,Yang2017,Yin2017                      7\n",
       "Jolma2013,Isakova2017,Yang2017                              4\n",
       "Kribelbauer2017                                             3\n",
       "Yang2017,Yin2017                                            2\n",
       "Jolma2013,Yang2017                                          2\n",
       "Jolma2013,Rodriguez2017,Yang2017,Yin2017                    2\n",
       "Rodriguez2017,Yin2017                                       2\n",
       "Jolma2013,Isakova2017                                       1\n",
       "Nitta2015,Slattery2011                                      1\n",
       "Jolma2013,Isakova2017,Kribelbauer2017,Yang2017,Yin2017      1\n",
       "Jolma2013,Yin2017                                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total study counts in probound')\n",
    "pb['study'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nitta2015',\n",
       " 'Slattery2011',\n",
       " 'Jolma2013',\n",
       " 'Yang2017',\n",
       " 'Yin2017',\n",
       " 'Rodriguez2017',\n",
       " 'Isakova2017',\n",
       " 'Kribelbauer2017']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to separate comma listed values\n",
    "studies = [x for x in pb['study'].unique() if ',' not in x]\n",
    "studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nitta2015        \t0        \t182\n",
      "Slattery2011        \t0        \t13\n",
      "Jolma2013        \t9        \t119\n",
      "Yang2017        \t13        \t217\n",
      "Yin2017        \t33        \t349\n",
      "Rodriguez2017        \t0        \t45\n",
      "Isakova2017        \t1        \t41\n",
      "Kribelbauer2017        \t0        \t4\n"
     ]
    }
   ],
   "source": [
    "for study in studies:\n",
    "    study_tfs = tfs_in_study(study).unique()\n",
    "    matches_in_bd = bd_data[bd_data['tf_name'].isin(study_tfs)]['tf_name'].unique()\n",
    "    print(study, len(matches_in_bd), len(study_tfs), sep='        \\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing R2's between Mubind and Probound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns two dataframes, one for mubind and one for probound,\n",
    "#     containing results for the same tf in both with matching libraries\n",
    "def get_tf_results(tf):\n",
    "    mb_results = mubind_tf_results(tf)\n",
    "    pb_results = pb_tf_results(tf)\n",
    "    pb_libs = ids[\n",
    "        ids['id'].isin(pb_results['id'].unique())\n",
    "    ]['library'].unique()\n",
    "    mb_libs = mb_results['library'].unique()\n",
    "    mb_lib_matches, pb_lib_matches = [], []\n",
    "    for mb_lib in mb_libs:\n",
    "        for pb_lib in pb_libs:\n",
    "            if mb_lib in pb_lib:\n",
    "                mb_lib_matches.append(mb_lib)\n",
    "                pb_lib_matches.append(pb_lib)\n",
    "            \n",
    "    mb_final = mb_results[\n",
    "        mb_results['library'].isin(mb_lib_matches)\n",
    "    ]\n",
    "    pb_final = pb_results[\n",
    "        pb_results['id'].isin(\n",
    "            ids[ids['library'].isin(pb_lib_matches)]['id'].unique()\n",
    "        )\n",
    "    ]\n",
    "    return mb_final, pb_final\n",
    "\n",
    "\n",
    "# takes a list of tf names, collects r2s from mubind and probound matching tfs+libraries\n",
    "#   if multiple libraries for same tf, computes mean of r2s\n",
    "def get_comparison(tfs):\n",
    "    results = pd.DataFrame()\n",
    "    for tf in tfs:\n",
    "        try:\n",
    "            mb_tf_res, pb_tf_res = get_tf_results(tf)\n",
    "            temp = pd.concat([\n",
    "                    mb_tf_res[['tf_name', 'library', 'r2_counts']].groupby(['tf_name', 'library']).mean().reset_index(), \n",
    "                    pb_tf_res['r2'].reset_index(drop=True).astype('float64')\n",
    "                ], \n",
    "                ignore_index=True,\n",
    "                axis=1\n",
    "            )\n",
    "            results = pd.concat([results, temp], axis=0)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    results = results.rename(columns={0: \"tf_name\", 1: \"library\", 2: \"mb_r2\", 3: \"pb_r2\"})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = bd_data['tf_name'].unique()\n",
    "results = get_comparison(tfs) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `tf_name` for `x`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# simple scatter plot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatterplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmb_r2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmubind\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(results, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_name\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpb_r2\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobound\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mubind_benchmark/lib/python3.9/site-packages/seaborn/relational.py:615\u001b[0m, in \u001b[0;36mscatterplot\u001b[0;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatterplot\u001b[39m(\n\u001b[1;32m    607\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    608\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    613\u001b[0m ):\n\u001b[0;32m--> 615\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_ScatterPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_hue(palette\u001b[38;5;241m=\u001b[39mpalette, order\u001b[38;5;241m=\u001b[39mhue_order, norm\u001b[38;5;241m=\u001b[39mhue_norm)\n\u001b[1;32m    622\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_size(sizes\u001b[38;5;241m=\u001b[39msizes, order\u001b[38;5;241m=\u001b[39msize_order, norm\u001b[38;5;241m=\u001b[39msize_norm)\n",
      "File \u001b[0;32m~/miniconda3/envs/mubind_benchmark/lib/python3.9/site-packages/seaborn/relational.py:396\u001b[0m, in \u001b[0;36m_ScatterPlotter.__init__\u001b[0;34m(self, data, variables, legend)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, variables\u001b[38;5;241m=\u001b[39m{}, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_size_range \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    393\u001b[0m         np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    394\u001b[0m     )\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend \u001b[38;5;241m=\u001b[39m legend\n",
      "File \u001b[0;32m~/miniconda3/envs/mubind_benchmark/lib/python3.9/site-packages/seaborn/_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/mubind_benchmark/lib/python3.9/site-packages/seaborn/_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m~/miniconda3/envs/mubind_benchmark/lib/python3.9/site-packages/seaborn/_core/data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     data: DataSource,\n\u001b[1;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[1;32m     55\u001b[0m ):\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[0;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[0;32m~/miniconda3/envs/mubind_benchmark/lib/python3.9/site-packages/seaborn/_core/data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `tf_name` for `x`. An entry with this name does not appear in `data`."
     ]
    }
   ],
   "source": [
    "# simple scatter plot\n",
    "sns.scatterplot(results, x='tf_name', y='mb_r2', label='mubind')\n",
    "sns.scatterplot(results, x='tf_name', y='pb_r2', label='probound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mubind_benchmark]",
   "language": "python",
   "name": "conda-env-mubind_benchmark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "598830fe471ad270c8799031f2ac384ffcd0e141210cbf2b0994cc2f8665407f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
