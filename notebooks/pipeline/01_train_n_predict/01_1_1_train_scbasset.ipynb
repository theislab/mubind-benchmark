{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List datasets that will be used for training with scBasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe anndata and others required\n",
    "# !pip install anndata h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here...\n"
     ]
    }
   ],
   "source": [
    "print('here...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 01:16:23.010656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:16:23.189764: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:16:23.194269: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:23.194288: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:16:24.237452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:24.237564: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:24.237574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import scbasset\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here...\n"
     ]
    }
   ],
   "source": [
    "print('here...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "d = '/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/theislab/mubind-pipeline/notebooks/pipeline/01_train_n_predict'\n",
    "os.chdir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets used in the core benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organoids': '/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad',\n",
       " 'gbm': '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad',\n",
       " 'noack_2022': '/mnt/f/workspace/theislab/mubind/data/noack_2022/*/merged_scATAC_integrated_cicero_faye_chong_obs*_var*.h5ad',\n",
       " 'pancreatic_endocrinogenesis': '/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/*/pancreas_multiome_2022_processed_atac_obs*_var*.h5ad',\n",
       " 'pbmc': '/mnt/f/workspace/theislab/mubind/data/pbmc/*/processed_laura_2023_obs*_var*.h5ad'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_by_dataset = utils.get_datasets()\n",
    "path_by_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scbasset/bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run python using the scbasset environment. If not found, please set up manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythonbin = '/home/ilibarra/.conda/envs/scbasset/bin/python' # ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = anndata.read_h5ad(ad_path)\n",
    "# print(adata.shape)\n",
    "# adata.var['chr'] = adata.var_names.str.split('-').str[0]\n",
    "# adata.var['chr'] = np.where(~adata.var['chr'].str.contains('chr'), 'chr', '') + adata.var['chr']\n",
    "# adata.var['start'] = adata.var_names.str.split('-').str[1]\n",
    "# adata.var['end'] = adata.var_names.str.split('-').str[2]\n",
    "# adata.write(ad_path, compression='lzf')\n",
    "# genome_fasta = '/mnt/c/Users/ignacio.ibarra/Dropbox/annotations/%s/genome/%s.fa' % (species, species)\n",
    "# os.path.exists(genome_fasta)\n",
    "# print(genome_fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/*/merged_scATAC_integrated_cicero_faye_chong_obs*_var*.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/*/pancreas_multiome_2022_processed_atac_obs*_var*.h5ad\n",
      "pbmc /mnt/f/workspace/theislab/mubind/data/pbmc/*/processed_laura_2023_obs*_var*.h5ad\n"
     ]
    }
   ],
   "source": [
    "for k in path_by_dataset:\n",
    "    print(k, path_by_dataset[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organoids\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids organoids_treutlein_dataset /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e1/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 01:16:27.876520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:16:28.097094: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:16:28.101570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:28.101640: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:16:29.009331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:29.009504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:29.009550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 01:16:31.781541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 01:16:31.781725: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.781830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.781901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.781970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.782045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.782116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.782185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.782252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:16:31.782283: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 01:16:31.782713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "29/29 [==============================] - 93s 3s/step - loss: 0.2079 - auc: 0.4467 - auc_1: 0.0024 - val_loss: 0.0192 - val_auc: 0.0961 - val_auc_1: 0.0025\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e1/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 01:18:07.558620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:18:07.729311: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:18:07.732720: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:07.732765: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:18:08.476065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:08.476306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:08.476358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 01:18:11.304692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 01:18:11.304968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305257: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305522: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:18:11.305811: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 01:18:11.306363: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "29/29 [==============================] - 78s 2s/step - loss: 0.3454 - auc: 0.4480 - auc_1: 0.0023 - val_loss: 0.0218 - val_auc: 0.0954 - val_auc_1: 0.0031\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids organoids_treutlein_dataset /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e10/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 01:19:34.987104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:19:35.126432: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:19:35.131213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:35.131256: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:19:35.832078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:35.832191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:35.832218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.4 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.5 s\n",
      "process 300 peaks takes 0.6 s\n",
      "process 350 peaks takes 0.7 s\n",
      "process 400 peaks takes 0.8 s\n",
      "process 450 peaks takes 0.8 s\n",
      "process 500 peaks takes 0.9 s\n",
      "process 550 peaks takes 1.0 s\n",
      "process 600 peaks takes 1.1 s\n",
      "process 650 peaks takes 1.2 s\n",
      "process 700 peaks takes 1.2 s\n",
      "process 750 peaks takes 1.3 s\n",
      "process 800 peaks takes 1.4 s\n",
      "process 850 peaks takes 1.5 s\n",
      "process 900 peaks takes 1.6 s\n",
      "process 950 peaks takes 1.7 s\n",
      "process 1000 peaks takes 1.8 s\n",
      "process 1050 peaks takes 1.9 s\n",
      "process 1100 peaks takes 1.9 s\n",
      "process 1150 peaks takes 2.0 s\n",
      "process 1200 peaks takes 2.1 s\n",
      "process 1250 peaks takes 2.2 s\n",
      "process 1300 peaks takes 2.3 s\n",
      "process 1350 peaks takes 2.4 s\n",
      "process 1400 peaks takes 2.5 s\n",
      "process 1450 peaks takes 2.6 s\n",
      "process 1500 peaks takes 2.6 s\n",
      "process 1550 peaks takes 2.7 s\n",
      "process 1600 peaks takes 2.8 s\n",
      "process 1650 peaks takes 2.9 s\n",
      "process 1700 peaks takes 2.9 s\n",
      "process 1750 peaks takes 3.0 s\n",
      "process 1800 peaks takes 3.1 s\n",
      "process 1850 peaks takes 3.2 s\n",
      "process 1900 peaks takes 3.3 s\n",
      "process 1950 peaks takes 3.4 s\n",
      "process 2000 peaks takes 3.5 s\n",
      "process 2050 peaks takes 3.6 s\n",
      "process 2100 peaks takes 3.6 s\n",
      "process 2150 peaks takes 3.7 s\n",
      "process 2200 peaks takes 3.8 s\n",
      "process 2250 peaks takes 3.9 s\n",
      "process 2300 peaks takes 4.0 s\n",
      "process 2350 peaks takes 4.0 s\n",
      "process 2400 peaks takes 4.1 s\n",
      "process 2450 peaks takes 4.2 s\n",
      "process 2500 peaks takes 4.2 s\n",
      "process 2550 peaks takes 4.3 s\n",
      "process 2600 peaks takes 4.4 s\n",
      "process 2650 peaks takes 4.4 s\n",
      "process 2700 peaks takes 4.5 s\n",
      "process 2750 peaks takes 4.6 s\n",
      "process 2800 peaks takes 4.6 s\n",
      "process 2850 peaks takes 4.7 s\n",
      "process 2900 peaks takes 4.8 s\n",
      "process 2950 peaks takes 4.8 s\n",
      "process 3000 peaks takes 4.9 s\n",
      "process 3050 peaks takes 5.0 s\n",
      "process 3100 peaks takes 5.1 s\n",
      "process 3150 peaks takes 5.1 s\n",
      "process 3200 peaks takes 5.2 s\n",
      "process 3250 peaks takes 5.3 s\n",
      "process 3300 peaks takes 5.3 s\n",
      "process 3350 peaks takes 5.4 s\n",
      "process 3400 peaks takes 5.5 s\n",
      "process 3450 peaks takes 5.5 s\n",
      "process 3500 peaks takes 5.6 s\n",
      "process 3550 peaks takes 5.7 s\n",
      "process 3600 peaks takes 5.7 s\n",
      "process 3650 peaks takes 5.8 s\n",
      "process 3700 peaks takes 5.8 s\n",
      "process 3750 peaks takes 5.9 s\n",
      "process 3800 peaks takes 6.0 s\n",
      "process 3850 peaks takes 6.1 s\n",
      "process 3900 peaks takes 6.1 s\n",
      "process 3950 peaks takes 6.2 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.2 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.3 s\n",
      "process 1000 peaks takes 1.4 s\n",
      "process 1050 peaks takes 1.5 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.6 s\n",
      "process 1200 peaks takes 1.7 s\n",
      "process 1250 peaks takes 1.7 s\n",
      "process 1300 peaks takes 1.8 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.9 s\n",
      "process 1450 peaks takes 2.0 s\n",
      "process 1500 peaks takes 2.0 s\n",
      "process 1550 peaks takes 2.1 s\n",
      "process 1600 peaks takes 2.2 s\n",
      "process 1650 peaks takes 2.2 s\n",
      "process 1700 peaks takes 2.3 s\n",
      "process 1750 peaks takes 2.3 s\n",
      "process 1800 peaks takes 2.4 s\n",
      "process 1850 peaks takes 2.5 s\n",
      "process 1900 peaks takes 2.5 s\n",
      "process 1950 peaks takes 2.6 s\n",
      "process 2000 peaks takes 2.6 s\n",
      "process 2050 peaks takes 2.7 s\n",
      "process 2100 peaks takes 2.7 s\n",
      "process 2150 peaks takes 2.8 s\n",
      "process 2200 peaks takes 2.9 s\n",
      "process 2250 peaks takes 2.9 s\n",
      "process 2300 peaks takes 3.0 s\n",
      "process 2350 peaks takes 3.1 s\n",
      "process 2400 peaks takes 3.1 s\n",
      "process 2450 peaks takes 3.2 s\n",
      "process 2500 peaks takes 3.3 s\n",
      "process 2550 peaks takes 3.3 s\n",
      "process 2600 peaks takes 3.4 s\n",
      "process 2650 peaks takes 3.4 s\n",
      "process 2700 peaks takes 3.5 s\n",
      "process 2750 peaks takes 3.6 s\n",
      "process 2800 peaks takes 3.6 s\n",
      "process 2850 peaks takes 3.7 s\n",
      "process 2900 peaks takes 3.7 s\n",
      "process 2950 peaks takes 3.8 s\n",
      "process 3000 peaks takes 3.9 s\n",
      "process 3050 peaks takes 3.9 s\n",
      "process 3100 peaks takes 4.0 s\n",
      "process 3150 peaks takes 4.1 s\n",
      "process 3200 peaks takes 4.2 s\n",
      "process 3250 peaks takes 4.2 s\n",
      "process 3300 peaks takes 4.3 s\n",
      "process 3350 peaks takes 4.4 s\n",
      "process 3400 peaks takes 4.4 s\n",
      "process 3450 peaks takes 4.5 s\n",
      "process 3500 peaks takes 4.6 s\n",
      "process 3550 peaks takes 4.7 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e10/poisson\n",
      "about to train...\n",
      "2024-05-13 01:19:50.072889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:19:50.220393: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:19:50.224155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:50.224196: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:19:50.903317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:50.903425: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:50.903461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 01:19:53.144089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 01:19:53.144251: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:19:53.144827: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 01:19:53.145361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 64s 2s/step - loss: 0.2104 - auc: 0.4432 - auc_1: 0.0020 - val_loss: 0.0194 - val_auc: 0.0953 - val_auc_1: 0.0038\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.0125 - auc: 0.4467 - auc_1: 0.0024 - val_loss: 0.0117 - val_auc: 0.0950 - val_auc_1: 0.0013\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0120 - auc: 0.4460 - auc_1: 0.0019 - val_loss: 0.0115 - val_auc: 0.0953 - val_auc_1: 0.0017\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0112 - auc: 0.4476 - auc_1: 0.0024 - val_loss: 0.0104 - val_auc: 0.0961 - val_auc_1: 0.0020\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0106 - auc: 0.4480 - auc_1: 0.0020 - val_loss: 0.0100 - val_auc: 0.0948 - val_auc_1: 0.0029\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0104 - auc: 0.4474 - auc_1: 0.0019 - val_loss: 0.0098 - val_auc: 0.0953 - val_auc_1: 0.0018\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.0102 - auc: 0.4470 - auc_1: 0.0021 - val_loss: 0.0098 - val_auc: 0.0947 - val_auc_1: 0.0025\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 61s 2s/step - loss: 0.0100 - auc: 0.4455 - auc_1: 0.0019 - val_loss: 0.0097 - val_auc: 0.0961 - val_auc_1: 0.0024\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 67s 2s/step - loss: 0.0099 - auc: 0.4492 - auc_1: 0.0025 - val_loss: 0.0097 - val_auc: 0.0954 - val_auc_1: 0.0016\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0099 - auc: 0.4471 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0948 - val_auc_1: 0.0021\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e10/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e10/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 01:30:32.978370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:30:33.198621: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:30:33.234855: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:33.234904: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:30:34.459853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:34.460242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:34.460270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.3 s\n",
      "process 1000 peaks takes 1.3 s\n",
      "process 1050 peaks takes 1.4 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.7 s\n",
      "process 1300 peaks takes 1.8 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.9 s\n",
      "process 1450 peaks takes 2.0 s\n",
      "process 1500 peaks takes 2.1 s\n",
      "process 1550 peaks takes 2.1 s\n",
      "process 1600 peaks takes 2.2 s\n",
      "process 1650 peaks takes 2.3 s\n",
      "process 1700 peaks takes 2.4 s\n",
      "process 1750 peaks takes 2.5 s\n",
      "process 1800 peaks takes 2.6 s\n",
      "process 1850 peaks takes 2.7 s\n",
      "process 1900 peaks takes 2.7 s\n",
      "process 1950 peaks takes 2.8 s\n",
      "process 2000 peaks takes 3.0 s\n",
      "process 2050 peaks takes 3.1 s\n",
      "process 2100 peaks takes 3.3 s\n",
      "process 2150 peaks takes 3.4 s\n",
      "process 2200 peaks takes 3.4 s\n",
      "process 2250 peaks takes 3.5 s\n",
      "process 2300 peaks takes 3.6 s\n",
      "process 2350 peaks takes 3.7 s\n",
      "process 2400 peaks takes 3.7 s\n",
      "process 2450 peaks takes 3.8 s\n",
      "process 2500 peaks takes 3.9 s\n",
      "process 2550 peaks takes 4.0 s\n",
      "process 2600 peaks takes 4.0 s\n",
      "process 2650 peaks takes 4.1 s\n",
      "process 2700 peaks takes 4.2 s\n",
      "process 2750 peaks takes 4.2 s\n",
      "process 2800 peaks takes 4.3 s\n",
      "process 2850 peaks takes 4.4 s\n",
      "process 2900 peaks takes 4.5 s\n",
      "process 2950 peaks takes 4.5 s\n",
      "process 3000 peaks takes 4.6 s\n",
      "process 3050 peaks takes 4.6 s\n",
      "process 3100 peaks takes 4.7 s\n",
      "process 3150 peaks takes 4.8 s\n",
      "process 3200 peaks takes 4.9 s\n",
      "process 3250 peaks takes 5.0 s\n",
      "process 3300 peaks takes 5.0 s\n",
      "process 3350 peaks takes 5.1 s\n",
      "process 3400 peaks takes 5.2 s\n",
      "process 3450 peaks takes 5.3 s\n",
      "process 3500 peaks takes 5.3 s\n",
      "process 3550 peaks takes 5.4 s\n",
      "process 3600 peaks takes 5.5 s\n",
      "process 3650 peaks takes 5.5 s\n",
      "process 3700 peaks takes 5.6 s\n",
      "process 3750 peaks takes 5.7 s\n",
      "process 3800 peaks takes 5.8 s\n",
      "process 3850 peaks takes 5.8 s\n",
      "process 3900 peaks takes 5.9 s\n",
      "process 3950 peaks takes 6.0 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.7 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.1 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.2 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.3 s\n",
      "process 1000 peaks takes 1.4 s\n",
      "process 1050 peaks takes 1.4 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.6 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.7 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.9 s\n",
      "process 1500 peaks takes 2.0 s\n",
      "process 1550 peaks takes 2.0 s\n",
      "process 1600 peaks takes 2.1 s\n",
      "process 1650 peaks takes 2.1 s\n",
      "process 1700 peaks takes 2.2 s\n",
      "process 1750 peaks takes 2.3 s\n",
      "process 1800 peaks takes 2.3 s\n",
      "process 1850 peaks takes 2.4 s\n",
      "process 1900 peaks takes 2.4 s\n",
      "process 1950 peaks takes 2.5 s\n",
      "process 2000 peaks takes 2.5 s\n",
      "process 2050 peaks takes 2.6 s\n",
      "process 2100 peaks takes 2.7 s\n",
      "process 2150 peaks takes 2.7 s\n",
      "process 2200 peaks takes 2.8 s\n",
      "process 2250 peaks takes 2.8 s\n",
      "process 2300 peaks takes 2.9 s\n",
      "process 2350 peaks takes 3.0 s\n",
      "process 2400 peaks takes 3.0 s\n",
      "process 2450 peaks takes 3.1 s\n",
      "process 2500 peaks takes 3.1 s\n",
      "process 2550 peaks takes 3.2 s\n",
      "process 2600 peaks takes 3.3 s\n",
      "process 2650 peaks takes 3.3 s\n",
      "process 2700 peaks takes 3.4 s\n",
      "process 2750 peaks takes 3.4 s\n",
      "process 2800 peaks takes 3.5 s\n",
      "process 2850 peaks takes 3.5 s\n",
      "process 2900 peaks takes 3.6 s\n",
      "process 2950 peaks takes 3.7 s\n",
      "process 3000 peaks takes 3.7 s\n",
      "process 3050 peaks takes 3.8 s\n",
      "process 3100 peaks takes 3.8 s\n",
      "process 3150 peaks takes 3.9 s\n",
      "process 3200 peaks takes 3.9 s\n",
      "process 3250 peaks takes 4.0 s\n",
      "process 3300 peaks takes 4.0 s\n",
      "process 3350 peaks takes 4.1 s\n",
      "process 3400 peaks takes 4.2 s\n",
      "process 3450 peaks takes 4.2 s\n",
      "process 3500 peaks takes 4.3 s\n",
      "process 3550 peaks takes 4.4 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e10/bce\n",
      "about to train...\n",
      "2024-05-13 01:30:49.348095: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:30:49.680370: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:30:49.707745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:49.707791: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:30:50.733966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:50.734115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:50.734136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 01:30:53.983774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 01:30:53.984139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.984306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.984392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.984777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.985215: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.985405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.985490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.985620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:30:53.985713: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 01:30:53.988876: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 79s 3s/step - loss: 0.3465 - auc: 0.4457 - auc_1: 0.0027 - val_loss: 0.0225 - val_auc: 0.0940 - val_auc_1: 0.0033\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0175 - auc: 0.4481 - auc_1: 0.0022 - val_loss: 0.0112 - val_auc: 0.0952 - val_auc_1: 0.0017\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 52s 2s/step - loss: 0.0116 - auc: 0.4444 - auc_1: 0.0017 - val_loss: 0.0114 - val_auc: 0.0948 - val_auc_1: 0.0013\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 52s 2s/step - loss: 0.0114 - auc: 0.4458 - auc_1: 0.0019 - val_loss: 0.0107 - val_auc: 0.0951 - val_auc_1: 0.0014\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 51s 2s/step - loss: 0.0108 - auc: 0.4461 - auc_1: 0.0018 - val_loss: 0.0101 - val_auc: 0.0963 - val_auc_1: 0.0017\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 52s 2s/step - loss: 0.0105 - auc: 0.4490 - auc_1: 0.0026 - val_loss: 0.0100 - val_auc: 0.0964 - val_auc_1: 0.0017\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 51s 2s/step - loss: 0.0104 - auc: 0.4478 - auc_1: 0.0021 - val_loss: 0.0099 - val_auc: 0.0970 - val_auc_1: 0.0019\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.0103 - auc: 0.4492 - auc_1: 0.0021 - val_loss: 0.0098 - val_auc: 0.0970 - val_auc_1: 0.0017\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.0102 - auc: 0.4502 - auc_1: 0.0020 - val_loss: 0.0098 - val_auc: 0.0982 - val_auc_1: 0.0020\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 50s 2s/step - loss: 0.0101 - auc: 0.4499 - auc_1: 0.0021 - val_loss: 0.0097 - val_auc: 0.0970 - val_auc_1: 0.0019\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e10/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids organoids_treutlein_dataset /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e20/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 01:41:03.936009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:41:04.131360: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:41:04.137085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:04.137136: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:41:04.777536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:04.777637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:04.777670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.3 s\n",
      "process 1050 peaks takes 1.4 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.5 s\n",
      "process 1250 peaks takes 1.6 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.7 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.8 s\n",
      "process 1500 peaks takes 1.9 s\n",
      "process 1550 peaks takes 2.0 s\n",
      "process 1600 peaks takes 2.0 s\n",
      "process 1650 peaks takes 2.1 s\n",
      "process 1700 peaks takes 2.1 s\n",
      "process 1750 peaks takes 2.3 s\n",
      "process 1800 peaks takes 2.4 s\n",
      "process 1850 peaks takes 2.5 s\n",
      "process 1900 peaks takes 2.5 s\n",
      "process 1950 peaks takes 2.6 s\n",
      "process 2000 peaks takes 2.6 s\n",
      "process 2050 peaks takes 2.7 s\n",
      "process 2100 peaks takes 2.8 s\n",
      "process 2150 peaks takes 2.8 s\n",
      "process 2200 peaks takes 2.9 s\n",
      "process 2250 peaks takes 2.9 s\n",
      "process 2300 peaks takes 3.0 s\n",
      "process 2350 peaks takes 3.0 s\n",
      "process 2400 peaks takes 3.1 s\n",
      "process 2450 peaks takes 3.1 s\n",
      "process 2500 peaks takes 3.2 s\n",
      "process 2550 peaks takes 3.2 s\n",
      "process 2600 peaks takes 3.3 s\n",
      "process 2650 peaks takes 3.4 s\n",
      "process 2700 peaks takes 3.5 s\n",
      "process 2750 peaks takes 3.5 s\n",
      "process 2800 peaks takes 3.6 s\n",
      "process 2850 peaks takes 3.7 s\n",
      "process 2900 peaks takes 3.7 s\n",
      "process 2950 peaks takes 3.8 s\n",
      "process 3000 peaks takes 3.9 s\n",
      "process 3050 peaks takes 3.9 s\n",
      "process 3100 peaks takes 4.0 s\n",
      "process 3150 peaks takes 4.1 s\n",
      "process 3200 peaks takes 4.1 s\n",
      "process 3250 peaks takes 4.2 s\n",
      "process 3300 peaks takes 4.2 s\n",
      "process 3350 peaks takes 4.3 s\n",
      "process 3400 peaks takes 4.4 s\n",
      "process 3450 peaks takes 4.4 s\n",
      "process 3500 peaks takes 4.6 s\n",
      "process 3550 peaks takes 4.6 s\n",
      "process 3600 peaks takes 4.7 s\n",
      "process 3650 peaks takes 4.7 s\n",
      "process 3700 peaks takes 4.8 s\n",
      "process 3750 peaks takes 4.9 s\n",
      "process 3800 peaks takes 4.9 s\n",
      "process 3850 peaks takes 5.0 s\n",
      "process 3900 peaks takes 5.0 s\n",
      "process 3950 peaks takes 5.1 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.7 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.3 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.6 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.9 s\n",
      "process 1500 peaks takes 1.9 s\n",
      "process 1550 peaks takes 2.0 s\n",
      "process 1600 peaks takes 2.1 s\n",
      "process 1650 peaks takes 2.1 s\n",
      "process 1700 peaks takes 2.2 s\n",
      "process 1750 peaks takes 2.2 s\n",
      "process 1800 peaks takes 2.3 s\n",
      "process 1850 peaks takes 2.3 s\n",
      "process 1900 peaks takes 2.4 s\n",
      "process 1950 peaks takes 2.4 s\n",
      "process 2000 peaks takes 2.5 s\n",
      "process 2050 peaks takes 2.6 s\n",
      "process 2100 peaks takes 2.7 s\n",
      "process 2150 peaks takes 2.7 s\n",
      "process 2200 peaks takes 2.8 s\n",
      "process 2250 peaks takes 2.9 s\n",
      "process 2300 peaks takes 2.9 s\n",
      "process 2350 peaks takes 3.0 s\n",
      "process 2400 peaks takes 3.0 s\n",
      "process 2450 peaks takes 3.1 s\n",
      "process 2500 peaks takes 3.1 s\n",
      "process 2550 peaks takes 3.2 s\n",
      "process 2600 peaks takes 3.2 s\n",
      "process 2650 peaks takes 3.3 s\n",
      "process 2700 peaks takes 3.3 s\n",
      "process 2750 peaks takes 3.4 s\n",
      "process 2800 peaks takes 3.5 s\n",
      "process 2850 peaks takes 3.6 s\n",
      "process 2900 peaks takes 3.6 s\n",
      "process 2950 peaks takes 3.7 s\n",
      "process 3000 peaks takes 3.7 s\n",
      "process 3050 peaks takes 3.8 s\n",
      "process 3100 peaks takes 3.9 s\n",
      "process 3150 peaks takes 3.9 s\n",
      "process 3200 peaks takes 4.0 s\n",
      "process 3250 peaks takes 4.0 s\n",
      "process 3300 peaks takes 4.0 s\n",
      "process 3350 peaks takes 4.1 s\n",
      "process 3400 peaks takes 4.1 s\n",
      "process 3450 peaks takes 4.2 s\n",
      "process 3500 peaks takes 4.2 s\n",
      "process 3550 peaks takes 4.3 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 20 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e20/poisson\n",
      "about to train...\n",
      "2024-05-13 01:41:17.462649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:41:17.591227: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:41:17.594596: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:17.594621: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:41:18.241186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:18.241288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:18.241297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 01:41:20.374488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 01:41:20.374653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.374758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.374814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.374847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.374909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.374965: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.375019: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.375076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:41:20.375099: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 01:41:20.375477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.2063 - auc: 0.4455 - auc_1: 0.0020 - val_loss: 0.0184 - val_auc: 0.0996 - val_auc_1: 0.0043\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.0125 - auc: 0.4466 - auc_1: 0.0021 - val_loss: 0.0116 - val_auc: 0.0950 - val_auc_1: 0.0013\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 51s 2s/step - loss: 0.0122 - auc: 0.4456 - auc_1: 0.0019 - val_loss: 0.0115 - val_auc: 0.0955 - val_auc_1: 0.0015\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 63s 2s/step - loss: 0.0117 - auc: 0.4471 - auc_1: 0.0021 - val_loss: 0.0107 - val_auc: 0.0965 - val_auc_1: 0.0016\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.0109 - auc: 0.4475 - auc_1: 0.0019 - val_loss: 0.0100 - val_auc: 0.0958 - val_auc_1: 0.0017\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 63s 2s/step - loss: 0.0105 - auc: 0.4493 - auc_1: 0.0022 - val_loss: 0.0098 - val_auc: 0.0948 - val_auc_1: 0.0015\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0102 - auc: 0.4514 - auc_1: 0.0022 - val_loss: 0.0097 - val_auc: 0.0946 - val_auc_1: 0.0017\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0100 - auc: 0.4504 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0953 - val_auc_1: 0.0019\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 50s 2s/step - loss: 0.0099 - auc: 0.4518 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0954 - val_auc_1: 0.0017\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0099 - auc: 0.4526 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0958 - val_auc_1: 0.0022\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0098 - auc: 0.4527 - auc_1: 0.0025 - val_loss: 0.0095 - val_auc: 0.0952 - val_auc_1: 0.0019\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 61s 2s/step - loss: 0.0098 - auc: 0.4540 - auc_1: 0.0027 - val_loss: 0.0095 - val_auc: 0.0961 - val_auc_1: 0.0021\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.0097 - auc: 0.4550 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0969 - val_auc_1: 0.0021\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 50s 2s/step - loss: 0.0097 - auc: 0.4548 - auc_1: 0.0026 - val_loss: 0.0095 - val_auc: 0.0962 - val_auc_1: 0.0022\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 48s 2s/step - loss: 0.0097 - auc: 0.4549 - auc_1: 0.0022 - val_loss: 0.0095 - val_auc: 0.0968 - val_auc_1: 0.0019\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0097 - auc: 0.4538 - auc_1: 0.0024 - val_loss: 0.0095 - val_auc: 0.0966 - val_auc_1: 0.0017\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0096 - auc: 0.4553 - auc_1: 0.0027 - val_loss: 0.0095 - val_auc: 0.0971 - val_auc_1: 0.0018\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0097 - auc: 0.4543 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0978 - val_auc_1: 0.0018\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 57s 2s/step - loss: 0.0096 - auc: 0.4565 - auc_1: 0.0029 - val_loss: 0.0095 - val_auc: 0.0971 - val_auc_1: 0.0020\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0096 - auc: 0.4580 - auc_1: 0.0031 - val_loss: 0.0095 - val_auc: 0.0974 - val_auc_1: 0.0019\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e20/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e20/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 01:59:20.622541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:59:20.718681: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:59:20.721668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:20.721700: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:59:21.205933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:21.206045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:21.206052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.3 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.4 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.7 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 0.9 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.0 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.1 s\n",
      "process 1300 peaks takes 1.1 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.2 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.3 s\n",
      "process 1550 peaks takes 1.4 s\n",
      "process 1600 peaks takes 1.4 s\n",
      "process 1650 peaks takes 1.4 s\n",
      "process 1700 peaks takes 1.5 s\n",
      "process 1750 peaks takes 1.5 s\n",
      "process 1800 peaks takes 1.6 s\n",
      "process 1850 peaks takes 1.6 s\n",
      "process 1900 peaks takes 1.7 s\n",
      "process 1950 peaks takes 1.7 s\n",
      "process 2000 peaks takes 1.8 s\n",
      "process 2050 peaks takes 1.8 s\n",
      "process 2100 peaks takes 1.8 s\n",
      "process 2150 peaks takes 1.9 s\n",
      "process 2200 peaks takes 1.9 s\n",
      "process 2250 peaks takes 2.0 s\n",
      "process 2300 peaks takes 2.0 s\n",
      "process 2350 peaks takes 2.0 s\n",
      "process 2400 peaks takes 2.1 s\n",
      "process 2450 peaks takes 2.1 s\n",
      "process 2500 peaks takes 2.2 s\n",
      "process 2550 peaks takes 2.2 s\n",
      "process 2600 peaks takes 2.2 s\n",
      "process 2650 peaks takes 2.3 s\n",
      "process 2700 peaks takes 2.3 s\n",
      "process 2750 peaks takes 2.4 s\n",
      "process 2800 peaks takes 2.4 s\n",
      "process 2850 peaks takes 2.4 s\n",
      "process 2900 peaks takes 2.5 s\n",
      "process 2950 peaks takes 2.5 s\n",
      "process 3000 peaks takes 2.6 s\n",
      "process 3050 peaks takes 2.6 s\n",
      "process 3100 peaks takes 2.7 s\n",
      "process 3150 peaks takes 2.7 s\n",
      "process 3200 peaks takes 2.7 s\n",
      "process 3250 peaks takes 2.8 s\n",
      "process 3300 peaks takes 2.8 s\n",
      "process 3350 peaks takes 2.9 s\n",
      "process 3400 peaks takes 2.9 s\n",
      "process 3450 peaks takes 3.0 s\n",
      "process 3500 peaks takes 3.0 s\n",
      "process 3550 peaks takes 3.0 s\n",
      "process 3600 peaks takes 3.1 s\n",
      "process 3650 peaks takes 3.1 s\n",
      "process 3700 peaks takes 3.1 s\n",
      "process 3750 peaks takes 3.2 s\n",
      "process 3800 peaks takes 3.2 s\n",
      "process 3850 peaks takes 3.3 s\n",
      "process 3900 peaks takes 3.3 s\n",
      "process 3950 peaks takes 3.4 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.3 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.4 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.6 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.7 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.8 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 0.9 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.0 s\n",
      "process 1200 peaks takes 1.0 s\n",
      "process 1250 peaks takes 1.1 s\n",
      "process 1300 peaks takes 1.1 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.2 s\n",
      "process 1450 peaks takes 1.2 s\n",
      "process 1500 peaks takes 1.3 s\n",
      "process 1550 peaks takes 1.3 s\n",
      "process 1600 peaks takes 1.4 s\n",
      "process 1650 peaks takes 1.4 s\n",
      "process 1700 peaks takes 1.5 s\n",
      "process 1750 peaks takes 1.5 s\n",
      "process 1800 peaks takes 1.5 s\n",
      "process 1850 peaks takes 1.6 s\n",
      "process 1900 peaks takes 1.6 s\n",
      "process 1950 peaks takes 1.7 s\n",
      "process 2000 peaks takes 1.7 s\n",
      "process 2050 peaks takes 1.7 s\n",
      "process 2100 peaks takes 1.8 s\n",
      "process 2150 peaks takes 1.8 s\n",
      "process 2200 peaks takes 1.9 s\n",
      "process 2250 peaks takes 1.9 s\n",
      "process 2300 peaks takes 1.9 s\n",
      "process 2350 peaks takes 2.0 s\n",
      "process 2400 peaks takes 2.0 s\n",
      "process 2450 peaks takes 2.1 s\n",
      "process 2500 peaks takes 2.1 s\n",
      "process 2550 peaks takes 2.1 s\n",
      "process 2600 peaks takes 2.2 s\n",
      "process 2650 peaks takes 2.2 s\n",
      "process 2700 peaks takes 2.3 s\n",
      "process 2750 peaks takes 2.3 s\n",
      "process 2800 peaks takes 2.3 s\n",
      "process 2850 peaks takes 2.4 s\n",
      "process 2900 peaks takes 2.4 s\n",
      "process 2950 peaks takes 2.5 s\n",
      "process 3000 peaks takes 2.5 s\n",
      "process 3050 peaks takes 2.6 s\n",
      "process 3100 peaks takes 2.6 s\n",
      "process 3150 peaks takes 2.7 s\n",
      "process 3200 peaks takes 2.7 s\n",
      "process 3250 peaks takes 2.7 s\n",
      "process 3300 peaks takes 2.8 s\n",
      "process 3350 peaks takes 2.8 s\n",
      "process 3400 peaks takes 2.9 s\n",
      "process 3450 peaks takes 2.9 s\n",
      "process 3500 peaks takes 3.0 s\n",
      "process 3550 peaks takes 3.0 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 20 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e20/bce\n",
      "about to train...\n",
      "2024-05-13 01:59:29.888292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 01:59:29.987764: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 01:59:29.990700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:29.990729: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 01:59:30.510569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:30.510637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:30.510643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 01:59:32.148201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 01:59:32.148309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148611: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148651: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 01:59:32.148698: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 01:59:32.149031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.3327 - auc: 0.4421 - auc_1: 0.0026 - val_loss: 0.0232 - val_auc: 0.0942 - val_auc_1: 0.0028\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0178 - auc: 0.4416 - auc_1: 0.0022 - val_loss: 0.0106 - val_auc: 0.0948 - val_auc_1: 0.0014\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0114 - auc: 0.4467 - auc_1: 0.0022 - val_loss: 0.0109 - val_auc: 0.0952 - val_auc_1: 0.0014\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0110 - auc: 0.4468 - auc_1: 0.0022 - val_loss: 0.0102 - val_auc: 0.0949 - val_auc_1: 0.0017\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0106 - auc: 0.4468 - auc_1: 0.0022 - val_loss: 0.0099 - val_auc: 0.0956 - val_auc_1: 0.0018\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0104 - auc: 0.4490 - auc_1: 0.0023 - val_loss: 0.0099 - val_auc: 0.0958 - val_auc_1: 0.0019\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0103 - auc: 0.4465 - auc_1: 0.0018 - val_loss: 0.0099 - val_auc: 0.0958 - val_auc_1: 0.0019\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0102 - auc: 0.4471 - auc_1: 0.0020 - val_loss: 0.0098 - val_auc: 0.0970 - val_auc_1: 0.0017\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0101 - auc: 0.4480 - auc_1: 0.0022 - val_loss: 0.0097 - val_auc: 0.0958 - val_auc_1: 0.0018\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0101 - auc: 0.4489 - auc_1: 0.0021 - val_loss: 0.0097 - val_auc: 0.0962 - val_auc_1: 0.0019\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0101 - auc: 0.4496 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0960 - val_auc_1: 0.0017\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0100 - auc: 0.4492 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0966 - val_auc_1: 0.0020\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0098 - auc: 0.4509 - auc_1: 0.0022 - val_loss: 0.0096 - val_auc: 0.0950 - val_auc_1: 0.0016\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0098 - auc: 0.4502 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0960 - val_auc_1: 0.0022\n",
      "Epoch 15/20\n",
      "2024-05-13 02:11:25.597375: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 1105 of 2000\n",
      "2024-05-13 02:11:25.781221: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "29/29 [==============================] - 55s 1s/step - loss: 0.0098 - auc: 0.4507 - auc_1: 0.0022 - val_loss: 0.0096 - val_auc: 0.0960 - val_auc_1: 0.0018\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0098 - auc: 0.4524 - auc_1: 0.0025 - val_loss: 0.0095 - val_auc: 0.0967 - val_auc_1: 0.0024\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0098 - auc: 0.4518 - auc_1: 0.0022 - val_loss: 0.0095 - val_auc: 0.0970 - val_auc_1: 0.0019\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0097 - auc: 0.4527 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0971 - val_auc_1: 0.0020\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 57s 2s/step - loss: 0.0098 - auc: 0.4547 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0981 - val_auc_1: 0.0019\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0097 - auc: 0.4538 - auc_1: 0.0028 - val_loss: 0.0096 - val_auc: 0.0961 - val_auc_1: 0.0021\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e20/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids organoids_treutlein_dataset /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 02:16:27.763453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 02:16:27.857769: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 02:16:27.860776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:27.860807: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 02:16:28.338366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:28.338448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:28.338468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.2 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.3 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.4 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.5 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.6 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.7 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 1.9 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.0 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.1 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.2 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.3 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.5 s\n",
      "process 2750 peaks takes 2.6 s\n",
      "process 2800 peaks takes 2.6 s\n",
      "process 2850 peaks takes 2.7 s\n",
      "process 2900 peaks takes 2.7 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.8 s\n",
      "process 3050 peaks takes 2.8 s\n",
      "process 3100 peaks takes 2.9 s\n",
      "process 3150 peaks takes 2.9 s\n",
      "process 3200 peaks takes 3.0 s\n",
      "process 3250 peaks takes 3.0 s\n",
      "process 3300 peaks takes 3.1 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.2 s\n",
      "process 3500 peaks takes 3.2 s\n",
      "process 3550 peaks takes 3.3 s\n",
      "process 3600 peaks takes 3.3 s\n",
      "process 3650 peaks takes 3.4 s\n",
      "process 3700 peaks takes 3.4 s\n",
      "process 3750 peaks takes 3.5 s\n",
      "process 3800 peaks takes 3.5 s\n",
      "process 3850 peaks takes 3.6 s\n",
      "process 3900 peaks takes 3.6 s\n",
      "process 3950 peaks takes 3.7 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.3 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.4 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.7 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.0 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.1 s\n",
      "process 1300 peaks takes 1.2 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.3 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.4 s\n",
      "process 1550 peaks takes 1.4 s\n",
      "process 1600 peaks takes 1.4 s\n",
      "process 1650 peaks takes 1.5 s\n",
      "process 1700 peaks takes 1.6 s\n",
      "process 1750 peaks takes 1.6 s\n",
      "process 1800 peaks takes 1.6 s\n",
      "process 1850 peaks takes 1.7 s\n",
      "process 1900 peaks takes 1.7 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.8 s\n",
      "process 2050 peaks takes 1.9 s\n",
      "process 2100 peaks takes 1.9 s\n",
      "process 2150 peaks takes 1.9 s\n",
      "process 2200 peaks takes 2.0 s\n",
      "process 2250 peaks takes 2.0 s\n",
      "process 2300 peaks takes 2.1 s\n",
      "process 2350 peaks takes 2.1 s\n",
      "process 2400 peaks takes 2.2 s\n",
      "process 2450 peaks takes 2.2 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.3 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.4 s\n",
      "process 2700 peaks takes 2.4 s\n",
      "process 2750 peaks takes 2.5 s\n",
      "process 2800 peaks takes 2.5 s\n",
      "process 2850 peaks takes 2.6 s\n",
      "process 2900 peaks takes 2.6 s\n",
      "process 2950 peaks takes 2.7 s\n",
      "process 3000 peaks takes 2.7 s\n",
      "process 3050 peaks takes 2.8 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.9 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 3.0 s\n",
      "process 3300 peaks takes 3.0 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.1 s\n",
      "process 3450 peaks takes 3.1 s\n",
      "process 3500 peaks takes 3.2 s\n",
      "process 3550 peaks takes 3.2 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/poisson\n",
      "about to train...\n",
      "2024-05-13 02:16:37.618859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 02:16:37.720048: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 02:16:37.722834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:37.722862: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 02:16:38.230175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:38.230271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:38.230279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 02:16:39.901306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 02:16:39.901411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901681: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:16:39.901738: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 02:16:39.902063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/50\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.2082 - auc: 0.4449 - auc_1: 0.0023 - val_loss: 0.0156 - val_auc: 0.0964 - val_auc_1: 0.0037\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0127 - auc: 0.4458 - auc_1: 0.0020 - val_loss: 0.0116 - val_auc: 0.0953 - val_auc_1: 0.0015\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0122 - auc: 0.4462 - auc_1: 0.0017 - val_loss: 0.0116 - val_auc: 0.0959 - val_auc_1: 0.0017\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0117 - auc: 0.4474 - auc_1: 0.0030 - val_loss: 0.0105 - val_auc: 0.0939 - val_auc_1: 0.0016\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0108 - auc: 0.4470 - auc_1: 0.0018 - val_loss: 0.0099 - val_auc: 0.0953 - val_auc_1: 0.0019\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0104 - auc: 0.4480 - auc_1: 0.0025 - val_loss: 0.0098 - val_auc: 0.0944 - val_auc_1: 0.0019\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0103 - auc: 0.4469 - auc_1: 0.0019 - val_loss: 0.0097 - val_auc: 0.0962 - val_auc_1: 0.0019\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0101 - auc: 0.4491 - auc_1: 0.0019 - val_loss: 0.0096 - val_auc: 0.0969 - val_auc_1: 0.0023\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0100 - auc: 0.4495 - auc_1: 0.0020 - val_loss: 0.0095 - val_auc: 0.0964 - val_auc_1: 0.0023\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0100 - auc: 0.4508 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0963 - val_auc_1: 0.0029\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0099 - auc: 0.4500 - auc_1: 0.0020 - val_loss: 0.0095 - val_auc: 0.0970 - val_auc_1: 0.0027\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0099 - auc: 0.4503 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0970 - val_auc_1: 0.0030\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0098 - auc: 0.4531 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0964 - val_auc_1: 0.0022\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0098 - auc: 0.4518 - auc_1: 0.0023 - val_loss: 0.0094 - val_auc: 0.0969 - val_auc_1: 0.0036\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0098 - auc: 0.4522 - auc_1: 0.0022 - val_loss: 0.0095 - val_auc: 0.0972 - val_auc_1: 0.0028\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0097 - auc: 0.4533 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0962 - val_auc_1: 0.0023\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0097 - auc: 0.4539 - auc_1: 0.0023 - val_loss: 0.0094 - val_auc: 0.0971 - val_auc_1: 0.0032\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0097 - auc: 0.4541 - auc_1: 0.0030 - val_loss: 0.0095 - val_auc: 0.0968 - val_auc_1: 0.0034\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0097 - auc: 0.4567 - auc_1: 0.0024 - val_loss: 0.0094 - val_auc: 0.0965 - val_auc_1: 0.0026\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0097 - auc: 0.4553 - auc_1: 0.0026 - val_loss: 0.0095 - val_auc: 0.0969 - val_auc_1: 0.0027\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0096 - auc: 0.4555 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0960 - val_auc_1: 0.0021\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0096 - auc: 0.4570 - auc_1: 0.0022 - val_loss: 0.0095 - val_auc: 0.0987 - val_auc_1: 0.0026\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0096 - auc: 0.4572 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0965 - val_auc_1: 0.0028\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0097 - auc: 0.4531 - auc_1: 0.0030 - val_loss: 0.0095 - val_auc: 0.0960 - val_auc_1: 0.0021\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4564 - auc_1: 0.0024 - val_loss: 0.0095 - val_auc: 0.0966 - val_auc_1: 0.0021\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4565 - auc_1: 0.0025 - val_loss: 0.0094 - val_auc: 0.0985 - val_auc_1: 0.0028\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0095 - auc: 0.4577 - auc_1: 0.0027 - val_loss: 0.0095 - val_auc: 0.0984 - val_auc_1: 0.0027\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0095 - auc: 0.4577 - auc_1: 0.0030 - val_loss: 0.0095 - val_auc: 0.0978 - val_auc_1: 0.0026\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0095 - auc: 0.4584 - auc_1: 0.0026 - val_loss: 0.0095 - val_auc: 0.0985 - val_auc_1: 0.0028\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0095 - auc: 0.4593 - auc_1: 0.0025 - val_loss: 0.0095 - val_auc: 0.1001 - val_auc_1: 0.0028\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0095 - auc: 0.4584 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0979 - val_auc_1: 0.0026\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0095 - auc: 0.4625 - auc_1: 0.0027 - val_loss: 0.0095 - val_auc: 0.0991 - val_auc_1: 0.0022\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4628 - auc_1: 0.0036 - val_loss: 0.0095 - val_auc: 0.0981 - val_auc_1: 0.0026\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4643 - auc_1: 0.0028 - val_loss: 0.0095 - val_auc: 0.0981 - val_auc_1: 0.0027\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0094 - auc: 0.4652 - auc_1: 0.0026 - val_loss: 0.0095 - val_auc: 0.0970 - val_auc_1: 0.0023\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0094 - auc: 0.4616 - auc_1: 0.0034 - val_loss: 0.0095 - val_auc: 0.0983 - val_auc_1: 0.0022\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0094 - auc: 0.4594 - auc_1: 0.0024 - val_loss: 0.0095 - val_auc: 0.0989 - val_auc_1: 0.0023\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0094 - auc: 0.4639 - auc_1: 0.0033 - val_loss: 0.0095 - val_auc: 0.0976 - val_auc_1: 0.0024\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0093 - auc: 0.4663 - auc_1: 0.0029 - val_loss: 0.0096 - val_auc: 0.0985 - val_auc_1: 0.0023\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0093 - auc: 0.4683 - auc_1: 0.0029 - val_loss: 0.0096 - val_auc: 0.0975 - val_auc_1: 0.0027\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0093 - auc: 0.4655 - auc_1: 0.0030 - val_loss: 0.0096 - val_auc: 0.0971 - val_auc_1: 0.0021\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0093 - auc: 0.4692 - auc_1: 0.0036 - val_loss: 0.0095 - val_auc: 0.0984 - val_auc_1: 0.0024\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0093 - auc: 0.4693 - auc_1: 0.0033 - val_loss: 0.0096 - val_auc: 0.0988 - val_auc_1: 0.0021\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0093 - auc: 0.4731 - auc_1: 0.0035 - val_loss: 0.0096 - val_auc: 0.0975 - val_auc_1: 0.0022\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0093 - auc: 0.4699 - auc_1: 0.0035 - val_loss: 0.0096 - val_auc: 0.0972 - val_auc_1: 0.0030\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0092 - auc: 0.4729 - auc_1: 0.0034 - val_loss: 0.0096 - val_auc: 0.0972 - val_auc_1: 0.0025\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0093 - auc: 0.4707 - auc_1: 0.0030 - val_loss: 0.0096 - val_auc: 0.0982 - val_auc_1: 0.0028\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0092 - auc: 0.4738 - auc_1: 0.0037 - val_loss: 0.0097 - val_auc: 0.0981 - val_auc_1: 0.0025\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0092 - auc: 0.4751 - auc_1: 0.0033 - val_loss: 0.0097 - val_auc: 0.0979 - val_auc_1: 0.0020\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0092 - auc: 0.4770 - auc_1: 0.0040 - val_loss: 0.0097 - val_auc: 0.0974 - val_auc_1: 0.0018\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 02:58:08.799121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 02:58:08.895885: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 02:58:08.898752: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:08.898782: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 02:58:09.379801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:09.379912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:09.379924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 0.9 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.0 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.1 s\n",
      "process 1300 peaks takes 1.1 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.2 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.3 s\n",
      "process 1550 peaks takes 1.3 s\n",
      "process 1600 peaks takes 1.4 s\n",
      "process 1650 peaks takes 1.4 s\n",
      "process 1700 peaks takes 1.4 s\n",
      "process 1750 peaks takes 1.5 s\n",
      "process 1800 peaks takes 1.5 s\n",
      "process 1850 peaks takes 1.6 s\n",
      "process 1900 peaks takes 1.6 s\n",
      "process 1950 peaks takes 1.6 s\n",
      "process 2000 peaks takes 1.7 s\n",
      "process 2050 peaks takes 1.7 s\n",
      "process 2100 peaks takes 1.8 s\n",
      "process 2150 peaks takes 1.8 s\n",
      "process 2200 peaks takes 1.8 s\n",
      "process 2250 peaks takes 1.9 s\n",
      "process 2300 peaks takes 1.9 s\n",
      "process 2350 peaks takes 2.0 s\n",
      "process 2400 peaks takes 2.0 s\n",
      "process 2450 peaks takes 2.0 s\n",
      "process 2500 peaks takes 2.1 s\n",
      "process 2550 peaks takes 2.1 s\n",
      "process 2600 peaks takes 2.1 s\n",
      "process 2650 peaks takes 2.2 s\n",
      "process 2700 peaks takes 2.2 s\n",
      "process 2750 peaks takes 2.3 s\n",
      "process 2800 peaks takes 2.3 s\n",
      "process 2850 peaks takes 2.3 s\n",
      "process 2900 peaks takes 2.4 s\n",
      "process 2950 peaks takes 2.4 s\n",
      "process 3000 peaks takes 2.4 s\n",
      "process 3050 peaks takes 2.5 s\n",
      "process 3100 peaks takes 2.5 s\n",
      "process 3150 peaks takes 2.6 s\n",
      "process 3200 peaks takes 2.6 s\n",
      "process 3250 peaks takes 2.7 s\n",
      "process 3300 peaks takes 2.7 s\n",
      "process 3350 peaks takes 2.7 s\n",
      "process 3400 peaks takes 2.8 s\n",
      "process 3450 peaks takes 2.8 s\n",
      "process 3500 peaks takes 2.9 s\n",
      "process 3550 peaks takes 2.9 s\n",
      "process 3600 peaks takes 2.9 s\n",
      "process 3650 peaks takes 3.0 s\n",
      "process 3700 peaks takes 3.0 s\n",
      "process 3750 peaks takes 3.1 s\n",
      "process 3800 peaks takes 3.1 s\n",
      "process 3850 peaks takes 3.1 s\n",
      "process 3900 peaks takes 3.2 s\n",
      "process 3950 peaks takes 3.2 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.4 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.7 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.2 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.3 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.4 s\n",
      "process 1550 peaks takes 1.4 s\n",
      "process 1600 peaks takes 1.5 s\n",
      "process 1650 peaks takes 1.5 s\n",
      "process 1700 peaks takes 1.5 s\n",
      "process 1750 peaks takes 1.6 s\n",
      "process 1800 peaks takes 1.6 s\n",
      "process 1850 peaks takes 1.7 s\n",
      "process 1900 peaks takes 1.7 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.8 s\n",
      "process 2050 peaks takes 1.9 s\n",
      "process 2100 peaks takes 1.9 s\n",
      "process 2150 peaks takes 1.9 s\n",
      "process 2200 peaks takes 2.0 s\n",
      "process 2250 peaks takes 2.0 s\n",
      "process 2300 peaks takes 2.1 s\n",
      "process 2350 peaks takes 2.1 s\n",
      "process 2400 peaks takes 2.2 s\n",
      "process 2450 peaks takes 2.2 s\n",
      "process 2500 peaks takes 2.2 s\n",
      "process 2550 peaks takes 2.3 s\n",
      "process 2600 peaks takes 2.3 s\n",
      "process 2650 peaks takes 2.4 s\n",
      "process 2700 peaks takes 2.4 s\n",
      "process 2750 peaks takes 2.4 s\n",
      "process 2800 peaks takes 2.5 s\n",
      "process 2850 peaks takes 2.5 s\n",
      "process 2900 peaks takes 2.6 s\n",
      "process 2950 peaks takes 2.6 s\n",
      "process 3000 peaks takes 2.7 s\n",
      "process 3050 peaks takes 2.7 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.8 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 2.9 s\n",
      "process 3300 peaks takes 2.9 s\n",
      "process 3350 peaks takes 3.0 s\n",
      "process 3400 peaks takes 3.0 s\n",
      "process 3450 peaks takes 3.1 s\n",
      "process 3500 peaks takes 3.1 s\n",
      "process 3550 peaks takes 3.2 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/bce\n",
      "about to train...\n",
      "2024-05-13 02:58:18.123216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 02:58:18.221524: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 02:58:18.224465: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:18.224495: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 02:58:18.707539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:18.707630: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:18.707641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 02:58:20.274875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 02:58:20.274987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 02:58:20.275320: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 02:58:20.275669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.3468 - auc: 0.4442 - auc_1: 0.0026 - val_loss: 0.0203 - val_auc: 0.0931 - val_auc_1: 0.0039\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0188 - auc: 0.4432 - auc_1: 0.0021 - val_loss: 0.0121 - val_auc: 0.0949 - val_auc_1: 0.0017\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0115 - auc: 0.4463 - auc_1: 0.0025 - val_loss: 0.0115 - val_auc: 0.0951 - val_auc_1: 0.0014\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0111 - auc: 0.4484 - auc_1: 0.0020 - val_loss: 0.0106 - val_auc: 0.0951 - val_auc_1: 0.0015\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0107 - auc: 0.4487 - auc_1: 0.0021 - val_loss: 0.0101 - val_auc: 0.0951 - val_auc_1: 0.0017\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0104 - auc: 0.4486 - auc_1: 0.0021 - val_loss: 0.0100 - val_auc: 0.0948 - val_auc_1: 0.0018\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0104 - auc: 0.4477 - auc_1: 0.0025 - val_loss: 0.0099 - val_auc: 0.0947 - val_auc_1: 0.0020\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0103 - auc: 0.4480 - auc_1: 0.0020 - val_loss: 0.0099 - val_auc: 0.0961 - val_auc_1: 0.0018\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0102 - auc: 0.4494 - auc_1: 0.0020 - val_loss: 0.0098 - val_auc: 0.0964 - val_auc_1: 0.0019\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0101 - auc: 0.4491 - auc_1: 0.0021 - val_loss: 0.0098 - val_auc: 0.0956 - val_auc_1: 0.0016\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0100 - auc: 0.4517 - auc_1: 0.0026 - val_loss: 0.0097 - val_auc: 0.0961 - val_auc_1: 0.0018\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0100 - auc: 0.4514 - auc_1: 0.0023 - val_loss: 0.0097 - val_auc: 0.0964 - val_auc_1: 0.0018\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0099 - auc: 0.4518 - auc_1: 0.0027 - val_loss: 0.0097 - val_auc: 0.0964 - val_auc_1: 0.0019\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0099 - auc: 0.4532 - auc_1: 0.0028 - val_loss: 0.0097 - val_auc: 0.0965 - val_auc_1: 0.0020\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0099 - auc: 0.4522 - auc_1: 0.0027 - val_loss: 0.0097 - val_auc: 0.0975 - val_auc_1: 0.0023\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0098 - auc: 0.4544 - auc_1: 0.0027 - val_loss: 0.0097 - val_auc: 0.0961 - val_auc_1: 0.0024\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0098 - auc: 0.4551 - auc_1: 0.0029 - val_loss: 0.0096 - val_auc: 0.0964 - val_auc_1: 0.0020\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0097 - auc: 0.4524 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0970 - val_auc_1: 0.0019\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0097 - auc: 0.4546 - auc_1: 0.0022 - val_loss: 0.0096 - val_auc: 0.0981 - val_auc_1: 0.0020\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0097 - auc: 0.4543 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0959 - val_auc_1: 0.0019\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0097 - auc: 0.4558 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0976 - val_auc_1: 0.0022\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 48s 2s/step - loss: 0.0097 - auc: 0.4552 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0973 - val_auc_1: 0.0021\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 77s 3s/step - loss: 0.0097 - auc: 0.4561 - auc_1: 0.0022 - val_loss: 0.0096 - val_auc: 0.0971 - val_auc_1: 0.0022\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 47s 2s/step - loss: 0.0096 - auc: 0.4559 - auc_1: 0.0022 - val_loss: 0.0096 - val_auc: 0.0973 - val_auc_1: 0.0021\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4555 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0978 - val_auc_1: 0.0021\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0096 - auc: 0.4587 - auc_1: 0.0033 - val_loss: 0.0096 - val_auc: 0.0973 - val_auc_1: 0.0024\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0096 - auc: 0.4584 - auc_1: 0.0031 - val_loss: 0.0096 - val_auc: 0.0979 - val_auc_1: 0.0024\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 51s 2s/step - loss: 0.0096 - auc: 0.4575 - auc_1: 0.0027 - val_loss: 0.0096 - val_auc: 0.0969 - val_auc_1: 0.0020\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0095 - auc: 0.4569 - auc_1: 0.0022 - val_loss: 0.0095 - val_auc: 0.0986 - val_auc_1: 0.0026\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4584 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0979 - val_auc_1: 0.0024\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0096 - auc: 0.4561 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0974 - val_auc_1: 0.0021\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0095 - auc: 0.4585 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0980 - val_auc_1: 0.0021\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0095 - auc: 0.4583 - auc_1: 0.0027 - val_loss: 0.0096 - val_auc: 0.0973 - val_auc_1: 0.0019\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0095 - auc: 0.4603 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0965 - val_auc_1: 0.0019\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0095 - auc: 0.4607 - auc_1: 0.0027 - val_loss: 0.0097 - val_auc: 0.0971 - val_auc_1: 0.0022\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0095 - auc: 0.4611 - auc_1: 0.0027 - val_loss: 0.0096 - val_auc: 0.0977 - val_auc_1: 0.0020\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0095 - auc: 0.4597 - auc_1: 0.0027 - val_loss: 0.0096 - val_auc: 0.0978 - val_auc_1: 0.0024\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0095 - auc: 0.4632 - auc_1: 0.0026 - val_loss: 0.0097 - val_auc: 0.0975 - val_auc_1: 0.0020\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0095 - auc: 0.4613 - auc_1: 0.0033 - val_loss: 0.0097 - val_auc: 0.0980 - val_auc_1: 0.0021\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 49s 2s/step - loss: 0.0094 - auc: 0.4626 - auc_1: 0.0029 - val_loss: 0.0097 - val_auc: 0.0979 - val_auc_1: 0.0021\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0094 - auc: 0.4621 - auc_1: 0.0030 - val_loss: 0.0096 - val_auc: 0.0984 - val_auc_1: 0.0022\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0094 - auc: 0.4603 - auc_1: 0.0029 - val_loss: 0.0097 - val_auc: 0.0980 - val_auc_1: 0.0019\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 57s 2s/step - loss: 0.0094 - auc: 0.4646 - auc_1: 0.0034 - val_loss: 0.0097 - val_auc: 0.0977 - val_auc_1: 0.0020\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0094 - auc: 0.4639 - auc_1: 0.0032 - val_loss: 0.0097 - val_auc: 0.0969 - val_auc_1: 0.0020\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0094 - auc: 0.4661 - auc_1: 0.0036 - val_loss: 0.0097 - val_auc: 0.0987 - val_auc_1: 0.0023\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4661 - auc_1: 0.0031 - val_loss: 0.0097 - val_auc: 0.0985 - val_auc_1: 0.0020\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0093 - auc: 0.4687 - auc_1: 0.0031 - val_loss: 0.0097 - val_auc: 0.0990 - val_auc_1: 0.0022\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0094 - auc: 0.4677 - auc_1: 0.0034 - val_loss: 0.0097 - val_auc: 0.0976 - val_auc_1: 0.0019\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0093 - auc: 0.4672 - auc_1: 0.0030 - val_loss: 0.0097 - val_auc: 0.0983 - val_auc_1: 0.0021\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0093 - auc: 0.4705 - auc_1: 0.0031 - val_loss: 0.0097 - val_auc: 0.0984 - val_auc_1: 0.0022\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "organoids organoids_treutlein_dataset /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e100/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 03:39:29.930142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 03:39:30.024376: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 03:39:30.027200: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:30.027229: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 03:39:30.568991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:30.569106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:30.569114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.4 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.5 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.6 s\n",
      "process 1750 peaks takes 1.6 s\n",
      "process 1800 peaks takes 1.7 s\n",
      "process 1850 peaks takes 1.7 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 1.9 s\n",
      "process 2100 peaks takes 1.9 s\n",
      "process 2150 peaks takes 2.0 s\n",
      "process 2200 peaks takes 2.0 s\n",
      "process 2250 peaks takes 2.1 s\n",
      "process 2300 peaks takes 2.1 s\n",
      "process 2350 peaks takes 2.1 s\n",
      "process 2400 peaks takes 2.2 s\n",
      "process 2450 peaks takes 2.2 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.3 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.4 s\n",
      "process 2700 peaks takes 2.4 s\n",
      "process 2750 peaks takes 2.5 s\n",
      "process 2800 peaks takes 2.5 s\n",
      "process 2850 peaks takes 2.6 s\n",
      "process 2900 peaks takes 2.6 s\n",
      "process 2950 peaks takes 2.7 s\n",
      "process 3000 peaks takes 2.7 s\n",
      "process 3050 peaks takes 2.7 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.8 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 2.9 s\n",
      "process 3300 peaks takes 2.9 s\n",
      "process 3350 peaks takes 3.0 s\n",
      "process 3400 peaks takes 3.0 s\n",
      "process 3450 peaks takes 3.1 s\n",
      "process 3500 peaks takes 3.1 s\n",
      "process 3550 peaks takes 3.2 s\n",
      "process 3600 peaks takes 3.2 s\n",
      "process 3650 peaks takes 3.3 s\n",
      "process 3700 peaks takes 3.3 s\n",
      "process 3750 peaks takes 3.4 s\n",
      "process 3800 peaks takes 3.4 s\n",
      "process 3850 peaks takes 3.5 s\n",
      "process 3900 peaks takes 3.5 s\n",
      "process 3950 peaks takes 3.5 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.6 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.7 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.8 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 2.9 s\n",
      "process 3150 peaks takes 3.0 s\n",
      "process 3200 peaks takes 3.0 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.1 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.2 s\n",
      "process 3500 peaks takes 3.3 s\n",
      "process 3550 peaks takes 3.3 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 100 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e100/poisson\n",
      "about to train...\n",
      "2024-05-13 03:39:39.837848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 03:39:39.925442: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 03:39:39.928343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:39.928371: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 03:39:40.402280: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:40.402393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:40.402413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 03:39:41.946138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 03:39:41.946260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946321: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946476: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 03:39:41.946625: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 03:39:41.946989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.2034 - auc: 0.4457 - auc_1: 0.0020 - val_loss: 0.0167 - val_auc: 0.0946 - val_auc_1: 0.0031\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0124 - auc: 0.4458 - auc_1: 0.0020 - val_loss: 0.0118 - val_auc: 0.0950 - val_auc_1: 0.0013\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0122 - auc: 0.4457 - auc_1: 0.0018 - val_loss: 0.0116 - val_auc: 0.0945 - val_auc_1: 0.0014\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0114 - auc: 0.4468 - auc_1: 0.0018 - val_loss: 0.0103 - val_auc: 0.0975 - val_auc_1: 0.0022\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0106 - auc: 0.4489 - auc_1: 0.0021 - val_loss: 0.0100 - val_auc: 0.0964 - val_auc_1: 0.0025\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0104 - auc: 0.4461 - auc_1: 0.0018 - val_loss: 0.0098 - val_auc: 0.0960 - val_auc_1: 0.0026\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0102 - auc: 0.4481 - auc_1: 0.0020 - val_loss: 0.0097 - val_auc: 0.0949 - val_auc_1: 0.0018\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0101 - auc: 0.4480 - auc_1: 0.0020 - val_loss: 0.0097 - val_auc: 0.0966 - val_auc_1: 0.0022\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0100 - auc: 0.4488 - auc_1: 0.0021 - val_loss: 0.0097 - val_auc: 0.0960 - val_auc_1: 0.0017\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0099 - auc: 0.4500 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0956 - val_auc_1: 0.0021\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0099 - auc: 0.4497 - auc_1: 0.0020 - val_loss: 0.0097 - val_auc: 0.0966 - val_auc_1: 0.0023\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0099 - auc: 0.4501 - auc_1: 0.0021 - val_loss: 0.0097 - val_auc: 0.0975 - val_auc_1: 0.0022\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0098 - auc: 0.4527 - auc_1: 0.0025 - val_loss: 0.0095 - val_auc: 0.0966 - val_auc_1: 0.0019\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0098 - auc: 0.4507 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0979 - val_auc_1: 0.0020\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0098 - auc: 0.4527 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0960 - val_auc_1: 0.0027\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0097 - auc: 0.4518 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0971 - val_auc_1: 0.0021\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0097 - auc: 0.4559 - auc_1: 0.0028 - val_loss: 0.0095 - val_auc: 0.0978 - val_auc_1: 0.0023\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0097 - auc: 0.4505 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0966 - val_auc_1: 0.0019\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4544 - auc_1: 0.0022 - val_loss: 0.0095 - val_auc: 0.0959 - val_auc_1: 0.0026\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4542 - auc_1: 0.0021 - val_loss: 0.0095 - val_auc: 0.0971 - val_auc_1: 0.0019\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0096 - auc: 0.4548 - auc_1: 0.0029 - val_loss: 0.0095 - val_auc: 0.0959 - val_auc_1: 0.0019\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4538 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0975 - val_auc_1: 0.0018\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0096 - auc: 0.4570 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0976 - val_auc_1: 0.0021\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0096 - auc: 0.4535 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0970 - val_auc_1: 0.0028\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0095 - auc: 0.4555 - auc_1: 0.0025 - val_loss: 0.0095 - val_auc: 0.0966 - val_auc_1: 0.0026\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0095 - auc: 0.4573 - auc_1: 0.0031 - val_loss: 0.0096 - val_auc: 0.0960 - val_auc_1: 0.0024\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 63s 2s/step - loss: 0.0095 - auc: 0.4578 - auc_1: 0.0033 - val_loss: 0.0096 - val_auc: 0.0974 - val_auc_1: 0.0027\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0095 - auc: 0.4599 - auc_1: 0.0031 - val_loss: 0.0096 - val_auc: 0.0967 - val_auc_1: 0.0023\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0095 - auc: 0.4597 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0958 - val_auc_1: 0.0024\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0095 - auc: 0.4591 - auc_1: 0.0028 - val_loss: 0.0096 - val_auc: 0.0978 - val_auc_1: 0.0024\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0094 - auc: 0.4597 - auc_1: 0.0032 - val_loss: 0.0096 - val_auc: 0.0976 - val_auc_1: 0.0027\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0094 - auc: 0.4587 - auc_1: 0.0031 - val_loss: 0.0096 - val_auc: 0.0975 - val_auc_1: 0.0031\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0095 - auc: 0.4579 - auc_1: 0.0027 - val_loss: 0.0096 - val_auc: 0.0986 - val_auc_1: 0.0023\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0095 - auc: 0.4630 - auc_1: 0.0027 - val_loss: 0.0097 - val_auc: 0.0967 - val_auc_1: 0.0024\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0094 - auc: 0.4622 - auc_1: 0.0032 - val_loss: 0.0097 - val_auc: 0.0976 - val_auc_1: 0.0027\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0094 - auc: 0.4612 - auc_1: 0.0029 - val_loss: 0.0096 - val_auc: 0.0985 - val_auc_1: 0.0020\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0094 - auc: 0.4633 - auc_1: 0.0028 - val_loss: 0.0096 - val_auc: 0.0976 - val_auc_1: 0.0023\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4655 - auc_1: 0.0035 - val_loss: 0.0096 - val_auc: 0.0988 - val_auc_1: 0.0027\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0094 - auc: 0.4664 - auc_1: 0.0034 - val_loss: 0.0096 - val_auc: 0.0987 - val_auc_1: 0.0023\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0094 - auc: 0.4640 - auc_1: 0.0038 - val_loss: 0.0097 - val_auc: 0.0993 - val_auc_1: 0.0023\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0093 - auc: 0.4660 - auc_1: 0.0035 - val_loss: 0.0097 - val_auc: 0.0985 - val_auc_1: 0.0026\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0093 - auc: 0.4685 - auc_1: 0.0034 - val_loss: 0.0097 - val_auc: 0.0975 - val_auc_1: 0.0023\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0093 - auc: 0.4659 - auc_1: 0.0029 - val_loss: 0.0098 - val_auc: 0.0973 - val_auc_1: 0.0023\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0093 - auc: 0.4679 - auc_1: 0.0034 - val_loss: 0.0097 - val_auc: 0.0985 - val_auc_1: 0.0020\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 51s 2s/step - loss: 0.0093 - auc: 0.4733 - auc_1: 0.0034 - val_loss: 0.0097 - val_auc: 0.0988 - val_auc_1: 0.0021\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0093 - auc: 0.4711 - auc_1: 0.0031 - val_loss: 0.0097 - val_auc: 0.0975 - val_auc_1: 0.0017\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0092 - auc: 0.4760 - auc_1: 0.0041 - val_loss: 0.0097 - val_auc: 0.0976 - val_auc_1: 0.0020\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0093 - auc: 0.4708 - auc_1: 0.0041 - val_loss: 0.0098 - val_auc: 0.0974 - val_auc_1: 0.0020\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0092 - auc: 0.4762 - auc_1: 0.0040 - val_loss: 0.0099 - val_auc: 0.0980 - val_auc_1: 0.0024\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0092 - auc: 0.4739 - auc_1: 0.0041 - val_loss: 0.0098 - val_auc: 0.0973 - val_auc_1: 0.0021\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0092 - auc: 0.4777 - auc_1: 0.0047 - val_loss: 0.0098 - val_auc: 0.0987 - val_auc_1: 0.0020\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0092 - auc: 0.4820 - auc_1: 0.0045 - val_loss: 0.0098 - val_auc: 0.0980 - val_auc_1: 0.0020\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0092 - auc: 0.4790 - auc_1: 0.0043 - val_loss: 0.0098 - val_auc: 0.0981 - val_auc_1: 0.0024\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0091 - auc: 0.4813 - auc_1: 0.0042 - val_loss: 0.0098 - val_auc: 0.0977 - val_auc_1: 0.0020\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0091 - auc: 0.4869 - auc_1: 0.0057 - val_loss: 0.0098 - val_auc: 0.0985 - val_auc_1: 0.0022\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0091 - auc: 0.4881 - auc_1: 0.0043 - val_loss: 0.0098 - val_auc: 0.0973 - val_auc_1: 0.0020\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 52s 2s/step - loss: 0.0092 - auc: 0.4849 - auc_1: 0.0048 - val_loss: 0.0100 - val_auc: 0.0976 - val_auc_1: 0.0022\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0091 - auc: 0.4854 - auc_1: 0.0044 - val_loss: 0.0099 - val_auc: 0.0970 - val_auc_1: 0.0025\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0091 - auc: 0.4926 - auc_1: 0.0061 - val_loss: 0.0100 - val_auc: 0.0968 - val_auc_1: 0.0019\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0091 - auc: 0.4926 - auc_1: 0.0049 - val_loss: 0.0100 - val_auc: 0.0971 - val_auc_1: 0.0028\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0090 - auc: 0.4979 - auc_1: 0.0055 - val_loss: 0.0100 - val_auc: 0.0993 - val_auc_1: 0.0028\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0090 - auc: 0.4988 - auc_1: 0.0062 - val_loss: 0.0100 - val_auc: 0.0979 - val_auc_1: 0.0022\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0090 - auc: 0.4971 - auc_1: 0.0067 - val_loss: 0.0100 - val_auc: 0.0975 - val_auc_1: 0.0025\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 66s 2s/step - loss: 0.0090 - auc: 0.5048 - auc_1: 0.0063 - val_loss: 0.0100 - val_auc: 0.0967 - val_auc_1: 0.0027\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0090 - auc: 0.4999 - auc_1: 0.0074 - val_loss: 0.0100 - val_auc: 0.0968 - val_auc_1: 0.0023\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0089 - auc: 0.5110 - auc_1: 0.0072 - val_loss: 0.0101 - val_auc: 0.0982 - val_auc_1: 0.0030\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0089 - auc: 0.5134 - auc_1: 0.0078 - val_loss: 0.0101 - val_auc: 0.0983 - val_auc_1: 0.0026\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0089 - auc: 0.5154 - auc_1: 0.0087 - val_loss: 0.0101 - val_auc: 0.0972 - val_auc_1: 0.0020\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0088 - auc: 0.5246 - auc_1: 0.0086 - val_loss: 0.0101 - val_auc: 0.0969 - val_auc_1: 0.0022\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0089 - auc: 0.5132 - auc_1: 0.0084 - val_loss: 0.0102 - val_auc: 0.0981 - val_auc_1: 0.0031\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0089 - auc: 0.5215 - auc_1: 0.0092 - val_loss: 0.0101 - val_auc: 0.0981 - val_auc_1: 0.0026\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0088 - auc: 0.5231 - auc_1: 0.0103 - val_loss: 0.0102 - val_auc: 0.0987 - val_auc_1: 0.0028\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0088 - auc: 0.5330 - auc_1: 0.0114 - val_loss: 0.0102 - val_auc: 0.0973 - val_auc_1: 0.0023\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0088 - auc: 0.5349 - auc_1: 0.0109 - val_loss: 0.0102 - val_auc: 0.0997 - val_auc_1: 0.0032\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0087 - auc: 0.5376 - auc_1: 0.0134 - val_loss: 0.0102 - val_auc: 0.0981 - val_auc_1: 0.0029\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0087 - auc: 0.5482 - auc_1: 0.0111 - val_loss: 0.0103 - val_auc: 0.0978 - val_auc_1: 0.0026\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0087 - auc: 0.5489 - auc_1: 0.0125 - val_loss: 0.0104 - val_auc: 0.0981 - val_auc_1: 0.0030\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0086 - auc: 0.5567 - auc_1: 0.0136 - val_loss: 0.0103 - val_auc: 0.0988 - val_auc_1: 0.0028\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 51s 2s/step - loss: 0.0087 - auc: 0.5517 - auc_1: 0.0136 - val_loss: 0.0104 - val_auc: 0.0963 - val_auc_1: 0.0027\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0086 - auc: 0.5599 - auc_1: 0.0166 - val_loss: 0.0104 - val_auc: 0.1003 - val_auc_1: 0.0040\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0086 - auc: 0.5617 - auc_1: 0.0155 - val_loss: 0.0104 - val_auc: 0.0981 - val_auc_1: 0.0030\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0086 - auc: 0.5683 - auc_1: 0.0195 - val_loss: 0.0105 - val_auc: 0.0978 - val_auc_1: 0.0023\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0086 - auc: 0.5724 - auc_1: 0.0167 - val_loss: 0.0105 - val_auc: 0.0973 - val_auc_1: 0.0025\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0086 - auc: 0.5832 - auc_1: 0.0171 - val_loss: 0.0105 - val_auc: 0.0974 - val_auc_1: 0.0028\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0085 - auc: 0.5801 - auc_1: 0.0188 - val_loss: 0.0105 - val_auc: 0.0980 - val_auc_1: 0.0036\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0085 - auc: 0.5879 - auc_1: 0.0222 - val_loss: 0.0105 - val_auc: 0.0972 - val_auc_1: 0.0036\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0084 - auc: 0.5980 - auc_1: 0.0216 - val_loss: 0.0106 - val_auc: 0.0970 - val_auc_1: 0.0023\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0085 - auc: 0.5982 - auc_1: 0.0212 - val_loss: 0.0106 - val_auc: 0.0974 - val_auc_1: 0.0028\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0084 - auc: 0.6064 - auc_1: 0.0267 - val_loss: 0.0106 - val_auc: 0.0974 - val_auc_1: 0.0031\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0084 - auc: 0.6050 - auc_1: 0.0237 - val_loss: 0.0107 - val_auc: 0.0976 - val_auc_1: 0.0034\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0084 - auc: 0.6164 - auc_1: 0.0279 - val_loss: 0.0107 - val_auc: 0.0964 - val_auc_1: 0.0030\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0083 - auc: 0.6190 - auc_1: 0.0344 - val_loss: 0.0107 - val_auc: 0.0981 - val_auc_1: 0.0040\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0083 - auc: 0.6215 - auc_1: 0.0295 - val_loss: 0.0108 - val_auc: 0.0965 - val_auc_1: 0.0035\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0083 - auc: 0.6311 - auc_1: 0.0314 - val_loss: 0.0108 - val_auc: 0.0977 - val_auc_1: 0.0034\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0083 - auc: 0.6305 - auc_1: 0.0330 - val_loss: 0.0110 - val_auc: 0.0971 - val_auc_1: 0.0040\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0083 - auc: 0.6324 - auc_1: 0.0339 - val_loss: 0.0110 - val_auc: 0.0959 - val_auc_1: 0.0030\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0082 - auc: 0.6406 - auc_1: 0.0358 - val_loss: 0.0109 - val_auc: 0.0979 - val_auc_1: 0.0032\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0082 - auc: 0.6512 - auc_1: 0.0454 - val_loss: 0.0110 - val_auc: 0.0958 - val_auc_1: 0.0036\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0082 - auc: 0.6500 - auc_1: 0.0423 - val_loss: 0.0110 - val_auc: 0.0992 - val_auc_1: 0.0047\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0081 - auc: 0.6551 - auc_1: 0.0454 - val_loss: 0.0109 - val_auc: 0.0990 - val_auc_1: 0.0041\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e100/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e100/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "(2000, 4000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 05:02:41.090918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 05:02:41.181602: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 05:02:41.184513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:41.184593: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 05:02:41.648508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:41.648617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:41.648624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[3601, 200, 199]\n",
      "4000 80\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.3 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.4 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.6 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.7 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.8 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 0.9 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.0 s\n",
      "process 1200 peaks takes 1.0 s\n",
      "process 1250 peaks takes 1.1 s\n",
      "process 1300 peaks takes 1.1 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.2 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.3 s\n",
      "process 1550 peaks takes 1.4 s\n",
      "process 1600 peaks takes 1.4 s\n",
      "process 1650 peaks takes 1.4 s\n",
      "process 1700 peaks takes 1.5 s\n",
      "process 1750 peaks takes 1.5 s\n",
      "process 1800 peaks takes 1.6 s\n",
      "process 1850 peaks takes 1.6 s\n",
      "process 1900 peaks takes 1.6 s\n",
      "process 1950 peaks takes 1.7 s\n",
      "process 2000 peaks takes 1.7 s\n",
      "process 2050 peaks takes 1.8 s\n",
      "process 2100 peaks takes 1.8 s\n",
      "process 2150 peaks takes 1.9 s\n",
      "process 2200 peaks takes 1.9 s\n",
      "process 2250 peaks takes 1.9 s\n",
      "process 2300 peaks takes 2.0 s\n",
      "process 2350 peaks takes 2.0 s\n",
      "process 2400 peaks takes 2.1 s\n",
      "process 2450 peaks takes 2.1 s\n",
      "process 2500 peaks takes 2.1 s\n",
      "process 2550 peaks takes 2.2 s\n",
      "process 2600 peaks takes 2.2 s\n",
      "process 2650 peaks takes 2.3 s\n",
      "process 2700 peaks takes 2.3 s\n",
      "process 2750 peaks takes 2.3 s\n",
      "process 2800 peaks takes 2.4 s\n",
      "process 2850 peaks takes 2.4 s\n",
      "process 2900 peaks takes 2.5 s\n",
      "process 2950 peaks takes 2.5 s\n",
      "process 3000 peaks takes 2.6 s\n",
      "process 3050 peaks takes 2.6 s\n",
      "process 3100 peaks takes 2.6 s\n",
      "process 3150 peaks takes 2.7 s\n",
      "process 3200 peaks takes 2.7 s\n",
      "process 3250 peaks takes 2.8 s\n",
      "process 3300 peaks takes 2.8 s\n",
      "process 3350 peaks takes 2.9 s\n",
      "process 3400 peaks takes 2.9 s\n",
      "process 3450 peaks takes 3.0 s\n",
      "process 3500 peaks takes 3.0 s\n",
      "process 3550 peaks takes 3.1 s\n",
      "process 3600 peaks takes 3.1 s\n",
      "process 3650 peaks takes 3.1 s\n",
      "process 3700 peaks takes 3.2 s\n",
      "process 3750 peaks takes 3.2 s\n",
      "process 3800 peaks takes 3.3 s\n",
      "process 3850 peaks takes 3.3 s\n",
      "process 3900 peaks takes 3.4 s\n",
      "process 3950 peaks takes 3.4 s\n",
      "\n",
      "train\n",
      "3601 72\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.3 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.4 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.5 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.6 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.7 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.8 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 0.9 s\n",
      "process 1050 peaks takes 0.9 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.0 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.1 s\n",
      "process 1300 peaks takes 1.2 s\n",
      "process 1350 peaks takes 1.2 s\n",
      "process 1400 peaks takes 1.2 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.3 s\n",
      "process 1550 peaks takes 1.4 s\n",
      "process 1600 peaks takes 1.4 s\n",
      "process 1650 peaks takes 1.5 s\n",
      "process 1700 peaks takes 1.5 s\n",
      "process 1750 peaks takes 1.5 s\n",
      "process 1800 peaks takes 1.6 s\n",
      "process 1850 peaks takes 1.6 s\n",
      "process 1900 peaks takes 1.7 s\n",
      "process 1950 peaks takes 1.7 s\n",
      "process 2000 peaks takes 1.7 s\n",
      "process 2050 peaks takes 1.8 s\n",
      "process 2100 peaks takes 1.8 s\n",
      "process 2150 peaks takes 1.9 s\n",
      "process 2200 peaks takes 1.9 s\n",
      "process 2250 peaks takes 1.9 s\n",
      "process 2300 peaks takes 2.0 s\n",
      "process 2350 peaks takes 2.0 s\n",
      "process 2400 peaks takes 2.1 s\n",
      "process 2450 peaks takes 2.1 s\n",
      "process 2500 peaks takes 2.2 s\n",
      "process 2550 peaks takes 2.2 s\n",
      "process 2600 peaks takes 2.2 s\n",
      "process 2650 peaks takes 2.3 s\n",
      "process 2700 peaks takes 2.3 s\n",
      "process 2750 peaks takes 2.4 s\n",
      "process 2800 peaks takes 2.4 s\n",
      "process 2850 peaks takes 2.4 s\n",
      "process 2900 peaks takes 2.5 s\n",
      "process 2950 peaks takes 2.5 s\n",
      "process 3000 peaks takes 2.6 s\n",
      "process 3050 peaks takes 2.6 s\n",
      "process 3100 peaks takes 2.7 s\n",
      "process 3150 peaks takes 2.7 s\n",
      "process 3200 peaks takes 2.8 s\n",
      "process 3250 peaks takes 2.8 s\n",
      "process 3300 peaks takes 2.8 s\n",
      "process 3350 peaks takes 2.9 s\n",
      "process 3400 peaks takes 2.9 s\n",
      "process 3450 peaks takes 3.0 s\n",
      "process 3500 peaks takes 3.0 s\n",
      "process 3550 peaks takes 3.1 s\n",
      "\n",
      "test\n",
      "200 4\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "199 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000 --epochs 100 --out_path /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e100/bce\n",
      "about to train...\n",
      "2024-05-13 05:02:50.437862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 05:02:50.537145: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 05:02:50.540060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:50.540092: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 05:02:51.049199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:51.049288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:51.049294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 05:02:52.600428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 05:02:52.600550: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600624: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600761: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 05:02:52.600912: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 05:02:52.601248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.3491 - auc: 0.4472 - auc_1: 0.0023 - val_loss: 0.0290 - val_auc: 0.0974 - val_auc_1: 0.0037\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0187 - auc: 0.4439 - auc_1: 0.0021 - val_loss: 0.0123 - val_auc: 0.0949 - val_auc_1: 0.0014\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0116 - auc: 0.4473 - auc_1: 0.0017 - val_loss: 0.0117 - val_auc: 0.0952 - val_auc_1: 0.0014\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0113 - auc: 0.4468 - auc_1: 0.0023 - val_loss: 0.0107 - val_auc: 0.0952 - val_auc_1: 0.0015\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 53s 2s/step - loss: 0.0108 - auc: 0.4450 - auc_1: 0.0019 - val_loss: 0.0102 - val_auc: 0.0944 - val_auc_1: 0.0017\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0105 - auc: 0.4480 - auc_1: 0.0018 - val_loss: 0.0101 - val_auc: 0.0937 - val_auc_1: 0.0017\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0105 - auc: 0.4463 - auc_1: 0.0019 - val_loss: 0.0100 - val_auc: 0.0950 - val_auc_1: 0.0019\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0104 - auc: 0.4464 - auc_1: 0.0021 - val_loss: 0.0100 - val_auc: 0.0949 - val_auc_1: 0.0019\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0103 - auc: 0.4452 - auc_1: 0.0020 - val_loss: 0.0099 - val_auc: 0.0949 - val_auc_1: 0.0017\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0103 - auc: 0.4470 - auc_1: 0.0019 - val_loss: 0.0098 - val_auc: 0.0938 - val_auc_1: 0.0018\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0102 - auc: 0.4482 - auc_1: 0.0018 - val_loss: 0.0098 - val_auc: 0.0944 - val_auc_1: 0.0025\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0101 - auc: 0.4477 - auc_1: 0.0020 - val_loss: 0.0097 - val_auc: 0.0943 - val_auc_1: 0.0016\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0101 - auc: 0.4479 - auc_1: 0.0021 - val_loss: 0.0097 - val_auc: 0.0947 - val_auc_1: 0.0017\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0101 - auc: 0.4493 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0950 - val_auc_1: 0.0023\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0100 - auc: 0.4496 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0949 - val_auc_1: 0.0021\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0100 - auc: 0.4499 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0943 - val_auc_1: 0.0022\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 52s 2s/step - loss: 0.0099 - auc: 0.4484 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0939 - val_auc_1: 0.0018\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0099 - auc: 0.4511 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0942 - val_auc_1: 0.0019\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 50s 2s/step - loss: 0.0099 - auc: 0.4489 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0938 - val_auc_1: 0.0015\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0099 - auc: 0.4504 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0949 - val_auc_1: 0.0024\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0099 - auc: 0.4492 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0937 - val_auc_1: 0.0022\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0098 - auc: 0.4511 - auc_1: 0.0020 - val_loss: 0.0096 - val_auc: 0.0950 - val_auc_1: 0.0024\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0098 - auc: 0.4519 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0949 - val_auc_1: 0.0025\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0098 - auc: 0.4504 - auc_1: 0.0022 - val_loss: 0.0096 - val_auc: 0.0935 - val_auc_1: 0.0021\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0097 - auc: 0.4527 - auc_1: 0.0028 - val_loss: 0.0095 - val_auc: 0.0940 - val_auc_1: 0.0018\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0097 - auc: 0.4521 - auc_1: 0.0020 - val_loss: 0.0095 - val_auc: 0.0942 - val_auc_1: 0.0018\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0097 - auc: 0.4517 - auc_1: 0.0021 - val_loss: 0.0096 - val_auc: 0.0950 - val_auc_1: 0.0017\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0097 - auc: 0.4519 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0932 - val_auc_1: 0.0017\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0097 - auc: 0.4526 - auc_1: 0.0027 - val_loss: 0.0095 - val_auc: 0.0947 - val_auc_1: 0.0018\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0097 - auc: 0.4530 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0948 - val_auc_1: 0.0027\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0097 - auc: 0.4519 - auc_1: 0.0020 - val_loss: 0.0096 - val_auc: 0.0955 - val_auc_1: 0.0022\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0096 - auc: 0.4521 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0946 - val_auc_1: 0.0015\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0096 - auc: 0.4527 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0955 - val_auc_1: 0.0017\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0096 - auc: 0.4542 - auc_1: 0.0032 - val_loss: 0.0096 - val_auc: 0.0937 - val_auc_1: 0.0016\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0096 - auc: 0.4549 - auc_1: 0.0029 - val_loss: 0.0095 - val_auc: 0.0955 - val_auc_1: 0.0017\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0096 - auc: 0.4533 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0952 - val_auc_1: 0.0018\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 46s 2s/step - loss: 0.0096 - auc: 0.4518 - auc_1: 0.0019 - val_loss: 0.0095 - val_auc: 0.0956 - val_auc_1: 0.0019\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 54s 1s/step - loss: 0.0096 - auc: 0.4542 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0965 - val_auc_1: 0.0021\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4533 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0961 - val_auc_1: 0.0017\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0096 - auc: 0.4526 - auc_1: 0.0027 - val_loss: 0.0096 - val_auc: 0.0967 - val_auc_1: 0.0020\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0096 - auc: 0.4566 - auc_1: 0.0032 - val_loss: 0.0096 - val_auc: 0.0939 - val_auc_1: 0.0016\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0096 - auc: 0.4542 - auc_1: 0.0034 - val_loss: 0.0096 - val_auc: 0.0956 - val_auc_1: 0.0020\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0096 - auc: 0.4557 - auc_1: 0.0028 - val_loss: 0.0096 - val_auc: 0.0956 - val_auc_1: 0.0023\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0095 - auc: 0.4537 - auc_1: 0.0027 - val_loss: 0.0095 - val_auc: 0.0966 - val_auc_1: 0.0028\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0096 - auc: 0.4557 - auc_1: 0.0023 - val_loss: 0.0095 - val_auc: 0.0969 - val_auc_1: 0.0018\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0096 - auc: 0.4534 - auc_1: 0.0023 - val_loss: 0.0096 - val_auc: 0.0943 - val_auc_1: 0.0017\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0095 - auc: 0.4569 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0964 - val_auc_1: 0.0022\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0095 - auc: 0.4561 - auc_1: 0.0028 - val_loss: 0.0096 - val_auc: 0.0958 - val_auc_1: 0.0021\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0095 - auc: 0.4580 - auc_1: 0.0024 - val_loss: 0.0096 - val_auc: 0.0956 - val_auc_1: 0.0021\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 45s 2s/step - loss: 0.0095 - auc: 0.4561 - auc_1: 0.0025 - val_loss: 0.0096 - val_auc: 0.0945 - val_auc_1: 0.0018\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0095 - auc: 0.4575 - auc_1: 0.0031 - val_loss: 0.0096 - val_auc: 0.0945 - val_auc_1: 0.0016\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0095 - auc: 0.4582 - auc_1: 0.0040 - val_loss: 0.0096 - val_auc: 0.0949 - val_auc_1: 0.0017\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0095 - auc: 0.4581 - auc_1: 0.0034 - val_loss: 0.0096 - val_auc: 0.0943 - val_auc_1: 0.0015\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0095 - auc: 0.4588 - auc_1: 0.0028 - val_loss: 0.0096 - val_auc: 0.0946 - val_auc_1: 0.0018\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4616 - auc_1: 0.0038 - val_loss: 0.0096 - val_auc: 0.0954 - val_auc_1: 0.0020\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0095 - auc: 0.4588 - auc_1: 0.0029 - val_loss: 0.0096 - val_auc: 0.0950 - val_auc_1: 0.0018\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0095 - auc: 0.4598 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0941 - val_auc_1: 0.0023\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4624 - auc_1: 0.0033 - val_loss: 0.0096 - val_auc: 0.0954 - val_auc_1: 0.0023\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0094 - auc: 0.4604 - auc_1: 0.0026 - val_loss: 0.0096 - val_auc: 0.0948 - val_auc_1: 0.0024\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0094 - auc: 0.4607 - auc_1: 0.0031 - val_loss: 0.0096 - val_auc: 0.0955 - val_auc_1: 0.0022\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0094 - auc: 0.4608 - auc_1: 0.0030 - val_loss: 0.0097 - val_auc: 0.0947 - val_auc_1: 0.0024\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 65s 2s/step - loss: 0.0094 - auc: 0.4632 - auc_1: 0.0032 - val_loss: 0.0097 - val_auc: 0.0940 - val_auc_1: 0.0022\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0094 - auc: 0.4644 - auc_1: 0.0038 - val_loss: 0.0096 - val_auc: 0.0953 - val_auc_1: 0.0027\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0094 - auc: 0.4667 - auc_1: 0.0032 - val_loss: 0.0097 - val_auc: 0.0957 - val_auc_1: 0.0018\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0093 - auc: 0.4642 - auc_1: 0.0031 - val_loss: 0.0097 - val_auc: 0.0952 - val_auc_1: 0.0021\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0093 - auc: 0.4669 - auc_1: 0.0034 - val_loss: 0.0097 - val_auc: 0.0944 - val_auc_1: 0.0023\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0093 - auc: 0.4681 - auc_1: 0.0030 - val_loss: 0.0097 - val_auc: 0.0955 - val_auc_1: 0.0031\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0093 - auc: 0.4690 - auc_1: 0.0035 - val_loss: 0.0097 - val_auc: 0.0951 - val_auc_1: 0.0024\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0093 - auc: 0.4722 - auc_1: 0.0036 - val_loss: 0.0098 - val_auc: 0.0949 - val_auc_1: 0.0027\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0093 - auc: 0.4700 - auc_1: 0.0036 - val_loss: 0.0098 - val_auc: 0.0950 - val_auc_1: 0.0027\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0093 - auc: 0.4719 - auc_1: 0.0038 - val_loss: 0.0097 - val_auc: 0.0950 - val_auc_1: 0.0025\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0093 - auc: 0.4734 - auc_1: 0.0047 - val_loss: 0.0097 - val_auc: 0.0955 - val_auc_1: 0.0027\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0093 - auc: 0.4761 - auc_1: 0.0043 - val_loss: 0.0098 - val_auc: 0.0960 - val_auc_1: 0.0029\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0092 - auc: 0.4787 - auc_1: 0.0039 - val_loss: 0.0098 - val_auc: 0.0961 - val_auc_1: 0.0026\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0092 - auc: 0.4790 - auc_1: 0.0049 - val_loss: 0.0097 - val_auc: 0.0960 - val_auc_1: 0.0023\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0092 - auc: 0.4817 - auc_1: 0.0049 - val_loss: 0.0098 - val_auc: 0.0962 - val_auc_1: 0.0026\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0092 - auc: 0.4805 - auc_1: 0.0040 - val_loss: 0.0098 - val_auc: 0.0963 - val_auc_1: 0.0025\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 52s 2s/step - loss: 0.0092 - auc: 0.4842 - auc_1: 0.0039 - val_loss: 0.0098 - val_auc: 0.0965 - val_auc_1: 0.0031\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 44s 2s/step - loss: 0.0092 - auc: 0.4850 - auc_1: 0.0043 - val_loss: 0.0098 - val_auc: 0.0945 - val_auc_1: 0.0027\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0091 - auc: 0.4882 - auc_1: 0.0051 - val_loss: 0.0098 - val_auc: 0.0947 - val_auc_1: 0.0016\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0091 - auc: 0.4881 - auc_1: 0.0055 - val_loss: 0.0098 - val_auc: 0.0963 - val_auc_1: 0.0027\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0091 - auc: 0.4933 - auc_1: 0.0054 - val_loss: 0.0099 - val_auc: 0.0963 - val_auc_1: 0.0025\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0090 - auc: 0.4989 - auc_1: 0.0058 - val_loss: 0.0098 - val_auc: 0.0964 - val_auc_1: 0.0021\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0091 - auc: 0.5014 - auc_1: 0.0072 - val_loss: 0.0099 - val_auc: 0.0968 - val_auc_1: 0.0021\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0091 - auc: 0.4985 - auc_1: 0.0069 - val_loss: 0.0099 - val_auc: 0.0977 - val_auc_1: 0.0022\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0090 - auc: 0.5023 - auc_1: 0.0067 - val_loss: 0.0099 - val_auc: 0.0979 - val_auc_1: 0.0027\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0090 - auc: 0.5073 - auc_1: 0.0065 - val_loss: 0.0100 - val_auc: 0.0981 - val_auc_1: 0.0025\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0090 - auc: 0.5104 - auc_1: 0.0101 - val_loss: 0.0100 - val_auc: 0.0967 - val_auc_1: 0.0031\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0089 - auc: 0.5159 - auc_1: 0.0083 - val_loss: 0.0100 - val_auc: 0.0965 - val_auc_1: 0.0021\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0090 - auc: 0.5187 - auc_1: 0.0097 - val_loss: 0.0100 - val_auc: 0.0997 - val_auc_1: 0.0027\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 44s 1s/step - loss: 0.0089 - auc: 0.5165 - auc_1: 0.0089 - val_loss: 0.0100 - val_auc: 0.0979 - val_auc_1: 0.0038\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 56s 2s/step - loss: 0.0089 - auc: 0.5222 - auc_1: 0.0103 - val_loss: 0.0100 - val_auc: 0.0980 - val_auc_1: 0.0035\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 63s 2s/step - loss: 0.0089 - auc: 0.5258 - auc_1: 0.0114 - val_loss: 0.0100 - val_auc: 0.0970 - val_auc_1: 0.0024\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0089 - auc: 0.5365 - auc_1: 0.0113 - val_loss: 0.0100 - val_auc: 0.0973 - val_auc_1: 0.0028\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 43s 1s/step - loss: 0.0088 - auc: 0.5357 - auc_1: 0.0092 - val_loss: 0.0100 - val_auc: 0.0997 - val_auc_1: 0.0026\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 55s 2s/step - loss: 0.0088 - auc: 0.5412 - auc_1: 0.0125 - val_loss: 0.0101 - val_auc: 0.0974 - val_auc_1: 0.0029\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0088 - auc: 0.5443 - auc_1: 0.0179 - val_loss: 0.0102 - val_auc: 0.0976 - val_auc_1: 0.0028\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0088 - auc: 0.5445 - auc_1: 0.0128 - val_loss: 0.0101 - val_auc: 0.0982 - val_auc_1: 0.0031\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0087 - auc: 0.5478 - auc_1: 0.0103 - val_loss: 0.0102 - val_auc: 0.0993 - val_auc_1: 0.0025\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 54s 2s/step - loss: 0.0087 - auc: 0.5535 - auc_1: 0.0177 - val_loss: 0.0102 - val_auc: 0.0971 - val_auc_1: 0.0025\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e100/bce/running_time.pkl\n",
      "\n",
      "\n",
      "gbm\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm gbm_multiome_scdori /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e1/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:24:56.815912: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:24:56.941249: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:24:56.945403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:24:56.945458: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:24:57.446393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:24:57.446466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:24:57.446473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:24:59.245518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:24:59.346445: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:24:59.349470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:24:59.349500: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:24:59.820907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:24:59.820992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:24:59.820998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:25:01.278176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:25:01.278309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278381: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278660: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:01.278678: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:25:01.279059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "2024-05-13 06:25:05.247917: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7652]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e1/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:25:07.493336: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:07.586250: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:07.589070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:07.589099: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:08.068177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:08.068249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:08.068256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:25:09.862018: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:09.973564: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:09.977046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:09.977081: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:10.446869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:10.446941: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:10.446948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:25:11.883775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:25:11.883903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.883970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884102: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:11.884257: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:25:11.884643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "2024-05-13 06:25:15.915282: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7726]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm gbm_multiome_scdori /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e10/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:25:18.184308: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:18.286866: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:18.290364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:18.290398: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:18.763807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:18.763887: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:18.763907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e10/poisson\n",
      "about to train...\n",
      "2024-05-13 06:25:20.517598: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:20.611104: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:20.614585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:20.614644: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:21.112557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:21.112649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:21.112676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:25:22.560922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:25:22.561051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:22.561423: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:25:22.561752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/10\n",
      "2024-05-13 06:25:26.539668: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7652]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e10/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e10/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:25:28.801264: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:28.893908: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:28.896862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:28.896892: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:29.351343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:29.351440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:29.351447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e10/bce\n",
      "about to train...\n",
      "2024-05-13 06:25:31.135581: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:31.233745: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:31.236854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:31.236886: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:31.692466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:31.692570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:31.692577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:25:33.145673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:25:33.145792: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.145865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.145909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.145952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.145997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.146040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.146083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.146127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:33.146145: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:25:33.146476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "2024-05-13 06:25:37.158317: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7726]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e10/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm gbm_multiome_scdori /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e20/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:25:39.392100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:39.484531: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:39.487430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:39.487460: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:39.955507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:39.955580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:39.955586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 20 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e20/poisson\n",
      "about to train...\n",
      "2024-05-13 06:25:41.723585: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:41.817630: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:41.821331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:41.821400: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:42.294100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:42.294165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:42.294171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:25:43.776856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:25:43.776986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:43.777372: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:25:43.777759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/20\n",
      "2024-05-13 06:25:47.825903: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7652]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e20/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e20/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:25:50.029799: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:50.129544: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:50.132448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:50.132484: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:50.589459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:50.589561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:50.589581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 20 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e20/bce\n",
      "about to train...\n",
      "2024-05-13 06:25:52.363576: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:25:52.459307: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:25:52.462295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:52.462325: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:25:52.924684: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:52.924790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:52.924797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:25:54.440689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:25:54.440806: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.440904: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.440961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.440989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.441038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.441065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.441104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.441143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:25:54.441150: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:25:54.441484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "2024-05-13 06:25:58.567820: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7726]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e20/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm gbm_multiome_scdori /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:26:01.042969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:01.151899: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:01.155310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:01.155345: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:01.655250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:01.655328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:01.655347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/poisson\n",
      "about to train...\n",
      "2024-05-13 06:26:03.381181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:03.475453: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:03.478428: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:03.478459: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:03.949440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:03.949510: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:03.949517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:26:05.417648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:26:05.417774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.417876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.417919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.417961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.418012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.418053: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.418096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.418154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:05.418171: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:26:05.418532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/50\n",
      "2024-05-13 06:26:09.320516: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7652]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:26:11.502432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:11.591478: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:11.594989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:11.595039: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:12.054732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:12.054814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:12.054836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/bce\n",
      "about to train...\n",
      "2024-05-13 06:26:13.886428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:13.990052: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:13.992929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:13.992955: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:14.488635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:14.488708: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:14.488714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:26:15.976761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:26:15.976895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.976966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977010: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:15.977271: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:26:15.977635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "2024-05-13 06:26:19.966468: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7726]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "gbm gbm_multiome_scdori /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e100/poisson\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:26:22.205018: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:22.298793: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:22.301536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:22.301563: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:22.767753: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:22.767828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:22.767834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 100 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e100/poisson\n",
      "about to train...\n",
      "2024-05-13 06:26:24.512739: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:24.606803: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:24.609807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:24.609836: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:25.066528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:25.066593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:25.066599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:26:26.505692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:26:26.505812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.505894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.505952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.505981: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.506045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.506074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.506123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.506165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:26.506172: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:26:26.506529: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/100\n",
      "2024-05-13 06:26:30.401599: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7652]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e100/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed\n",
      "out False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e100/bce\n",
      "hg38\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "(1000, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 50\n",
      "2024-05-13 06:26:32.605800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:32.705720: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:32.708574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:32.708604: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:33.164220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:33.164334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:33.164341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 31, in make_bed_seqs_from_df\n",
      "    start = int(input_bed.iloc[i,1])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 100 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e100/bce\n",
      "about to train...\n",
      "2024-05-13 06:26:34.897457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:34.988991: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:34.991772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:34.991801: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:35.459153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:35.459224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:35.459231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:26:36.881026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:26:36.881144: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881418: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:36.881531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:26:36.881919: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "2024-05-13 06:26:40.943402: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_7726]\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e100/bce/running_time.pkl\n",
      "\n",
      "\n",
      "noack_2022\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "noack_2022 random /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500\n",
      "out True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:26:42.165091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:26:42.264095: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:26:42.267214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:42.267244: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:26:42.713779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:42.713846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:42.713852: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:26:44.271824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:26:44.271949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272071: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272241: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:26:44.272302: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:26:44.272648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "11/11 [==============================] - 20s 1s/step - loss: 0.4687 - auc: 0.5479 - auc_1: 0.0815 - val_loss: 0.7126 - val_auc: 0.5516 - val_auc_1: 0.1406\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500\n",
      "out True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:27:06.193945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:27:06.292844: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:27:06.295701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:06.295730: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:27:06.758689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:06.758758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:06.758765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:27:08.257543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:27:08.257648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:08.257986: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:27:08.258328: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.6140 - auc: 0.5489 - auc_1: 0.0836 - val_loss: 0.7125 - val_auc: 0.5678 - val_auc_1: 0.0958\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "noack_2022 random /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:27:41.704315: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:27:41.799824: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:27:41.802580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:41.802608: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:27:42.277541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:42.277614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:42.277620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:27:44.088725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:27:44.088850: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.088945: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.088973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.089032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.089061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.089101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.089152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.089179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:27:44.089197: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:27:44.089591: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "43/43 [==============================] - 79s 2s/step - loss: 0.3260 - auc: 0.5865 - auc_1: 0.0910 - val_loss: 0.2533 - val_auc: 0.6411 - val_auc_1: 0.1694\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 06:29:06.810074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:29:06.910381: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:29:06.913770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:06.913820: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:29:07.393501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:07.393574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:07.393581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 2.0 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.1 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.2 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.3 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.4 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.5 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.7 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.8 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 2.9 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "process 2700 peaks takes 3.1 s\n",
      "process 2750 peaks takes 3.1 s\n",
      "process 2800 peaks takes 3.2 s\n",
      "process 2850 peaks takes 3.2 s\n",
      "process 2900 peaks takes 3.3 s\n",
      "process 2950 peaks takes 3.3 s\n",
      "process 3000 peaks takes 3.4 s\n",
      "process 3050 peaks takes 3.5 s\n",
      "process 3100 peaks takes 3.5 s\n",
      "process 3150 peaks takes 3.6 s\n",
      "process 3200 peaks takes 3.6 s\n",
      "process 3250 peaks takes 3.7 s\n",
      "process 3300 peaks takes 3.8 s\n",
      "process 3350 peaks takes 3.8 s\n",
      "process 3400 peaks takes 3.9 s\n",
      "process 3450 peaks takes 4.0 s\n",
      "process 3500 peaks takes 4.0 s\n",
      "process 3550 peaks takes 4.1 s\n",
      "process 3600 peaks takes 4.1 s\n",
      "process 3650 peaks takes 4.2 s\n",
      "process 3700 peaks takes 4.2 s\n",
      "process 3750 peaks takes 4.3 s\n",
      "process 3800 peaks takes 4.4 s\n",
      "process 3850 peaks takes 4.4 s\n",
      "process 3900 peaks takes 4.5 s\n",
      "process 3950 peaks takes 4.6 s\n",
      "process 4000 peaks takes 4.6 s\n",
      "process 4050 peaks takes 4.7 s\n",
      "process 4100 peaks takes 4.7 s\n",
      "process 4150 peaks takes 4.8 s\n",
      "process 4200 peaks takes 4.9 s\n",
      "process 4250 peaks takes 4.9 s\n",
      "process 4300 peaks takes 5.0 s\n",
      "process 4350 peaks takes 5.0 s\n",
      "process 4400 peaks takes 5.1 s\n",
      "process 4450 peaks takes 5.1 s\n",
      "process 4500 peaks takes 5.2 s\n",
      "process 4550 peaks takes 5.3 s\n",
      "process 4600 peaks takes 5.3 s\n",
      "process 4650 peaks takes 5.4 s\n",
      "process 4700 peaks takes 5.4 s\n",
      "process 4750 peaks takes 5.5 s\n",
      "process 4800 peaks takes 5.5 s\n",
      "process 4850 peaks takes 5.6 s\n",
      "process 4900 peaks takes 5.6 s\n",
      "process 4950 peaks takes 5.7 s\n",
      "process 5000 peaks takes 5.8 s\n",
      "process 5050 peaks takes 5.8 s\n",
      "process 5100 peaks takes 5.9 s\n",
      "process 5150 peaks takes 5.9 s\n",
      "process 5200 peaks takes 6.0 s\n",
      "process 5250 peaks takes 6.0 s\n",
      "process 5300 peaks takes 6.1 s\n",
      "process 5350 peaks takes 6.2 s\n",
      "process 5400 peaks takes 6.2 s\n",
      "process 5450 peaks takes 6.3 s\n",
      "process 5500 peaks takes 6.3 s\n",
      "process 5550 peaks takes 6.4 s\n",
      "process 5600 peaks takes 6.4 s\n",
      "process 5650 peaks takes 6.5 s\n",
      "process 5700 peaks takes 6.5 s\n",
      "process 5750 peaks takes 6.6 s\n",
      "process 5800 peaks takes 6.7 s\n",
      "process 5850 peaks takes 6.7 s\n",
      "process 5900 peaks takes 6.8 s\n",
      "process 5950 peaks takes 6.8 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.3 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.5 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.6 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.7 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.8 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.9 s\n",
      "process 4100 peaks takes 3.9 s\n",
      "process 4150 peaks takes 4.0 s\n",
      "process 4200 peaks takes 4.0 s\n",
      "process 4250 peaks takes 4.1 s\n",
      "process 4300 peaks takes 4.1 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.2 s\n",
      "process 4450 peaks takes 4.3 s\n",
      "process 4500 peaks takes 4.3 s\n",
      "process 4550 peaks takes 4.3 s\n",
      "process 4600 peaks takes 4.4 s\n",
      "process 4650 peaks takes 4.4 s\n",
      "process 4700 peaks takes 4.5 s\n",
      "process 4750 peaks takes 4.5 s\n",
      "process 4800 peaks takes 4.6 s\n",
      "process 4850 peaks takes 4.6 s\n",
      "process 4900 peaks takes 4.7 s\n",
      "process 4950 peaks takes 4.7 s\n",
      "process 5000 peaks takes 4.8 s\n",
      "process 5050 peaks takes 4.8 s\n",
      "process 5100 peaks takes 4.9 s\n",
      "process 5150 peaks takes 4.9 s\n",
      "process 5200 peaks takes 5.0 s\n",
      "process 5250 peaks takes 5.0 s\n",
      "process 5300 peaks takes 5.1 s\n",
      "process 5350 peaks takes 5.1 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:29:22.275751: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:29:22.371166: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:29:22.375390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:22.375421: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:29:22.853853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:22.853950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:22.853957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:29:24.453034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:29:24.453152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:29:24.453511: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:29:24.453870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "43/43 [==============================] - 80s 2s/step - loss: 0.3726 - auc: 0.5750 - auc_1: 0.0879 - val_loss: 0.3680 - val_auc: 0.6088 - val_auc_1: 0.0982\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "noack_2022 random /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 06:30:49.561476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:30:49.652674: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:30:49.655456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:30:49.655485: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:30:50.132018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:30:50.132110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:30:50.132126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.3 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.5 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.6 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.7 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.8 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.9 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 2.0 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.1 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.2 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.4 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.6 s\n",
      "process 2300 peaks takes 2.7 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.8 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.9 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 3.0 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "process 2700 peaks takes 3.1 s\n",
      "process 2750 peaks takes 3.1 s\n",
      "process 2800 peaks takes 3.2 s\n",
      "process 2850 peaks takes 3.2 s\n",
      "process 2900 peaks takes 3.3 s\n",
      "process 2950 peaks takes 3.3 s\n",
      "process 3000 peaks takes 3.4 s\n",
      "process 3050 peaks takes 3.5 s\n",
      "process 3100 peaks takes 3.5 s\n",
      "process 3150 peaks takes 3.6 s\n",
      "process 3200 peaks takes 3.6 s\n",
      "process 3250 peaks takes 3.7 s\n",
      "process 3300 peaks takes 3.8 s\n",
      "process 3350 peaks takes 3.8 s\n",
      "process 3400 peaks takes 3.9 s\n",
      "process 3450 peaks takes 3.9 s\n",
      "process 3500 peaks takes 4.0 s\n",
      "process 3550 peaks takes 4.0 s\n",
      "process 3600 peaks takes 4.1 s\n",
      "process 3650 peaks takes 4.1 s\n",
      "process 3700 peaks takes 4.2 s\n",
      "process 3750 peaks takes 4.2 s\n",
      "process 3800 peaks takes 4.3 s\n",
      "process 3850 peaks takes 4.3 s\n",
      "process 3900 peaks takes 4.4 s\n",
      "process 3950 peaks takes 4.4 s\n",
      "process 4000 peaks takes 4.5 s\n",
      "process 4050 peaks takes 4.5 s\n",
      "process 4100 peaks takes 4.6 s\n",
      "process 4150 peaks takes 4.6 s\n",
      "process 4200 peaks takes 4.7 s\n",
      "process 4250 peaks takes 4.7 s\n",
      "process 4300 peaks takes 4.8 s\n",
      "process 4350 peaks takes 4.8 s\n",
      "process 4400 peaks takes 4.9 s\n",
      "process 4450 peaks takes 4.9 s\n",
      "process 4500 peaks takes 5.0 s\n",
      "process 4550 peaks takes 5.0 s\n",
      "process 4600 peaks takes 5.1 s\n",
      "process 4650 peaks takes 5.1 s\n",
      "process 4700 peaks takes 5.2 s\n",
      "process 4750 peaks takes 5.2 s\n",
      "process 4800 peaks takes 5.3 s\n",
      "process 4850 peaks takes 5.3 s\n",
      "process 4900 peaks takes 5.4 s\n",
      "process 4950 peaks takes 5.4 s\n",
      "process 5000 peaks takes 5.5 s\n",
      "process 5050 peaks takes 5.5 s\n",
      "process 5100 peaks takes 5.6 s\n",
      "process 5150 peaks takes 5.6 s\n",
      "process 5200 peaks takes 5.7 s\n",
      "process 5250 peaks takes 5.7 s\n",
      "process 5300 peaks takes 5.8 s\n",
      "process 5350 peaks takes 5.8 s\n",
      "process 5400 peaks takes 5.9 s\n",
      "process 5450 peaks takes 5.9 s\n",
      "process 5500 peaks takes 6.0 s\n",
      "process 5550 peaks takes 6.1 s\n",
      "process 5600 peaks takes 6.1 s\n",
      "process 5650 peaks takes 6.2 s\n",
      "process 5700 peaks takes 6.2 s\n",
      "process 5750 peaks takes 6.2 s\n",
      "process 5800 peaks takes 6.3 s\n",
      "process 5850 peaks takes 6.4 s\n",
      "process 5900 peaks takes 6.4 s\n",
      "process 5950 peaks takes 6.5 s\n",
      "process 6000 peaks takes 6.5 s\n",
      "process 6050 peaks takes 6.6 s\n",
      "process 6100 peaks takes 6.6 s\n",
      "process 6150 peaks takes 6.7 s\n",
      "process 6200 peaks takes 6.7 s\n",
      "process 6250 peaks takes 6.8 s\n",
      "process 6300 peaks takes 6.8 s\n",
      "process 6350 peaks takes 6.9 s\n",
      "process 6400 peaks takes 6.9 s\n",
      "process 6450 peaks takes 7.0 s\n",
      "process 6500 peaks takes 7.0 s\n",
      "process 6550 peaks takes 7.1 s\n",
      "process 6600 peaks takes 7.1 s\n",
      "process 6650 peaks takes 7.2 s\n",
      "process 6700 peaks takes 7.2 s\n",
      "process 6750 peaks takes 7.3 s\n",
      "process 6800 peaks takes 7.3 s\n",
      "process 6850 peaks takes 7.4 s\n",
      "process 6900 peaks takes 7.4 s\n",
      "process 6950 peaks takes 7.5 s\n",
      "process 7000 peaks takes 7.5 s\n",
      "process 7050 peaks takes 7.6 s\n",
      "process 7100 peaks takes 7.6 s\n",
      "process 7150 peaks takes 7.7 s\n",
      "process 7200 peaks takes 7.7 s\n",
      "process 7250 peaks takes 7.8 s\n",
      "process 7300 peaks takes 7.8 s\n",
      "process 7350 peaks takes 7.9 s\n",
      "process 7400 peaks takes 7.9 s\n",
      "process 7450 peaks takes 8.0 s\n",
      "process 7500 peaks takes 8.0 s\n",
      "process 7550 peaks takes 8.1 s\n",
      "process 7600 peaks takes 8.1 s\n",
      "process 7650 peaks takes 8.2 s\n",
      "process 7700 peaks takes 8.2 s\n",
      "process 7750 peaks takes 8.3 s\n",
      "process 7800 peaks takes 8.3 s\n",
      "process 7850 peaks takes 8.4 s\n",
      "process 7900 peaks takes 8.4 s\n",
      "process 7950 peaks takes 8.5 s\n",
      "process 8000 peaks takes 8.6 s\n",
      "process 8050 peaks takes 8.6 s\n",
      "process 8100 peaks takes 8.7 s\n",
      "process 8150 peaks takes 8.7 s\n",
      "process 8200 peaks takes 8.8 s\n",
      "process 8250 peaks takes 8.9 s\n",
      "process 8300 peaks takes 8.9 s\n",
      "process 8350 peaks takes 9.0 s\n",
      "process 8400 peaks takes 9.0 s\n",
      "process 8450 peaks takes 9.1 s\n",
      "process 8500 peaks takes 9.1 s\n",
      "process 8550 peaks takes 9.2 s\n",
      "process 8600 peaks takes 9.3 s\n",
      "process 8650 peaks takes 9.3 s\n",
      "process 8700 peaks takes 9.4 s\n",
      "process 8750 peaks takes 9.4 s\n",
      "process 8800 peaks takes 9.5 s\n",
      "process 8850 peaks takes 9.5 s\n",
      "process 8900 peaks takes 9.6 s\n",
      "process 8950 peaks takes 9.6 s\n",
      "process 9000 peaks takes 9.7 s\n",
      "process 9050 peaks takes 9.7 s\n",
      "process 9100 peaks takes 9.8 s\n",
      "process 9150 peaks takes 9.8 s\n",
      "process 9200 peaks takes 9.9 s\n",
      "process 9250 peaks takes 9.9 s\n",
      "process 9300 peaks takes 10.0 s\n",
      "process 9350 peaks takes 10.1 s\n",
      "process 9400 peaks takes 10.1 s\n",
      "process 9450 peaks takes 10.2 s\n",
      "process 9500 peaks takes 10.2 s\n",
      "process 9550 peaks takes 10.3 s\n",
      "process 9600 peaks takes 10.3 s\n",
      "process 9650 peaks takes 10.4 s\n",
      "process 9700 peaks takes 10.5 s\n",
      "process 9750 peaks takes 10.5 s\n",
      "process 9800 peaks takes 10.6 s\n",
      "process 9850 peaks takes 10.6 s\n",
      "process 9900 peaks takes 10.7 s\n",
      "process 9950 peaks takes 10.7 s\n",
      "process 10000 peaks takes 10.8 s\n",
      "process 10050 peaks takes 10.8 s\n",
      "process 10100 peaks takes 10.9 s\n",
      "process 10150 peaks takes 10.9 s\n",
      "process 10200 peaks takes 11.0 s\n",
      "process 10250 peaks takes 11.0 s\n",
      "process 10300 peaks takes 11.1 s\n",
      "process 10350 peaks takes 11.1 s\n",
      "process 10400 peaks takes 11.2 s\n",
      "process 10450 peaks takes 11.2 s\n",
      "process 10500 peaks takes 11.3 s\n",
      "process 10550 peaks takes 11.3 s\n",
      "process 10600 peaks takes 11.4 s\n",
      "process 10650 peaks takes 11.4 s\n",
      "process 10700 peaks takes 11.5 s\n",
      "process 10750 peaks takes 11.5 s\n",
      "process 10800 peaks takes 11.6 s\n",
      "process 10850 peaks takes 11.6 s\n",
      "process 10900 peaks takes 11.7 s\n",
      "process 10950 peaks takes 11.7 s\n",
      "process 11000 peaks takes 11.8 s\n",
      "process 11050 peaks takes 11.9 s\n",
      "process 11100 peaks takes 11.9 s\n",
      "process 11150 peaks takes 12.0 s\n",
      "process 11200 peaks takes 12.0 s\n",
      "process 11250 peaks takes 12.1 s\n",
      "process 11300 peaks takes 12.1 s\n",
      "process 11350 peaks takes 12.2 s\n",
      "process 11400 peaks takes 12.3 s\n",
      "process 11450 peaks takes 12.3 s\n",
      "process 11500 peaks takes 12.4 s\n",
      "process 11550 peaks takes 12.4 s\n",
      "process 11600 peaks takes 12.5 s\n",
      "process 11650 peaks takes 12.5 s\n",
      "process 11700 peaks takes 12.6 s\n",
      "process 11750 peaks takes 12.6 s\n",
      "process 11800 peaks takes 12.7 s\n",
      "process 11850 peaks takes 12.7 s\n",
      "process 11900 peaks takes 12.8 s\n",
      "process 11950 peaks takes 12.8 s\n",
      "process 12000 peaks takes 12.9 s\n",
      "process 12050 peaks takes 13.0 s\n",
      "process 12100 peaks takes 13.0 s\n",
      "process 12150 peaks takes 13.1 s\n",
      "process 12200 peaks takes 13.1 s\n",
      "process 12250 peaks takes 13.2 s\n",
      "process 12300 peaks takes 13.2 s\n",
      "process 12350 peaks takes 13.3 s\n",
      "process 12400 peaks takes 13.3 s\n",
      "process 12450 peaks takes 13.4 s\n",
      "process 12500 peaks takes 13.4 s\n",
      "process 12550 peaks takes 13.5 s\n",
      "process 12600 peaks takes 13.6 s\n",
      "process 12650 peaks takes 13.6 s\n",
      "process 12700 peaks takes 13.7 s\n",
      "process 12750 peaks takes 13.7 s\n",
      "process 12800 peaks takes 13.8 s\n",
      "process 12850 peaks takes 13.8 s\n",
      "process 12900 peaks takes 13.9 s\n",
      "process 12950 peaks takes 13.9 s\n",
      "process 13000 peaks takes 14.0 s\n",
      "process 13050 peaks takes 14.0 s\n",
      "process 13100 peaks takes 14.1 s\n",
      "process 13150 peaks takes 14.2 s\n",
      "process 13200 peaks takes 14.2 s\n",
      "process 13250 peaks takes 14.3 s\n",
      "process 13300 peaks takes 14.3 s\n",
      "process 13350 peaks takes 14.4 s\n",
      "process 13400 peaks takes 14.4 s\n",
      "process 13450 peaks takes 14.5 s\n",
      "process 13500 peaks takes 14.5 s\n",
      "process 13550 peaks takes 14.6 s\n",
      "process 13600 peaks takes 14.6 s\n",
      "process 13650 peaks takes 14.7 s\n",
      "process 13700 peaks takes 14.7 s\n",
      "process 13750 peaks takes 14.8 s\n",
      "process 13800 peaks takes 14.8 s\n",
      "process 13850 peaks takes 14.9 s\n",
      "process 13900 peaks takes 14.9 s\n",
      "process 13950 peaks takes 15.0 s\n",
      "process 14000 peaks takes 15.0 s\n",
      "process 14050 peaks takes 15.1 s\n",
      "process 14100 peaks takes 15.1 s\n",
      "process 14150 peaks takes 15.2 s\n",
      "process 14200 peaks takes 15.2 s\n",
      "process 14250 peaks takes 15.3 s\n",
      "process 14300 peaks takes 15.3 s\n",
      "process 14350 peaks takes 15.4 s\n",
      "process 14400 peaks takes 15.4 s\n",
      "process 14450 peaks takes 15.5 s\n",
      "process 14500 peaks takes 15.5 s\n",
      "process 14550 peaks takes 15.6 s\n",
      "process 14600 peaks takes 15.6 s\n",
      "process 14650 peaks takes 15.7 s\n",
      "process 14700 peaks takes 15.7 s\n",
      "process 14750 peaks takes 15.8 s\n",
      "process 14800 peaks takes 15.8 s\n",
      "process 14850 peaks takes 15.9 s\n",
      "process 14900 peaks takes 15.9 s\n",
      "process 14950 peaks takes 16.0 s\n",
      "\n",
      "train\n",
      "13501 270\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.0 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.3 s\n",
      "process 3500 peaks takes 3.3 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.4 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.5 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.6 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.7 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.8 s\n",
      "process 4100 peaks takes 3.9 s\n",
      "process 4150 peaks takes 3.9 s\n",
      "process 4200 peaks takes 4.0 s\n",
      "process 4250 peaks takes 4.0 s\n",
      "process 4300 peaks takes 4.1 s\n",
      "process 4350 peaks takes 4.1 s\n",
      "process 4400 peaks takes 4.1 s\n",
      "process 4450 peaks takes 4.2 s\n",
      "process 4500 peaks takes 4.2 s\n",
      "process 4550 peaks takes 4.3 s\n",
      "process 4600 peaks takes 4.3 s\n",
      "process 4650 peaks takes 4.4 s\n",
      "process 4700 peaks takes 4.4 s\n",
      "process 4750 peaks takes 4.4 s\n",
      "process 4800 peaks takes 4.5 s\n",
      "process 4850 peaks takes 4.5 s\n",
      "process 4900 peaks takes 4.6 s\n",
      "process 4950 peaks takes 4.6 s\n",
      "process 5000 peaks takes 4.7 s\n",
      "process 5050 peaks takes 4.7 s\n",
      "process 5100 peaks takes 4.7 s\n",
      "process 5150 peaks takes 4.8 s\n",
      "process 5200 peaks takes 4.8 s\n",
      "process 5250 peaks takes 4.9 s\n",
      "process 5300 peaks takes 4.9 s\n",
      "process 5350 peaks takes 5.0 s\n",
      "process 5400 peaks takes 5.0 s\n",
      "process 5450 peaks takes 5.1 s\n",
      "process 5500 peaks takes 5.1 s\n",
      "process 5550 peaks takes 5.1 s\n",
      "process 5600 peaks takes 5.2 s\n",
      "process 5650 peaks takes 5.2 s\n",
      "process 5700 peaks takes 5.3 s\n",
      "process 5750 peaks takes 5.3 s\n",
      "process 5800 peaks takes 5.4 s\n",
      "process 5850 peaks takes 5.4 s\n",
      "process 5900 peaks takes 5.5 s\n",
      "process 5950 peaks takes 5.5 s\n",
      "process 6000 peaks takes 5.6 s\n",
      "process 6050 peaks takes 5.6 s\n",
      "process 6100 peaks takes 5.7 s\n",
      "process 6150 peaks takes 5.7 s\n",
      "process 6200 peaks takes 5.8 s\n",
      "process 6250 peaks takes 5.8 s\n",
      "process 6300 peaks takes 5.9 s\n",
      "process 6350 peaks takes 5.9 s\n",
      "process 6400 peaks takes 6.0 s\n",
      "process 6450 peaks takes 6.0 s\n",
      "process 6500 peaks takes 6.1 s\n",
      "process 6550 peaks takes 6.1 s\n",
      "process 6600 peaks takes 6.2 s\n",
      "process 6650 peaks takes 6.2 s\n",
      "process 6700 peaks takes 6.2 s\n",
      "process 6750 peaks takes 6.3 s\n",
      "process 6800 peaks takes 6.4 s\n",
      "process 6850 peaks takes 6.5 s\n",
      "process 6900 peaks takes 6.5 s\n",
      "process 6950 peaks takes 6.6 s\n",
      "process 7000 peaks takes 6.6 s\n",
      "process 7050 peaks takes 6.7 s\n",
      "process 7100 peaks takes 6.7 s\n",
      "process 7150 peaks takes 6.7 s\n",
      "process 7200 peaks takes 6.8 s\n",
      "process 7250 peaks takes 6.8 s\n",
      "process 7300 peaks takes 6.9 s\n",
      "process 7350 peaks takes 6.9 s\n",
      "process 7400 peaks takes 7.0 s\n",
      "process 7450 peaks takes 7.0 s\n",
      "process 7500 peaks takes 7.1 s\n",
      "process 7550 peaks takes 7.1 s\n",
      "process 7600 peaks takes 7.1 s\n",
      "process 7650 peaks takes 7.2 s\n",
      "process 7700 peaks takes 7.2 s\n",
      "process 7750 peaks takes 7.3 s\n",
      "process 7800 peaks takes 7.3 s\n",
      "process 7850 peaks takes 7.3 s\n",
      "process 7900 peaks takes 7.4 s\n",
      "process 7950 peaks takes 7.4 s\n",
      "process 8000 peaks takes 7.5 s\n",
      "process 8050 peaks takes 7.5 s\n",
      "process 8100 peaks takes 7.6 s\n",
      "process 8150 peaks takes 7.6 s\n",
      "process 8200 peaks takes 7.7 s\n",
      "process 8250 peaks takes 7.7 s\n",
      "process 8300 peaks takes 7.7 s\n",
      "process 8350 peaks takes 7.8 s\n",
      "process 8400 peaks takes 7.8 s\n",
      "process 8450 peaks takes 7.9 s\n",
      "process 8500 peaks takes 7.9 s\n",
      "process 8550 peaks takes 8.0 s\n",
      "process 8600 peaks takes 8.0 s\n",
      "process 8650 peaks takes 8.1 s\n",
      "process 8700 peaks takes 8.1 s\n",
      "process 8750 peaks takes 8.1 s\n",
      "process 8800 peaks takes 8.2 s\n",
      "process 8850 peaks takes 8.2 s\n",
      "process 8900 peaks takes 8.3 s\n",
      "process 8950 peaks takes 8.3 s\n",
      "process 9000 peaks takes 8.3 s\n",
      "process 9050 peaks takes 8.4 s\n",
      "process 9100 peaks takes 8.4 s\n",
      "process 9150 peaks takes 8.5 s\n",
      "process 9200 peaks takes 8.5 s\n",
      "process 9250 peaks takes 8.6 s\n",
      "process 9300 peaks takes 8.6 s\n",
      "process 9350 peaks takes 8.7 s\n",
      "process 9400 peaks takes 8.7 s\n",
      "process 9450 peaks takes 8.8 s\n",
      "process 9500 peaks takes 8.8 s\n",
      "process 9550 peaks takes 8.9 s\n",
      "process 9600 peaks takes 8.9 s\n",
      "process 9650 peaks takes 9.0 s\n",
      "process 9700 peaks takes 9.0 s\n",
      "process 9750 peaks takes 9.1 s\n",
      "process 9800 peaks takes 9.1 s\n",
      "process 9850 peaks takes 9.2 s\n",
      "process 9900 peaks takes 9.2 s\n",
      "process 9950 peaks takes 9.3 s\n",
      "process 10000 peaks takes 9.3 s\n",
      "process 10050 peaks takes 9.4 s\n",
      "process 10100 peaks takes 9.4 s\n",
      "process 10150 peaks takes 9.5 s\n",
      "process 10200 peaks takes 9.5 s\n",
      "process 10250 peaks takes 9.6 s\n",
      "process 10300 peaks takes 9.6 s\n",
      "process 10350 peaks takes 9.7 s\n",
      "process 10400 peaks takes 9.7 s\n",
      "process 10450 peaks takes 9.8 s\n",
      "process 10500 peaks takes 9.8 s\n",
      "process 10550 peaks takes 9.8 s\n",
      "process 10600 peaks takes 9.9 s\n",
      "process 10650 peaks takes 9.9 s\n",
      "process 10700 peaks takes 10.0 s\n",
      "process 10750 peaks takes 10.0 s\n",
      "process 10800 peaks takes 10.1 s\n",
      "process 10850 peaks takes 10.2 s\n",
      "process 10900 peaks takes 10.2 s\n",
      "process 10950 peaks takes 10.3 s\n",
      "process 11000 peaks takes 10.3 s\n",
      "process 11050 peaks takes 10.4 s\n",
      "process 11100 peaks takes 10.4 s\n",
      "process 11150 peaks takes 10.5 s\n",
      "process 11200 peaks takes 10.5 s\n",
      "process 11250 peaks takes 10.6 s\n",
      "process 11300 peaks takes 10.6 s\n",
      "process 11350 peaks takes 10.7 s\n",
      "process 11400 peaks takes 10.7 s\n",
      "process 11450 peaks takes 10.8 s\n",
      "process 11500 peaks takes 10.8 s\n",
      "process 11550 peaks takes 10.9 s\n",
      "process 11600 peaks takes 10.9 s\n",
      "process 11650 peaks takes 11.0 s\n",
      "process 11700 peaks takes 11.0 s\n",
      "process 11750 peaks takes 11.1 s\n",
      "process 11800 peaks takes 11.1 s\n",
      "process 11850 peaks takes 11.2 s\n",
      "process 11900 peaks takes 11.2 s\n",
      "process 11950 peaks takes 11.2 s\n",
      "process 12000 peaks takes 11.3 s\n",
      "process 12050 peaks takes 11.3 s\n",
      "process 12100 peaks takes 11.4 s\n",
      "process 12150 peaks takes 11.4 s\n",
      "process 12200 peaks takes 11.5 s\n",
      "process 12250 peaks takes 11.5 s\n",
      "process 12300 peaks takes 11.5 s\n",
      "process 12350 peaks takes 11.6 s\n",
      "process 12400 peaks takes 11.6 s\n",
      "process 12450 peaks takes 11.7 s\n",
      "process 12500 peaks takes 11.7 s\n",
      "process 12550 peaks takes 11.8 s\n",
      "process 12600 peaks takes 11.8 s\n",
      "process 12650 peaks takes 11.9 s\n",
      "process 12700 peaks takes 11.9 s\n",
      "process 12750 peaks takes 12.0 s\n",
      "process 12800 peaks takes 12.0 s\n",
      "process 12850 peaks takes 12.0 s\n",
      "process 12900 peaks takes 12.1 s\n",
      "process 12950 peaks takes 12.1 s\n",
      "process 13000 peaks takes 12.2 s\n",
      "process 13050 peaks takes 12.2 s\n",
      "process 13100 peaks takes 12.3 s\n",
      "process 13150 peaks takes 12.3 s\n",
      "process 13200 peaks takes 12.3 s\n",
      "process 13250 peaks takes 12.4 s\n",
      "process 13300 peaks takes 12.4 s\n",
      "process 13350 peaks takes 12.5 s\n",
      "process 13400 peaks takes 12.5 s\n",
      "process 13450 peaks takes 12.6 s\n",
      "\n",
      "test\n",
      "750 15\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "\n",
      "val\n",
      "749 14\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:31:23.519017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:31:23.613359: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:31:23.616233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:23.616265: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:31:24.099492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:24.099552: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:24.099558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.6GB.\n",
      "2024-05-13 06:31:26.128756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:31:26.128866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.128934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.128978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.129021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.129066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.129109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.129151: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.129194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:31:26.129211: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:31:26.129541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5000)      165000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,684,810\n",
      "Trainable params: 4,678,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "106/106 [==============================] - 185s 2s/step - loss: 0.2776 - auc: 0.6294 - auc_1: 0.1112 - val_loss: 0.2476 - val_auc: 0.6849 - val_auc_1: 0.1867\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 06:34:36.042901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:34:36.148794: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:34:36.151817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:34:36.151850: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:34:36.653015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:34:36.653123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:34:36.653156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.2 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.3 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.5 s\n",
      "process 2750 peaks takes 2.5 s\n",
      "process 2800 peaks takes 2.6 s\n",
      "process 2850 peaks takes 2.6 s\n",
      "process 2900 peaks takes 2.7 s\n",
      "process 2950 peaks takes 2.7 s\n",
      "process 3000 peaks takes 2.7 s\n",
      "process 3050 peaks takes 2.8 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.9 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 2.9 s\n",
      "process 3300 peaks takes 3.0 s\n",
      "process 3350 peaks takes 3.0 s\n",
      "process 3400 peaks takes 3.1 s\n",
      "process 3450 peaks takes 3.1 s\n",
      "process 3500 peaks takes 3.1 s\n",
      "process 3550 peaks takes 3.2 s\n",
      "process 3600 peaks takes 3.2 s\n",
      "process 3650 peaks takes 3.3 s\n",
      "process 3700 peaks takes 3.3 s\n",
      "process 3750 peaks takes 3.4 s\n",
      "process 3800 peaks takes 3.4 s\n",
      "process 3850 peaks takes 3.4 s\n",
      "process 3900 peaks takes 3.5 s\n",
      "process 3950 peaks takes 3.5 s\n",
      "process 4000 peaks takes 3.6 s\n",
      "process 4050 peaks takes 3.6 s\n",
      "process 4100 peaks takes 3.7 s\n",
      "process 4150 peaks takes 3.7 s\n",
      "process 4200 peaks takes 3.7 s\n",
      "process 4250 peaks takes 3.8 s\n",
      "process 4300 peaks takes 3.8 s\n",
      "process 4350 peaks takes 3.9 s\n",
      "process 4400 peaks takes 3.9 s\n",
      "process 4450 peaks takes 4.0 s\n",
      "process 4500 peaks takes 4.0 s\n",
      "process 4550 peaks takes 4.1 s\n",
      "process 4600 peaks takes 4.1 s\n",
      "process 4650 peaks takes 4.1 s\n",
      "process 4700 peaks takes 4.2 s\n",
      "process 4750 peaks takes 4.2 s\n",
      "process 4800 peaks takes 4.3 s\n",
      "process 4850 peaks takes 4.3 s\n",
      "process 4900 peaks takes 4.3 s\n",
      "process 4950 peaks takes 4.4 s\n",
      "process 5000 peaks takes 4.4 s\n",
      "process 5050 peaks takes 4.5 s\n",
      "process 5100 peaks takes 4.5 s\n",
      "process 5150 peaks takes 4.6 s\n",
      "process 5200 peaks takes 4.6 s\n",
      "process 5250 peaks takes 4.6 s\n",
      "process 5300 peaks takes 4.7 s\n",
      "process 5350 peaks takes 4.7 s\n",
      "process 5400 peaks takes 4.8 s\n",
      "process 5450 peaks takes 4.8 s\n",
      "process 5500 peaks takes 4.8 s\n",
      "process 5550 peaks takes 4.9 s\n",
      "process 5600 peaks takes 4.9 s\n",
      "process 5650 peaks takes 5.0 s\n",
      "process 5700 peaks takes 5.0 s\n",
      "process 5750 peaks takes 5.1 s\n",
      "process 5800 peaks takes 5.1 s\n",
      "process 5850 peaks takes 5.2 s\n",
      "process 5900 peaks takes 5.2 s\n",
      "process 5950 peaks takes 5.2 s\n",
      "process 6000 peaks takes 5.3 s\n",
      "process 6050 peaks takes 5.3 s\n",
      "process 6100 peaks takes 5.4 s\n",
      "process 6150 peaks takes 5.4 s\n",
      "process 6200 peaks takes 5.4 s\n",
      "process 6250 peaks takes 5.5 s\n",
      "process 6300 peaks takes 5.5 s\n",
      "process 6350 peaks takes 5.6 s\n",
      "process 6400 peaks takes 5.6 s\n",
      "process 6450 peaks takes 5.6 s\n",
      "process 6500 peaks takes 5.7 s\n",
      "process 6550 peaks takes 5.7 s\n",
      "process 6600 peaks takes 5.8 s\n",
      "process 6650 peaks takes 5.8 s\n",
      "process 6700 peaks takes 5.9 s\n",
      "process 6750 peaks takes 5.9 s\n",
      "process 6800 peaks takes 5.9 s\n",
      "process 6850 peaks takes 6.0 s\n",
      "process 6900 peaks takes 6.0 s\n",
      "process 6950 peaks takes 6.1 s\n",
      "process 7000 peaks takes 6.1 s\n",
      "process 7050 peaks takes 6.2 s\n",
      "process 7100 peaks takes 6.2 s\n",
      "process 7150 peaks takes 6.2 s\n",
      "process 7200 peaks takes 6.3 s\n",
      "process 7250 peaks takes 6.3 s\n",
      "process 7300 peaks takes 6.4 s\n",
      "process 7350 peaks takes 6.4 s\n",
      "process 7400 peaks takes 6.5 s\n",
      "process 7450 peaks takes 6.5 s\n",
      "process 7500 peaks takes 6.5 s\n",
      "process 7550 peaks takes 6.6 s\n",
      "process 7600 peaks takes 6.6 s\n",
      "process 7650 peaks takes 6.7 s\n",
      "process 7700 peaks takes 6.7 s\n",
      "process 7750 peaks takes 6.7 s\n",
      "process 7800 peaks takes 6.8 s\n",
      "process 7850 peaks takes 6.8 s\n",
      "process 7900 peaks takes 6.9 s\n",
      "process 7950 peaks takes 6.9 s\n",
      "process 8000 peaks takes 6.9 s\n",
      "process 8050 peaks takes 7.0 s\n",
      "process 8100 peaks takes 7.0 s\n",
      "process 8150 peaks takes 7.1 s\n",
      "process 8200 peaks takes 7.1 s\n",
      "process 8250 peaks takes 7.2 s\n",
      "process 8300 peaks takes 7.2 s\n",
      "process 8350 peaks takes 7.2 s\n",
      "process 8400 peaks takes 7.3 s\n",
      "process 8450 peaks takes 7.3 s\n",
      "process 8500 peaks takes 7.4 s\n",
      "process 8550 peaks takes 7.4 s\n",
      "process 8600 peaks takes 7.5 s\n",
      "process 8650 peaks takes 7.5 s\n",
      "process 8700 peaks takes 7.5 s\n",
      "process 8750 peaks takes 7.6 s\n",
      "process 8800 peaks takes 7.6 s\n",
      "process 8850 peaks takes 7.7 s\n",
      "process 8900 peaks takes 7.7 s\n",
      "process 8950 peaks takes 7.8 s\n",
      "process 9000 peaks takes 7.8 s\n",
      "process 9050 peaks takes 7.9 s\n",
      "process 9100 peaks takes 7.9 s\n",
      "process 9150 peaks takes 7.9 s\n",
      "process 9200 peaks takes 8.0 s\n",
      "process 9250 peaks takes 8.0 s\n",
      "process 9300 peaks takes 8.1 s\n",
      "process 9350 peaks takes 8.1 s\n",
      "process 9400 peaks takes 8.1 s\n",
      "process 9450 peaks takes 8.2 s\n",
      "process 9500 peaks takes 8.2 s\n",
      "process 9550 peaks takes 8.3 s\n",
      "process 9600 peaks takes 8.3 s\n",
      "process 9650 peaks takes 8.3 s\n",
      "process 9700 peaks takes 8.4 s\n",
      "process 9750 peaks takes 8.4 s\n",
      "process 9800 peaks takes 8.5 s\n",
      "process 9850 peaks takes 8.5 s\n",
      "process 9900 peaks takes 8.5 s\n",
      "process 9950 peaks takes 8.6 s\n",
      "process 10000 peaks takes 8.6 s\n",
      "process 10050 peaks takes 8.7 s\n",
      "process 10100 peaks takes 8.7 s\n",
      "process 10150 peaks takes 8.7 s\n",
      "process 10200 peaks takes 8.8 s\n",
      "process 10250 peaks takes 8.8 s\n",
      "process 10300 peaks takes 8.8 s\n",
      "process 10350 peaks takes 8.9 s\n",
      "process 10400 peaks takes 8.9 s\n",
      "process 10450 peaks takes 9.0 s\n",
      "process 10500 peaks takes 9.0 s\n",
      "process 10550 peaks takes 9.1 s\n",
      "process 10600 peaks takes 9.1 s\n",
      "process 10650 peaks takes 9.1 s\n",
      "process 10700 peaks takes 9.2 s\n",
      "process 10750 peaks takes 9.2 s\n",
      "process 10800 peaks takes 9.3 s\n",
      "process 10850 peaks takes 9.3 s\n",
      "process 10900 peaks takes 9.3 s\n",
      "process 10950 peaks takes 9.4 s\n",
      "process 11000 peaks takes 9.4 s\n",
      "process 11050 peaks takes 9.5 s\n",
      "process 11100 peaks takes 9.5 s\n",
      "process 11150 peaks takes 9.6 s\n",
      "process 11200 peaks takes 9.6 s\n",
      "process 11250 peaks takes 9.6 s\n",
      "process 11300 peaks takes 9.7 s\n",
      "process 11350 peaks takes 9.7 s\n",
      "process 11400 peaks takes 9.8 s\n",
      "process 11450 peaks takes 9.8 s\n",
      "process 11500 peaks takes 9.8 s\n",
      "process 11550 peaks takes 9.9 s\n",
      "process 11600 peaks takes 9.9 s\n",
      "process 11650 peaks takes 10.0 s\n",
      "process 11700 peaks takes 10.0 s\n",
      "process 11750 peaks takes 10.0 s\n",
      "process 11800 peaks takes 10.1 s\n",
      "process 11850 peaks takes 10.1 s\n",
      "process 11900 peaks takes 10.2 s\n",
      "process 11950 peaks takes 10.2 s\n",
      "process 12000 peaks takes 10.3 s\n",
      "process 12050 peaks takes 10.3 s\n",
      "process 12100 peaks takes 10.3 s\n",
      "process 12150 peaks takes 10.4 s\n",
      "process 12200 peaks takes 10.4 s\n",
      "process 12250 peaks takes 10.5 s\n",
      "process 12300 peaks takes 10.5 s\n",
      "process 12350 peaks takes 10.6 s\n",
      "process 12400 peaks takes 10.6 s\n",
      "process 12450 peaks takes 10.6 s\n",
      "process 12500 peaks takes 10.7 s\n",
      "process 12550 peaks takes 10.7 s\n",
      "process 12600 peaks takes 10.8 s\n",
      "process 12650 peaks takes 10.8 s\n",
      "process 12700 peaks takes 10.8 s\n",
      "process 12750 peaks takes 10.9 s\n",
      "process 12800 peaks takes 10.9 s\n",
      "process 12850 peaks takes 11.0 s\n",
      "process 12900 peaks takes 11.0 s\n",
      "process 12950 peaks takes 11.0 s\n",
      "process 13000 peaks takes 11.1 s\n",
      "process 13050 peaks takes 11.1 s\n",
      "process 13100 peaks takes 11.2 s\n",
      "process 13150 peaks takes 11.2 s\n",
      "process 13200 peaks takes 11.3 s\n",
      "process 13250 peaks takes 11.3 s\n",
      "process 13300 peaks takes 11.4 s\n",
      "process 13350 peaks takes 11.4 s\n",
      "process 13400 peaks takes 11.4 s\n",
      "process 13450 peaks takes 11.5 s\n",
      "process 13500 peaks takes 11.5 s\n",
      "process 13550 peaks takes 11.5 s\n",
      "process 13600 peaks takes 11.6 s\n",
      "process 13650 peaks takes 11.6 s\n",
      "process 13700 peaks takes 11.7 s\n",
      "process 13750 peaks takes 11.7 s\n",
      "process 13800 peaks takes 11.8 s\n",
      "process 13850 peaks takes 11.8 s\n",
      "process 13900 peaks takes 11.8 s\n",
      "process 13950 peaks takes 11.9 s\n",
      "process 14000 peaks takes 11.9 s\n",
      "process 14050 peaks takes 12.0 s\n",
      "process 14100 peaks takes 12.0 s\n",
      "process 14150 peaks takes 12.1 s\n",
      "process 14200 peaks takes 12.1 s\n",
      "process 14250 peaks takes 12.1 s\n",
      "process 14300 peaks takes 12.2 s\n",
      "process 14350 peaks takes 12.2 s\n",
      "process 14400 peaks takes 12.3 s\n",
      "process 14450 peaks takes 12.3 s\n",
      "process 14500 peaks takes 12.3 s\n",
      "process 14550 peaks takes 12.4 s\n",
      "process 14600 peaks takes 12.4 s\n",
      "process 14650 peaks takes 12.5 s\n",
      "process 14700 peaks takes 12.5 s\n",
      "process 14750 peaks takes 12.6 s\n",
      "process 14800 peaks takes 12.6 s\n",
      "process 14850 peaks takes 12.6 s\n",
      "process 14900 peaks takes 12.7 s\n",
      "process 14950 peaks takes 12.7 s\n",
      "\n",
      "train\n",
      "13501 270\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.3 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.6 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.7 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.8 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.0 s\n",
      "process 3200 peaks takes 3.0 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.1 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.3 s\n",
      "process 3500 peaks takes 3.3 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.4 s\n",
      "process 3650 peaks takes 3.4 s\n",
      "process 3700 peaks takes 3.5 s\n",
      "process 3750 peaks takes 3.5 s\n",
      "process 3800 peaks takes 3.6 s\n",
      "process 3850 peaks takes 3.6 s\n",
      "process 3900 peaks takes 3.7 s\n",
      "process 3950 peaks takes 3.7 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.8 s\n",
      "process 4100 peaks takes 3.8 s\n",
      "process 4150 peaks takes 3.9 s\n",
      "process 4200 peaks takes 3.9 s\n",
      "process 4250 peaks takes 4.0 s\n",
      "process 4300 peaks takes 4.0 s\n",
      "process 4350 peaks takes 4.1 s\n",
      "process 4400 peaks takes 4.1 s\n",
      "process 4450 peaks takes 4.1 s\n",
      "process 4500 peaks takes 4.2 s\n",
      "process 4550 peaks takes 4.2 s\n",
      "process 4600 peaks takes 4.3 s\n",
      "process 4650 peaks takes 4.3 s\n",
      "process 4700 peaks takes 4.3 s\n",
      "process 4750 peaks takes 4.4 s\n",
      "process 4800 peaks takes 4.4 s\n",
      "process 4850 peaks takes 4.5 s\n",
      "process 4900 peaks takes 4.5 s\n",
      "process 4950 peaks takes 4.6 s\n",
      "process 5000 peaks takes 4.6 s\n",
      "process 5050 peaks takes 4.7 s\n",
      "process 5100 peaks takes 4.7 s\n",
      "process 5150 peaks takes 4.7 s\n",
      "process 5200 peaks takes 4.8 s\n",
      "process 5250 peaks takes 4.8 s\n",
      "process 5300 peaks takes 4.9 s\n",
      "process 5350 peaks takes 4.9 s\n",
      "process 5400 peaks takes 4.9 s\n",
      "process 5450 peaks takes 5.0 s\n",
      "process 5500 peaks takes 5.0 s\n",
      "process 5550 peaks takes 5.1 s\n",
      "process 5600 peaks takes 5.1 s\n",
      "process 5650 peaks takes 5.2 s\n",
      "process 5700 peaks takes 5.2 s\n",
      "process 5750 peaks takes 5.3 s\n",
      "process 5800 peaks takes 5.3 s\n",
      "process 5850 peaks takes 5.4 s\n",
      "process 5900 peaks takes 5.4 s\n",
      "process 5950 peaks takes 5.5 s\n",
      "process 6000 peaks takes 5.5 s\n",
      "process 6050 peaks takes 5.6 s\n",
      "process 6100 peaks takes 5.6 s\n",
      "process 6150 peaks takes 5.6 s\n",
      "process 6200 peaks takes 5.7 s\n",
      "process 6250 peaks takes 5.7 s\n",
      "process 6300 peaks takes 5.8 s\n",
      "process 6350 peaks takes 5.8 s\n",
      "process 6400 peaks takes 5.9 s\n",
      "process 6450 peaks takes 5.9 s\n",
      "process 6500 peaks takes 6.0 s\n",
      "process 6550 peaks takes 6.0 s\n",
      "process 6600 peaks takes 6.1 s\n",
      "process 6650 peaks takes 6.1 s\n",
      "process 6700 peaks takes 6.2 s\n",
      "process 6750 peaks takes 6.2 s\n",
      "process 6800 peaks takes 6.2 s\n",
      "process 6850 peaks takes 6.3 s\n",
      "process 6900 peaks takes 6.4 s\n",
      "process 6950 peaks takes 6.4 s\n",
      "process 7000 peaks takes 6.4 s\n",
      "process 7050 peaks takes 6.5 s\n",
      "process 7100 peaks takes 6.5 s\n",
      "process 7150 peaks takes 6.6 s\n",
      "process 7200 peaks takes 6.6 s\n",
      "process 7250 peaks takes 6.7 s\n",
      "process 7300 peaks takes 6.7 s\n",
      "process 7350 peaks takes 6.8 s\n",
      "process 7400 peaks takes 6.8 s\n",
      "process 7450 peaks takes 6.9 s\n",
      "process 7500 peaks takes 6.9 s\n",
      "process 7550 peaks takes 7.0 s\n",
      "process 7600 peaks takes 7.0 s\n",
      "process 7650 peaks takes 7.1 s\n",
      "process 7700 peaks takes 7.1 s\n",
      "process 7750 peaks takes 7.1 s\n",
      "process 7800 peaks takes 7.2 s\n",
      "process 7850 peaks takes 7.3 s\n",
      "process 7900 peaks takes 7.3 s\n",
      "process 7950 peaks takes 7.3 s\n",
      "process 8000 peaks takes 7.4 s\n",
      "process 8050 peaks takes 7.4 s\n",
      "process 8100 peaks takes 7.5 s\n",
      "process 8150 peaks takes 7.5 s\n",
      "process 8200 peaks takes 7.6 s\n",
      "process 8250 peaks takes 7.6 s\n",
      "process 8300 peaks takes 7.7 s\n",
      "process 8350 peaks takes 7.7 s\n",
      "process 8400 peaks takes 7.7 s\n",
      "process 8450 peaks takes 7.8 s\n",
      "process 8500 peaks takes 7.8 s\n",
      "process 8550 peaks takes 7.9 s\n",
      "process 8600 peaks takes 7.9 s\n",
      "process 8650 peaks takes 8.0 s\n",
      "process 8700 peaks takes 8.0 s\n",
      "process 8750 peaks takes 8.1 s\n",
      "process 8800 peaks takes 8.1 s\n",
      "process 8850 peaks takes 8.1 s\n",
      "process 8900 peaks takes 8.2 s\n",
      "process 8950 peaks takes 8.2 s\n",
      "process 9000 peaks takes 8.3 s\n",
      "process 9050 peaks takes 8.3 s\n",
      "process 9100 peaks takes 8.4 s\n",
      "process 9150 peaks takes 8.4 s\n",
      "process 9200 peaks takes 8.5 s\n",
      "process 9250 peaks takes 8.5 s\n",
      "process 9300 peaks takes 8.5 s\n",
      "process 9350 peaks takes 8.6 s\n",
      "process 9400 peaks takes 8.6 s\n",
      "process 9450 peaks takes 8.7 s\n",
      "process 9500 peaks takes 8.7 s\n",
      "process 9550 peaks takes 8.8 s\n",
      "process 9600 peaks takes 8.8 s\n",
      "process 9650 peaks takes 8.9 s\n",
      "process 9700 peaks takes 8.9 s\n",
      "process 9750 peaks takes 8.9 s\n",
      "process 9800 peaks takes 9.0 s\n",
      "process 9850 peaks takes 9.0 s\n",
      "process 9900 peaks takes 9.1 s\n",
      "process 9950 peaks takes 9.1 s\n",
      "process 10000 peaks takes 9.2 s\n",
      "process 10050 peaks takes 9.2 s\n",
      "process 10100 peaks takes 9.2 s\n",
      "process 10150 peaks takes 9.3 s\n",
      "process 10200 peaks takes 9.3 s\n",
      "process 10250 peaks takes 9.4 s\n",
      "process 10300 peaks takes 9.4 s\n",
      "process 10350 peaks takes 9.5 s\n",
      "process 10400 peaks takes 9.5 s\n",
      "process 10450 peaks takes 9.5 s\n",
      "process 10500 peaks takes 9.6 s\n",
      "process 10550 peaks takes 9.6 s\n",
      "process 10600 peaks takes 9.7 s\n",
      "process 10650 peaks takes 9.7 s\n",
      "process 10700 peaks takes 9.7 s\n",
      "process 10750 peaks takes 9.8 s\n",
      "process 10800 peaks takes 9.8 s\n",
      "process 10850 peaks takes 9.9 s\n",
      "process 10900 peaks takes 9.9 s\n",
      "process 10950 peaks takes 10.0 s\n",
      "process 11000 peaks takes 10.0 s\n",
      "process 11050 peaks takes 10.1 s\n",
      "process 11100 peaks takes 10.1 s\n",
      "process 11150 peaks takes 10.1 s\n",
      "process 11200 peaks takes 10.2 s\n",
      "process 11250 peaks takes 10.2 s\n",
      "process 11300 peaks takes 10.3 s\n",
      "process 11350 peaks takes 10.3 s\n",
      "process 11400 peaks takes 10.4 s\n",
      "process 11450 peaks takes 10.4 s\n",
      "process 11500 peaks takes 10.5 s\n",
      "process 11550 peaks takes 10.5 s\n",
      "process 11600 peaks takes 10.6 s\n",
      "process 11650 peaks takes 10.6 s\n",
      "process 11700 peaks takes 10.7 s\n",
      "process 11750 peaks takes 10.7 s\n",
      "process 11800 peaks takes 10.7 s\n",
      "process 11850 peaks takes 10.8 s\n",
      "process 11900 peaks takes 10.8 s\n",
      "process 11950 peaks takes 10.9 s\n",
      "process 12000 peaks takes 10.9 s\n",
      "process 12050 peaks takes 11.0 s\n",
      "process 12100 peaks takes 11.0 s\n",
      "process 12150 peaks takes 11.1 s\n",
      "process 12200 peaks takes 11.1 s\n",
      "process 12250 peaks takes 11.1 s\n",
      "process 12300 peaks takes 11.2 s\n",
      "process 12350 peaks takes 11.2 s\n",
      "process 12400 peaks takes 11.3 s\n",
      "process 12450 peaks takes 11.3 s\n",
      "process 12500 peaks takes 11.4 s\n",
      "process 12550 peaks takes 11.4 s\n",
      "process 12600 peaks takes 11.5 s\n",
      "process 12650 peaks takes 11.5 s\n",
      "process 12700 peaks takes 11.6 s\n",
      "process 12750 peaks takes 11.6 s\n",
      "process 12800 peaks takes 11.6 s\n",
      "process 12850 peaks takes 11.7 s\n",
      "process 12900 peaks takes 11.7 s\n",
      "process 12950 peaks takes 11.8 s\n",
      "process 13000 peaks takes 11.8 s\n",
      "process 13050 peaks takes 11.9 s\n",
      "process 13100 peaks takes 11.9 s\n",
      "process 13150 peaks takes 12.0 s\n",
      "process 13200 peaks takes 12.0 s\n",
      "process 13250 peaks takes 12.0 s\n",
      "process 13300 peaks takes 12.1 s\n",
      "process 13350 peaks takes 12.2 s\n",
      "process 13400 peaks takes 12.2 s\n",
      "process 13450 peaks takes 12.2 s\n",
      "\n",
      "test\n",
      "750 15\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "\n",
      "val\n",
      "749 14\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:35:06.274842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:35:06.381328: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:35:06.384303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:06.384330: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:35:06.887657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:06.887754: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:06.887778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.6GB.\n",
      "2024-05-13 06:35:09.003595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:35:09.003712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.003780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.003823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.003866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.003910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.003955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.003996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.004038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:35:09.004056: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:35:09.004392: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5000)      165000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,684,810\n",
      "Trainable params: 4,678,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "106/106 [==============================] - 183s 2s/step - loss: 0.3017 - auc: 0.6150 - auc_1: 0.1033 - val_loss: 0.2350 - val_auc: 0.6702 - val_auc_1: 0.2049\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad\n",
      "noack_2022 random /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs10000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad\n",
      "(5877, 30000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000 --batch 50\n",
      "2024-05-13 06:38:18.640763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:38:18.742648: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:38:18.745587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:38:18.745614: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:38:19.209422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:38:19.209499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:38:19.209506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[27001, 1500, 1499]\n",
      "30000 600\n",
      "process 0 peaks takes 0.4 s\n",
      "process 50 peaks takes 0.4 s\n",
      "process 100 peaks takes 0.5 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.6 s\n",
      "process 250 peaks takes 0.6 s\n",
      "process 300 peaks takes 0.7 s\n",
      "process 350 peaks takes 0.7 s\n",
      "process 400 peaks takes 0.8 s\n",
      "process 450 peaks takes 0.8 s\n",
      "process 500 peaks takes 0.9 s\n",
      "process 550 peaks takes 0.9 s\n",
      "process 600 peaks takes 1.0 s\n",
      "process 650 peaks takes 1.0 s\n",
      "process 700 peaks takes 1.1 s\n",
      "process 750 peaks takes 1.1 s\n",
      "process 800 peaks takes 1.2 s\n",
      "process 850 peaks takes 1.2 s\n",
      "process 900 peaks takes 1.3 s\n",
      "process 950 peaks takes 1.3 s\n",
      "process 1000 peaks takes 1.4 s\n",
      "process 1050 peaks takes 1.4 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.5 s\n",
      "process 1250 peaks takes 1.6 s\n",
      "process 1300 peaks takes 1.6 s\n",
      "process 1350 peaks takes 1.7 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.8 s\n",
      "process 1500 peaks takes 1.9 s\n",
      "process 1550 peaks takes 1.9 s\n",
      "process 1600 peaks takes 2.0 s\n",
      "process 1650 peaks takes 2.0 s\n",
      "process 1700 peaks takes 2.1 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.2 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.3 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.4 s\n",
      "process 2050 peaks takes 2.5 s\n",
      "process 2100 peaks takes 2.5 s\n",
      "process 2150 peaks takes 2.6 s\n",
      "process 2200 peaks takes 2.6 s\n",
      "process 2250 peaks takes 2.7 s\n",
      "process 2300 peaks takes 2.7 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.8 s\n",
      "process 2450 peaks takes 2.9 s\n",
      "process 2500 peaks takes 2.9 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 3.0 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "process 2700 peaks takes 3.1 s\n",
      "process 2750 peaks takes 3.2 s\n",
      "process 2800 peaks takes 3.2 s\n",
      "process 2850 peaks takes 3.3 s\n",
      "process 2900 peaks takes 3.3 s\n",
      "process 2950 peaks takes 3.4 s\n",
      "process 3000 peaks takes 3.4 s\n",
      "process 3050 peaks takes 3.5 s\n",
      "process 3100 peaks takes 3.5 s\n",
      "process 3150 peaks takes 3.6 s\n",
      "process 3200 peaks takes 3.6 s\n",
      "process 3250 peaks takes 3.7 s\n",
      "process 3300 peaks takes 3.7 s\n",
      "process 3350 peaks takes 3.8 s\n",
      "process 3400 peaks takes 3.8 s\n",
      "process 3450 peaks takes 3.9 s\n",
      "process 3500 peaks takes 3.9 s\n",
      "process 3550 peaks takes 4.0 s\n",
      "process 3600 peaks takes 4.0 s\n",
      "process 3650 peaks takes 4.1 s\n",
      "process 3700 peaks takes 4.1 s\n",
      "process 3750 peaks takes 4.2 s\n",
      "process 3800 peaks takes 4.2 s\n",
      "process 3850 peaks takes 4.3 s\n",
      "process 3900 peaks takes 4.3 s\n",
      "process 3950 peaks takes 4.4 s\n",
      "process 4000 peaks takes 4.4 s\n",
      "process 4050 peaks takes 4.5 s\n",
      "process 4100 peaks takes 4.5 s\n",
      "process 4150 peaks takes 4.6 s\n",
      "process 4200 peaks takes 4.6 s\n",
      "process 4250 peaks takes 4.7 s\n",
      "process 4300 peaks takes 4.7 s\n",
      "process 4350 peaks takes 4.8 s\n",
      "process 4400 peaks takes 4.8 s\n",
      "process 4450 peaks takes 4.9 s\n",
      "process 4500 peaks takes 4.9 s\n",
      "process 4550 peaks takes 5.0 s\n",
      "process 4600 peaks takes 5.1 s\n",
      "process 4650 peaks takes 5.1 s\n",
      "process 4700 peaks takes 5.2 s\n",
      "process 4750 peaks takes 5.2 s\n",
      "process 4800 peaks takes 5.3 s\n",
      "process 4850 peaks takes 5.3 s\n",
      "process 4900 peaks takes 5.4 s\n",
      "process 4950 peaks takes 5.4 s\n",
      "process 5000 peaks takes 5.5 s\n",
      "process 5050 peaks takes 5.5 s\n",
      "process 5100 peaks takes 5.6 s\n",
      "process 5150 peaks takes 5.7 s\n",
      "process 5200 peaks takes 5.7 s\n",
      "process 5250 peaks takes 5.8 s\n",
      "process 5300 peaks takes 5.8 s\n",
      "process 5350 peaks takes 5.9 s\n",
      "process 5400 peaks takes 5.9 s\n",
      "process 5450 peaks takes 6.0 s\n",
      "process 5500 peaks takes 6.0 s\n",
      "process 5550 peaks takes 6.1 s\n",
      "process 5600 peaks takes 6.1 s\n",
      "process 5650 peaks takes 6.2 s\n",
      "process 5700 peaks takes 6.2 s\n",
      "process 5750 peaks takes 6.3 s\n",
      "process 5800 peaks takes 6.3 s\n",
      "process 5850 peaks takes 6.4 s\n",
      "process 5900 peaks takes 6.4 s\n",
      "process 5950 peaks takes 6.5 s\n",
      "process 6000 peaks takes 6.5 s\n",
      "process 6050 peaks takes 6.6 s\n",
      "process 6100 peaks takes 6.6 s\n",
      "process 6150 peaks takes 6.7 s\n",
      "process 6200 peaks takes 6.8 s\n",
      "process 6250 peaks takes 6.8 s\n",
      "process 6300 peaks takes 6.9 s\n",
      "process 6350 peaks takes 6.9 s\n",
      "process 6400 peaks takes 7.0 s\n",
      "process 6450 peaks takes 7.0 s\n",
      "process 6500 peaks takes 7.1 s\n",
      "process 6550 peaks takes 7.1 s\n",
      "process 6600 peaks takes 7.2 s\n",
      "process 6650 peaks takes 7.2 s\n",
      "process 6700 peaks takes 7.3 s\n",
      "process 6750 peaks takes 7.3 s\n",
      "process 6800 peaks takes 7.4 s\n",
      "process 6850 peaks takes 7.4 s\n",
      "process 6900 peaks takes 7.5 s\n",
      "process 6950 peaks takes 7.5 s\n",
      "process 7000 peaks takes 7.6 s\n",
      "process 7050 peaks takes 7.6 s\n",
      "process 7100 peaks takes 7.7 s\n",
      "process 7150 peaks takes 7.7 s\n",
      "process 7200 peaks takes 7.8 s\n",
      "process 7250 peaks takes 7.8 s\n",
      "process 7300 peaks takes 7.9 s\n",
      "process 7350 peaks takes 7.9 s\n",
      "process 7400 peaks takes 8.0 s\n",
      "process 7450 peaks takes 8.0 s\n",
      "process 7500 peaks takes 8.0 s\n",
      "process 7550 peaks takes 8.1 s\n",
      "process 7600 peaks takes 8.1 s\n",
      "process 7650 peaks takes 8.2 s\n",
      "process 7700 peaks takes 8.2 s\n",
      "process 7750 peaks takes 8.3 s\n",
      "process 7800 peaks takes 8.3 s\n",
      "process 7850 peaks takes 8.3 s\n",
      "process 7900 peaks takes 8.4 s\n",
      "process 7950 peaks takes 8.4 s\n",
      "process 8000 peaks takes 8.5 s\n",
      "process 8050 peaks takes 8.5 s\n",
      "process 8100 peaks takes 8.6 s\n",
      "process 8150 peaks takes 8.6 s\n",
      "process 8200 peaks takes 8.7 s\n",
      "process 8250 peaks takes 8.7 s\n",
      "process 8300 peaks takes 8.7 s\n",
      "process 8350 peaks takes 8.8 s\n",
      "process 8400 peaks takes 8.8 s\n",
      "process 8450 peaks takes 8.9 s\n",
      "process 8500 peaks takes 8.9 s\n",
      "process 8550 peaks takes 9.0 s\n",
      "process 8600 peaks takes 9.0 s\n",
      "process 8650 peaks takes 9.1 s\n",
      "process 8700 peaks takes 9.1 s\n",
      "process 8750 peaks takes 9.2 s\n",
      "process 8800 peaks takes 9.2 s\n",
      "process 8850 peaks takes 9.2 s\n",
      "process 8900 peaks takes 9.3 s\n",
      "process 8950 peaks takes 9.4 s\n",
      "process 9000 peaks takes 9.4 s\n",
      "process 9050 peaks takes 9.5 s\n",
      "process 9100 peaks takes 9.5 s\n",
      "process 9150 peaks takes 9.6 s\n",
      "process 9200 peaks takes 9.6 s\n",
      "process 9250 peaks takes 9.6 s\n",
      "process 9300 peaks takes 9.7 s\n",
      "process 9350 peaks takes 9.7 s\n",
      "process 9400 peaks takes 9.8 s\n",
      "process 9450 peaks takes 9.8 s\n",
      "process 9500 peaks takes 9.9 s\n",
      "process 9550 peaks takes 9.9 s\n",
      "process 9600 peaks takes 10.0 s\n",
      "process 9650 peaks takes 10.0 s\n",
      "process 9700 peaks takes 10.0 s\n",
      "process 9750 peaks takes 10.1 s\n",
      "process 9800 peaks takes 10.1 s\n",
      "process 9850 peaks takes 10.2 s\n",
      "process 9900 peaks takes 10.2 s\n",
      "process 9950 peaks takes 10.3 s\n",
      "process 10000 peaks takes 10.3 s\n",
      "process 10050 peaks takes 10.3 s\n",
      "process 10100 peaks takes 10.4 s\n",
      "process 10150 peaks takes 10.4 s\n",
      "process 10200 peaks takes 10.5 s\n",
      "process 10250 peaks takes 10.5 s\n",
      "process 10300 peaks takes 10.6 s\n",
      "process 10350 peaks takes 10.6 s\n",
      "process 10400 peaks takes 10.7 s\n",
      "process 10450 peaks takes 10.7 s\n",
      "process 10500 peaks takes 10.8 s\n",
      "process 10550 peaks takes 10.8 s\n",
      "process 10600 peaks takes 10.9 s\n",
      "process 10650 peaks takes 10.9 s\n",
      "process 10700 peaks takes 11.0 s\n",
      "process 10750 peaks takes 11.0 s\n",
      "process 10800 peaks takes 11.1 s\n",
      "process 10850 peaks takes 11.1 s\n",
      "process 10900 peaks takes 11.2 s\n",
      "process 10950 peaks takes 11.2 s\n",
      "process 11000 peaks takes 11.2 s\n",
      "process 11050 peaks takes 11.3 s\n",
      "process 11100 peaks takes 11.4 s\n",
      "process 11150 peaks takes 11.4 s\n",
      "process 11200 peaks takes 11.4 s\n",
      "process 11250 peaks takes 11.5 s\n",
      "process 11300 peaks takes 11.5 s\n",
      "process 11350 peaks takes 11.6 s\n",
      "process 11400 peaks takes 11.6 s\n",
      "process 11450 peaks takes 11.6 s\n",
      "process 11500 peaks takes 11.7 s\n",
      "process 11550 peaks takes 11.7 s\n",
      "process 11600 peaks takes 11.8 s\n",
      "process 11650 peaks takes 11.8 s\n",
      "process 11700 peaks takes 11.9 s\n",
      "process 11750 peaks takes 11.9 s\n",
      "process 11800 peaks takes 12.0 s\n",
      "process 11850 peaks takes 12.0 s\n",
      "process 11900 peaks takes 12.0 s\n",
      "process 11950 peaks takes 12.1 s\n",
      "process 12000 peaks takes 12.1 s\n",
      "process 12050 peaks takes 12.2 s\n",
      "process 12100 peaks takes 12.2 s\n",
      "process 12150 peaks takes 12.3 s\n",
      "process 12200 peaks takes 12.3 s\n",
      "process 12250 peaks takes 12.4 s\n",
      "process 12300 peaks takes 12.4 s\n",
      "process 12350 peaks takes 12.4 s\n",
      "process 12400 peaks takes 12.5 s\n",
      "process 12450 peaks takes 12.5 s\n",
      "process 12500 peaks takes 12.6 s\n",
      "process 12550 peaks takes 12.6 s\n",
      "process 12600 peaks takes 12.7 s\n",
      "process 12650 peaks takes 12.7 s\n",
      "process 12700 peaks takes 12.8 s\n",
      "process 12750 peaks takes 12.8 s\n",
      "process 12800 peaks takes 12.9 s\n",
      "process 12850 peaks takes 12.9 s\n",
      "process 12900 peaks takes 12.9 s\n",
      "process 12950 peaks takes 13.0 s\n",
      "process 13000 peaks takes 13.1 s\n",
      "process 13050 peaks takes 13.1 s\n",
      "process 13100 peaks takes 13.1 s\n",
      "process 13150 peaks takes 13.2 s\n",
      "process 13200 peaks takes 13.2 s\n",
      "process 13250 peaks takes 13.3 s\n",
      "process 13300 peaks takes 13.3 s\n",
      "process 13350 peaks takes 13.3 s\n",
      "process 13400 peaks takes 13.4 s\n",
      "process 13450 peaks takes 13.5 s\n",
      "process 13500 peaks takes 13.5 s\n",
      "process 13550 peaks takes 13.5 s\n",
      "process 13600 peaks takes 13.6 s\n",
      "process 13650 peaks takes 13.6 s\n",
      "process 13700 peaks takes 13.7 s\n",
      "process 13750 peaks takes 13.7 s\n",
      "process 13800 peaks takes 13.8 s\n",
      "process 13850 peaks takes 13.8 s\n",
      "process 13900 peaks takes 13.9 s\n",
      "process 13950 peaks takes 13.9 s\n",
      "process 14000 peaks takes 14.0 s\n",
      "process 14050 peaks takes 14.0 s\n",
      "process 14100 peaks takes 14.1 s\n",
      "process 14150 peaks takes 14.1 s\n",
      "process 14200 peaks takes 14.2 s\n",
      "process 14250 peaks takes 14.2 s\n",
      "process 14300 peaks takes 14.3 s\n",
      "process 14350 peaks takes 14.3 s\n",
      "process 14400 peaks takes 14.4 s\n",
      "process 14450 peaks takes 14.4 s\n",
      "process 14500 peaks takes 14.5 s\n",
      "process 14550 peaks takes 14.5 s\n",
      "process 14600 peaks takes 14.6 s\n",
      "process 14650 peaks takes 14.6 s\n",
      "process 14700 peaks takes 14.7 s\n",
      "process 14750 peaks takes 14.7 s\n",
      "process 14800 peaks takes 14.7 s\n",
      "process 14850 peaks takes 14.8 s\n",
      "process 14900 peaks takes 14.8 s\n",
      "process 14950 peaks takes 14.9 s\n",
      "process 15000 peaks takes 14.9 s\n",
      "process 15050 peaks takes 15.0 s\n",
      "process 15100 peaks takes 15.0 s\n",
      "process 15150 peaks takes 15.1 s\n",
      "process 15200 peaks takes 15.1 s\n",
      "process 15250 peaks takes 15.2 s\n",
      "process 15300 peaks takes 15.2 s\n",
      "process 15350 peaks takes 15.2 s\n",
      "process 15400 peaks takes 15.3 s\n",
      "process 15450 peaks takes 15.3 s\n",
      "process 15500 peaks takes 15.4 s\n",
      "process 15550 peaks takes 15.4 s\n",
      "process 15600 peaks takes 15.5 s\n",
      "process 15650 peaks takes 15.5 s\n",
      "process 15700 peaks takes 15.6 s\n",
      "process 15750 peaks takes 15.6 s\n",
      "process 15800 peaks takes 15.6 s\n",
      "process 15850 peaks takes 15.7 s\n",
      "process 15900 peaks takes 15.7 s\n",
      "process 15950 peaks takes 15.8 s\n",
      "process 16000 peaks takes 15.8 s\n",
      "process 16050 peaks takes 15.9 s\n",
      "process 16100 peaks takes 15.9 s\n",
      "process 16150 peaks takes 15.9 s\n",
      "process 16200 peaks takes 16.0 s\n",
      "process 16250 peaks takes 16.0 s\n",
      "process 16300 peaks takes 16.1 s\n",
      "process 16350 peaks takes 16.1 s\n",
      "process 16400 peaks takes 16.2 s\n",
      "process 16450 peaks takes 16.2 s\n",
      "process 16500 peaks takes 16.2 s\n",
      "process 16550 peaks takes 16.3 s\n",
      "process 16600 peaks takes 16.3 s\n",
      "process 16650 peaks takes 16.4 s\n",
      "process 16700 peaks takes 16.5 s\n",
      "process 16750 peaks takes 16.5 s\n",
      "process 16800 peaks takes 16.5 s\n",
      "process 16850 peaks takes 16.6 s\n",
      "process 16900 peaks takes 16.6 s\n",
      "process 16950 peaks takes 16.7 s\n",
      "process 17000 peaks takes 16.7 s\n",
      "process 17050 peaks takes 16.8 s\n",
      "process 17100 peaks takes 16.8 s\n",
      "process 17150 peaks takes 16.9 s\n",
      "process 17200 peaks takes 16.9 s\n",
      "process 17250 peaks takes 17.0 s\n",
      "process 17300 peaks takes 17.0 s\n",
      "process 17350 peaks takes 17.1 s\n",
      "process 17400 peaks takes 17.1 s\n",
      "process 17450 peaks takes 17.2 s\n",
      "process 17500 peaks takes 17.2 s\n",
      "process 17550 peaks takes 17.3 s\n",
      "process 17600 peaks takes 17.3 s\n",
      "process 17650 peaks takes 17.4 s\n",
      "process 17700 peaks takes 17.4 s\n",
      "process 17750 peaks takes 17.5 s\n",
      "process 17800 peaks takes 17.5 s\n",
      "process 17850 peaks takes 17.6 s\n",
      "process 17900 peaks takes 17.6 s\n",
      "process 17950 peaks takes 17.7 s\n",
      "process 18000 peaks takes 17.7 s\n",
      "process 18050 peaks takes 17.7 s\n",
      "process 18100 peaks takes 17.8 s\n",
      "process 18150 peaks takes 17.9 s\n",
      "process 18200 peaks takes 17.9 s\n",
      "process 18250 peaks takes 17.9 s\n",
      "process 18300 peaks takes 18.0 s\n",
      "process 18350 peaks takes 18.1 s\n",
      "process 18400 peaks takes 18.1 s\n",
      "process 18450 peaks takes 18.2 s\n",
      "process 18500 peaks takes 18.2 s\n",
      "process 18550 peaks takes 18.2 s\n",
      "process 18600 peaks takes 18.3 s\n",
      "process 18650 peaks takes 18.3 s\n",
      "process 18700 peaks takes 18.4 s\n",
      "process 18750 peaks takes 18.4 s\n",
      "process 18800 peaks takes 18.5 s\n",
      "process 18850 peaks takes 18.5 s\n",
      "process 18900 peaks takes 18.6 s\n",
      "process 18950 peaks takes 18.6 s\n",
      "process 19000 peaks takes 18.7 s\n",
      "process 19050 peaks takes 18.7 s\n",
      "process 19100 peaks takes 18.8 s\n",
      "process 19150 peaks takes 18.8 s\n",
      "process 19200 peaks takes 18.8 s\n",
      "process 19250 peaks takes 18.9 s\n",
      "process 19300 peaks takes 19.0 s\n",
      "process 19350 peaks takes 19.0 s\n",
      "process 19400 peaks takes 19.1 s\n",
      "process 19450 peaks takes 19.1 s\n",
      "process 19500 peaks takes 19.2 s\n",
      "process 19550 peaks takes 19.2 s\n",
      "process 19600 peaks takes 19.3 s\n",
      "process 19650 peaks takes 19.3 s\n",
      "process 19700 peaks takes 19.4 s\n",
      "process 19750 peaks takes 19.4 s\n",
      "process 19800 peaks takes 19.5 s\n",
      "process 19850 peaks takes 19.5 s\n",
      "process 19900 peaks takes 19.6 s\n",
      "process 19950 peaks takes 19.6 s\n",
      "process 20000 peaks takes 19.7 s\n",
      "process 20050 peaks takes 19.7 s\n",
      "process 20100 peaks takes 19.8 s\n",
      "process 20150 peaks takes 19.8 s\n",
      "process 20200 peaks takes 19.9 s\n",
      "process 20250 peaks takes 19.9 s\n",
      "process 20300 peaks takes 20.0 s\n",
      "process 20350 peaks takes 20.0 s\n",
      "process 20400 peaks takes 20.1 s\n",
      "process 20450 peaks takes 20.1 s\n",
      "process 20500 peaks takes 20.2 s\n",
      "process 20550 peaks takes 20.2 s\n",
      "process 20600 peaks takes 20.3 s\n",
      "process 20650 peaks takes 20.4 s\n",
      "process 20700 peaks takes 20.4 s\n",
      "process 20750 peaks takes 20.5 s\n",
      "process 20800 peaks takes 20.5 s\n",
      "process 20850 peaks takes 20.6 s\n",
      "process 20900 peaks takes 20.6 s\n",
      "process 20950 peaks takes 20.7 s\n",
      "process 21000 peaks takes 20.7 s\n",
      "process 21050 peaks takes 20.8 s\n",
      "process 21100 peaks takes 20.9 s\n",
      "process 21150 peaks takes 20.9 s\n",
      "process 21200 peaks takes 21.0 s\n",
      "process 21250 peaks takes 21.0 s\n",
      "process 21300 peaks takes 21.1 s\n",
      "process 21350 peaks takes 21.1 s\n",
      "process 21400 peaks takes 21.2 s\n",
      "process 21450 peaks takes 21.2 s\n",
      "process 21500 peaks takes 21.2 s\n",
      "process 21550 peaks takes 21.3 s\n",
      "process 21600 peaks takes 21.4 s\n",
      "process 21650 peaks takes 21.4 s\n",
      "process 21700 peaks takes 21.5 s\n",
      "process 21750 peaks takes 21.5 s\n",
      "process 21800 peaks takes 21.6 s\n",
      "process 21850 peaks takes 21.6 s\n",
      "process 21900 peaks takes 21.7 s\n",
      "process 21950 peaks takes 21.7 s\n",
      "process 22000 peaks takes 21.7 s\n",
      "process 22050 peaks takes 21.8 s\n",
      "process 22100 peaks takes 21.8 s\n",
      "process 22150 peaks takes 21.9 s\n",
      "process 22200 peaks takes 22.0 s\n",
      "process 22250 peaks takes 22.0 s\n",
      "process 22300 peaks takes 22.0 s\n",
      "process 22350 peaks takes 22.1 s\n",
      "process 22400 peaks takes 22.1 s\n",
      "process 22450 peaks takes 22.2 s\n",
      "process 22500 peaks takes 22.3 s\n",
      "process 22550 peaks takes 22.3 s\n",
      "process 22600 peaks takes 22.4 s\n",
      "process 22650 peaks takes 22.4 s\n",
      "process 22700 peaks takes 22.5 s\n",
      "process 22750 peaks takes 22.5 s\n",
      "process 22800 peaks takes 22.6 s\n",
      "process 22850 peaks takes 22.6 s\n",
      "process 22900 peaks takes 22.7 s\n",
      "process 22950 peaks takes 22.7 s\n",
      "process 23000 peaks takes 22.8 s\n",
      "process 23050 peaks takes 22.9 s\n",
      "process 23100 peaks takes 22.9 s\n",
      "process 23150 peaks takes 23.0 s\n",
      "process 23200 peaks takes 23.0 s\n",
      "process 23250 peaks takes 23.1 s\n",
      "process 23300 peaks takes 23.1 s\n",
      "process 23350 peaks takes 23.2 s\n",
      "process 23400 peaks takes 23.2 s\n",
      "process 23450 peaks takes 23.3 s\n",
      "process 23500 peaks takes 23.4 s\n",
      "process 23550 peaks takes 23.4 s\n",
      "process 23600 peaks takes 23.5 s\n",
      "process 23650 peaks takes 23.5 s\n",
      "process 23700 peaks takes 23.6 s\n",
      "process 23750 peaks takes 23.6 s\n",
      "process 23800 peaks takes 23.7 s\n",
      "process 23850 peaks takes 23.7 s\n",
      "process 23900 peaks takes 23.8 s\n",
      "process 23950 peaks takes 23.9 s\n",
      "process 24000 peaks takes 23.9 s\n",
      "process 24050 peaks takes 24.0 s\n",
      "process 24100 peaks takes 24.0 s\n",
      "process 24150 peaks takes 24.1 s\n",
      "process 24200 peaks takes 24.1 s\n",
      "process 24250 peaks takes 24.2 s\n",
      "process 24300 peaks takes 24.2 s\n",
      "process 24350 peaks takes 24.3 s\n",
      "process 24400 peaks takes 24.4 s\n",
      "process 24450 peaks takes 24.4 s\n",
      "process 24500 peaks takes 24.5 s\n",
      "process 24550 peaks takes 24.5 s\n",
      "process 24600 peaks takes 24.5 s\n",
      "process 24650 peaks takes 24.6 s\n",
      "process 24700 peaks takes 24.6 s\n",
      "process 24750 peaks takes 24.7 s\n",
      "process 24800 peaks takes 24.7 s\n",
      "process 24850 peaks takes 24.8 s\n",
      "process 24900 peaks takes 24.9 s\n",
      "process 24950 peaks takes 24.9 s\n",
      "process 25000 peaks takes 24.9 s\n",
      "process 25050 peaks takes 25.0 s\n",
      "process 25100 peaks takes 25.0 s\n",
      "process 25150 peaks takes 25.1 s\n",
      "process 25200 peaks takes 25.1 s\n",
      "process 25250 peaks takes 25.2 s\n",
      "process 25300 peaks takes 25.2 s\n",
      "process 25350 peaks takes 25.3 s\n",
      "process 25400 peaks takes 25.3 s\n",
      "process 25450 peaks takes 25.4 s\n",
      "process 25500 peaks takes 25.4 s\n",
      "process 25550 peaks takes 25.4 s\n",
      "process 25600 peaks takes 25.5 s\n",
      "process 25650 peaks takes 25.5 s\n",
      "process 25700 peaks takes 25.6 s\n",
      "process 25750 peaks takes 25.6 s\n",
      "process 25800 peaks takes 25.7 s\n",
      "process 25850 peaks takes 25.7 s\n",
      "process 25900 peaks takes 25.8 s\n",
      "process 25950 peaks takes 25.8 s\n",
      "process 26000 peaks takes 25.9 s\n",
      "process 26050 peaks takes 25.9 s\n",
      "process 26100 peaks takes 26.0 s\n",
      "process 26150 peaks takes 26.0 s\n",
      "process 26200 peaks takes 26.0 s\n",
      "process 26250 peaks takes 26.1 s\n",
      "process 26300 peaks takes 26.1 s\n",
      "process 26350 peaks takes 26.2 s\n",
      "process 26400 peaks takes 26.2 s\n",
      "process 26450 peaks takes 26.3 s\n",
      "process 26500 peaks takes 26.4 s\n",
      "process 26550 peaks takes 26.4 s\n",
      "process 26600 peaks takes 26.4 s\n",
      "process 26650 peaks takes 26.5 s\n",
      "process 26700 peaks takes 26.5 s\n",
      "process 26750 peaks takes 26.6 s\n",
      "process 26800 peaks takes 26.6 s\n",
      "process 26850 peaks takes 26.7 s\n",
      "process 26900 peaks takes 26.7 s\n",
      "process 26950 peaks takes 26.8 s\n",
      "process 27000 peaks takes 26.8 s\n",
      "process 27050 peaks takes 26.9 s\n",
      "process 27100 peaks takes 26.9 s\n",
      "process 27150 peaks takes 27.0 s\n",
      "process 27200 peaks takes 27.0 s\n",
      "process 27250 peaks takes 27.1 s\n",
      "process 27300 peaks takes 27.1 s\n",
      "process 27350 peaks takes 27.1 s\n",
      "process 27400 peaks takes 27.2 s\n",
      "process 27450 peaks takes 27.2 s\n",
      "process 27500 peaks takes 27.3 s\n",
      "process 27550 peaks takes 27.3 s\n",
      "process 27600 peaks takes 27.4 s\n",
      "process 27650 peaks takes 27.4 s\n",
      "process 27700 peaks takes 27.5 s\n",
      "process 27750 peaks takes 27.5 s\n",
      "process 27800 peaks takes 27.6 s\n",
      "process 27850 peaks takes 27.6 s\n",
      "process 27900 peaks takes 27.7 s\n",
      "process 27950 peaks takes 27.7 s\n",
      "process 28000 peaks takes 27.8 s\n",
      "process 28050 peaks takes 27.8 s\n",
      "process 28100 peaks takes 27.9 s\n",
      "process 28150 peaks takes 27.9 s\n",
      "process 28200 peaks takes 28.0 s\n",
      "process 28250 peaks takes 28.1 s\n",
      "process 28300 peaks takes 28.1 s\n",
      "process 28350 peaks takes 28.2 s\n",
      "process 28400 peaks takes 28.2 s\n",
      "process 28450 peaks takes 28.3 s\n",
      "process 28500 peaks takes 28.3 s\n",
      "process 28550 peaks takes 28.4 s\n",
      "process 28600 peaks takes 28.5 s\n",
      "process 28650 peaks takes 28.5 s\n",
      "process 28700 peaks takes 28.5 s\n",
      "process 28750 peaks takes 28.6 s\n",
      "process 28800 peaks takes 28.6 s\n",
      "process 28850 peaks takes 28.7 s\n",
      "process 28900 peaks takes 28.7 s\n",
      "process 28950 peaks takes 28.8 s\n",
      "process 29000 peaks takes 28.8 s\n",
      "process 29050 peaks takes 28.9 s\n",
      "process 29100 peaks takes 28.9 s\n",
      "process 29150 peaks takes 29.0 s\n",
      "process 29200 peaks takes 29.0 s\n",
      "process 29250 peaks takes 29.0 s\n",
      "process 29300 peaks takes 29.1 s\n",
      "process 29350 peaks takes 29.1 s\n",
      "process 29400 peaks takes 29.2 s\n",
      "process 29450 peaks takes 29.2 s\n",
      "process 29500 peaks takes 29.3 s\n",
      "process 29550 peaks takes 29.3 s\n",
      "process 29600 peaks takes 29.4 s\n",
      "process 29650 peaks takes 29.4 s\n",
      "process 29700 peaks takes 29.5 s\n",
      "process 29750 peaks takes 29.5 s\n",
      "process 29800 peaks takes 29.6 s\n",
      "process 29850 peaks takes 29.6 s\n",
      "process 29900 peaks takes 29.7 s\n",
      "process 29950 peaks takes 29.7 s\n",
      "\n",
      "train\n",
      "27001 540\n",
      "process 0 peaks takes 0.4 s\n",
      "process 50 peaks takes 0.4 s\n",
      "process 100 peaks takes 0.5 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.6 s\n",
      "process 250 peaks takes 0.6 s\n",
      "process 300 peaks takes 0.6 s\n",
      "process 350 peaks takes 0.7 s\n",
      "process 400 peaks takes 0.7 s\n",
      "process 450 peaks takes 0.8 s\n",
      "process 500 peaks takes 0.8 s\n",
      "process 550 peaks takes 0.9 s\n",
      "process 600 peaks takes 0.9 s\n",
      "process 650 peaks takes 1.0 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.1 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.2 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.3 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.4 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.9 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 3.0 s\n",
      "process 3000 peaks takes 3.0 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.2 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.3 s\n",
      "process 3350 peaks takes 3.3 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.4 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.5 s\n",
      "process 3600 peaks takes 3.5 s\n",
      "process 3650 peaks takes 3.6 s\n",
      "process 3700 peaks takes 3.6 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.7 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.8 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.9 s\n",
      "process 4100 peaks takes 3.9 s\n",
      "process 4150 peaks takes 4.0 s\n",
      "process 4200 peaks takes 4.0 s\n",
      "process 4250 peaks takes 4.1 s\n",
      "process 4300 peaks takes 4.1 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.2 s\n",
      "process 4450 peaks takes 4.3 s\n",
      "process 4500 peaks takes 4.3 s\n",
      "process 4550 peaks takes 4.4 s\n",
      "process 4600 peaks takes 4.4 s\n",
      "process 4650 peaks takes 4.5 s\n",
      "process 4700 peaks takes 4.5 s\n",
      "process 4750 peaks takes 4.6 s\n",
      "process 4800 peaks takes 4.6 s\n",
      "process 4850 peaks takes 4.7 s\n",
      "process 4900 peaks takes 4.7 s\n",
      "process 4950 peaks takes 4.7 s\n",
      "process 5000 peaks takes 4.8 s\n",
      "process 5050 peaks takes 4.8 s\n",
      "process 5100 peaks takes 4.9 s\n",
      "process 5150 peaks takes 4.9 s\n",
      "process 5200 peaks takes 4.9 s\n",
      "process 5250 peaks takes 5.0 s\n",
      "process 5300 peaks takes 5.0 s\n",
      "process 5350 peaks takes 5.1 s\n",
      "process 5400 peaks takes 5.1 s\n",
      "process 5450 peaks takes 5.2 s\n",
      "process 5500 peaks takes 5.2 s\n",
      "process 5550 peaks takes 5.2 s\n",
      "process 5600 peaks takes 5.3 s\n",
      "process 5650 peaks takes 5.3 s\n",
      "process 5700 peaks takes 5.4 s\n",
      "process 5750 peaks takes 5.4 s\n",
      "process 5800 peaks takes 5.5 s\n",
      "process 5850 peaks takes 5.5 s\n",
      "process 5900 peaks takes 5.5 s\n",
      "process 5950 peaks takes 5.6 s\n",
      "process 6000 peaks takes 5.6 s\n",
      "process 6050 peaks takes 5.7 s\n",
      "process 6100 peaks takes 5.7 s\n",
      "process 6150 peaks takes 5.8 s\n",
      "process 6200 peaks takes 5.8 s\n",
      "process 6250 peaks takes 5.9 s\n",
      "process 6300 peaks takes 5.9 s\n",
      "process 6350 peaks takes 6.0 s\n",
      "process 6400 peaks takes 6.0 s\n",
      "process 6450 peaks takes 6.1 s\n",
      "process 6500 peaks takes 6.1 s\n",
      "process 6550 peaks takes 6.2 s\n",
      "process 6600 peaks takes 6.2 s\n",
      "process 6650 peaks takes 6.2 s\n",
      "process 6700 peaks takes 6.3 s\n",
      "process 6750 peaks takes 6.3 s\n",
      "process 6800 peaks takes 6.4 s\n",
      "process 6850 peaks takes 6.4 s\n",
      "process 6900 peaks takes 6.5 s\n",
      "process 6950 peaks takes 6.5 s\n",
      "process 7000 peaks takes 6.5 s\n",
      "process 7050 peaks takes 6.6 s\n",
      "process 7100 peaks takes 6.6 s\n",
      "process 7150 peaks takes 6.6 s\n",
      "process 7200 peaks takes 6.7 s\n",
      "process 7250 peaks takes 6.7 s\n",
      "process 7300 peaks takes 6.8 s\n",
      "process 7350 peaks takes 6.8 s\n",
      "process 7400 peaks takes 6.8 s\n",
      "process 7450 peaks takes 6.9 s\n",
      "process 7500 peaks takes 6.9 s\n",
      "process 7550 peaks takes 7.0 s\n",
      "process 7600 peaks takes 7.0 s\n",
      "process 7650 peaks takes 7.1 s\n",
      "process 7700 peaks takes 7.1 s\n",
      "process 7750 peaks takes 7.2 s\n",
      "process 7800 peaks takes 7.2 s\n",
      "process 7850 peaks takes 7.3 s\n",
      "process 7900 peaks takes 7.3 s\n",
      "process 7950 peaks takes 7.4 s\n",
      "process 8000 peaks takes 7.4 s\n",
      "process 8050 peaks takes 7.4 s\n",
      "process 8100 peaks takes 7.5 s\n",
      "process 8150 peaks takes 7.5 s\n",
      "process 8200 peaks takes 7.6 s\n",
      "process 8250 peaks takes 7.6 s\n",
      "process 8300 peaks takes 7.7 s\n",
      "process 8350 peaks takes 7.7 s\n",
      "process 8400 peaks takes 7.8 s\n",
      "process 8450 peaks takes 7.8 s\n",
      "process 8500 peaks takes 7.9 s\n",
      "process 8550 peaks takes 7.9 s\n",
      "process 8600 peaks takes 8.0 s\n",
      "process 8650 peaks takes 8.0 s\n",
      "process 8700 peaks takes 8.1 s\n",
      "process 8750 peaks takes 8.1 s\n",
      "process 8800 peaks takes 8.2 s\n",
      "process 8850 peaks takes 8.2 s\n",
      "process 8900 peaks takes 8.2 s\n",
      "process 8950 peaks takes 8.3 s\n",
      "process 9000 peaks takes 8.3 s\n",
      "process 9050 peaks takes 8.4 s\n",
      "process 9100 peaks takes 8.4 s\n",
      "process 9150 peaks takes 8.5 s\n",
      "process 9200 peaks takes 8.5 s\n",
      "process 9250 peaks takes 8.6 s\n",
      "process 9300 peaks takes 8.6 s\n",
      "process 9350 peaks takes 8.7 s\n",
      "process 9400 peaks takes 8.7 s\n",
      "process 9450 peaks takes 8.7 s\n",
      "process 9500 peaks takes 8.8 s\n",
      "process 9550 peaks takes 8.8 s\n",
      "process 9600 peaks takes 8.9 s\n",
      "process 9650 peaks takes 8.9 s\n",
      "process 9700 peaks takes 9.0 s\n",
      "process 9750 peaks takes 9.0 s\n",
      "process 9800 peaks takes 9.0 s\n",
      "process 9850 peaks takes 9.1 s\n",
      "process 9900 peaks takes 9.1 s\n",
      "process 9950 peaks takes 9.2 s\n",
      "process 10000 peaks takes 9.2 s\n",
      "process 10050 peaks takes 9.3 s\n",
      "process 10100 peaks takes 9.3 s\n",
      "process 10150 peaks takes 9.3 s\n",
      "process 10200 peaks takes 9.4 s\n",
      "process 10250 peaks takes 9.4 s\n",
      "process 10300 peaks takes 9.5 s\n",
      "process 10350 peaks takes 9.5 s\n",
      "process 10400 peaks takes 9.6 s\n",
      "process 10450 peaks takes 9.6 s\n",
      "process 10500 peaks takes 9.7 s\n",
      "process 10550 peaks takes 9.7 s\n",
      "process 10600 peaks takes 9.7 s\n",
      "process 10650 peaks takes 9.8 s\n",
      "process 10700 peaks takes 9.8 s\n",
      "process 10750 peaks takes 9.9 s\n",
      "process 10800 peaks takes 9.9 s\n",
      "process 10850 peaks takes 10.0 s\n",
      "process 10900 peaks takes 10.0 s\n",
      "process 10950 peaks takes 10.1 s\n",
      "process 11000 peaks takes 10.2 s\n",
      "process 11050 peaks takes 10.2 s\n",
      "process 11100 peaks takes 10.3 s\n",
      "process 11150 peaks takes 10.3 s\n",
      "process 11200 peaks takes 10.3 s\n",
      "process 11250 peaks takes 10.4 s\n",
      "process 11300 peaks takes 10.5 s\n",
      "process 11350 peaks takes 10.5 s\n",
      "process 11400 peaks takes 10.6 s\n",
      "process 11450 peaks takes 10.6 s\n",
      "process 11500 peaks takes 10.7 s\n",
      "process 11550 peaks takes 10.7 s\n",
      "process 11600 peaks takes 10.8 s\n",
      "process 11650 peaks takes 10.8 s\n",
      "process 11700 peaks takes 10.9 s\n",
      "process 11750 peaks takes 10.9 s\n",
      "process 11800 peaks takes 11.0 s\n",
      "process 11850 peaks takes 11.0 s\n",
      "process 11900 peaks takes 11.0 s\n",
      "process 11950 peaks takes 11.1 s\n",
      "process 12000 peaks takes 11.1 s\n",
      "process 12050 peaks takes 11.2 s\n",
      "process 12100 peaks takes 11.2 s\n",
      "process 12150 peaks takes 11.3 s\n",
      "process 12200 peaks takes 11.3 s\n",
      "process 12250 peaks takes 11.4 s\n",
      "process 12300 peaks takes 11.4 s\n",
      "process 12350 peaks takes 11.5 s\n",
      "process 12400 peaks takes 11.5 s\n",
      "process 12450 peaks takes 11.6 s\n",
      "process 12500 peaks takes 11.6 s\n",
      "process 12550 peaks takes 11.7 s\n",
      "process 12600 peaks takes 11.7 s\n",
      "process 12650 peaks takes 11.8 s\n",
      "process 12700 peaks takes 11.8 s\n",
      "process 12750 peaks takes 11.8 s\n",
      "process 12800 peaks takes 11.9 s\n",
      "process 12850 peaks takes 11.9 s\n",
      "process 12900 peaks takes 12.0 s\n",
      "process 12950 peaks takes 12.0 s\n",
      "process 13000 peaks takes 12.0 s\n",
      "process 13050 peaks takes 12.1 s\n",
      "process 13100 peaks takes 12.1 s\n",
      "process 13150 peaks takes 12.2 s\n",
      "process 13200 peaks takes 12.2 s\n",
      "process 13250 peaks takes 12.3 s\n",
      "process 13300 peaks takes 12.3 s\n",
      "process 13350 peaks takes 12.4 s\n",
      "process 13400 peaks takes 12.4 s\n",
      "process 13450 peaks takes 12.5 s\n",
      "process 13500 peaks takes 12.5 s\n",
      "process 13550 peaks takes 12.5 s\n",
      "process 13600 peaks takes 12.6 s\n",
      "process 13650 peaks takes 12.6 s\n",
      "process 13700 peaks takes 12.7 s\n",
      "process 13750 peaks takes 12.7 s\n",
      "process 13800 peaks takes 12.8 s\n",
      "process 13850 peaks takes 12.8 s\n",
      "process 13900 peaks takes 12.8 s\n",
      "process 13950 peaks takes 12.9 s\n",
      "process 14000 peaks takes 12.9 s\n",
      "process 14050 peaks takes 13.0 s\n",
      "process 14100 peaks takes 13.0 s\n",
      "process 14150 peaks takes 13.0 s\n",
      "process 14200 peaks takes 13.1 s\n",
      "process 14250 peaks takes 13.1 s\n",
      "process 14300 peaks takes 13.2 s\n",
      "process 14350 peaks takes 13.2 s\n",
      "process 14400 peaks takes 13.3 s\n",
      "process 14450 peaks takes 13.3 s\n",
      "process 14500 peaks takes 13.4 s\n",
      "process 14550 peaks takes 13.4 s\n",
      "process 14600 peaks takes 13.4 s\n",
      "process 14650 peaks takes 13.5 s\n",
      "process 14700 peaks takes 13.5 s\n",
      "process 14750 peaks takes 13.6 s\n",
      "process 14800 peaks takes 13.6 s\n",
      "process 14850 peaks takes 13.7 s\n",
      "process 14900 peaks takes 13.7 s\n",
      "process 14950 peaks takes 13.8 s\n",
      "process 15000 peaks takes 13.8 s\n",
      "process 15050 peaks takes 13.9 s\n",
      "process 15100 peaks takes 13.9 s\n",
      "process 15150 peaks takes 14.0 s\n",
      "process 15200 peaks takes 14.0 s\n",
      "process 15250 peaks takes 14.1 s\n",
      "process 15300 peaks takes 14.1 s\n",
      "process 15350 peaks takes 14.2 s\n",
      "process 15400 peaks takes 14.2 s\n",
      "process 15450 peaks takes 14.2 s\n",
      "process 15500 peaks takes 14.3 s\n",
      "process 15550 peaks takes 14.3 s\n",
      "process 15600 peaks takes 14.4 s\n",
      "process 15650 peaks takes 14.4 s\n",
      "process 15700 peaks takes 14.5 s\n",
      "process 15750 peaks takes 14.5 s\n",
      "process 15800 peaks takes 14.6 s\n",
      "process 15850 peaks takes 14.6 s\n",
      "process 15900 peaks takes 14.7 s\n",
      "process 15950 peaks takes 14.7 s\n",
      "process 16000 peaks takes 14.7 s\n",
      "process 16050 peaks takes 14.8 s\n",
      "process 16100 peaks takes 14.8 s\n",
      "process 16150 peaks takes 14.9 s\n",
      "process 16200 peaks takes 14.9 s\n",
      "process 16250 peaks takes 15.0 s\n",
      "process 16300 peaks takes 15.0 s\n",
      "process 16350 peaks takes 15.1 s\n",
      "process 16400 peaks takes 15.1 s\n",
      "process 16450 peaks takes 15.1 s\n",
      "process 16500 peaks takes 15.2 s\n",
      "process 16550 peaks takes 15.2 s\n",
      "process 16600 peaks takes 15.3 s\n",
      "process 16650 peaks takes 15.3 s\n",
      "process 16700 peaks takes 15.4 s\n",
      "process 16750 peaks takes 15.4 s\n",
      "process 16800 peaks takes 15.5 s\n",
      "process 16850 peaks takes 15.5 s\n",
      "process 16900 peaks takes 15.5 s\n",
      "process 16950 peaks takes 15.6 s\n",
      "process 17000 peaks takes 15.6 s\n",
      "process 17050 peaks takes 15.7 s\n",
      "process 17100 peaks takes 15.7 s\n",
      "process 17150 peaks takes 15.8 s\n",
      "process 17200 peaks takes 15.8 s\n",
      "process 17250 peaks takes 15.9 s\n",
      "process 17300 peaks takes 15.9 s\n",
      "process 17350 peaks takes 15.9 s\n",
      "process 17400 peaks takes 16.0 s\n",
      "process 17450 peaks takes 16.0 s\n",
      "process 17500 peaks takes 16.1 s\n",
      "process 17550 peaks takes 16.1 s\n",
      "process 17600 peaks takes 16.2 s\n",
      "process 17650 peaks takes 16.2 s\n",
      "process 17700 peaks takes 16.2 s\n",
      "process 17750 peaks takes 16.3 s\n",
      "process 17800 peaks takes 16.3 s\n",
      "process 17850 peaks takes 16.3 s\n",
      "process 17900 peaks takes 16.4 s\n",
      "process 17950 peaks takes 16.4 s\n",
      "process 18000 peaks takes 16.5 s\n",
      "process 18050 peaks takes 16.5 s\n",
      "process 18100 peaks takes 16.6 s\n",
      "process 18150 peaks takes 16.6 s\n",
      "process 18200 peaks takes 16.7 s\n",
      "process 18250 peaks takes 16.7 s\n",
      "process 18300 peaks takes 16.8 s\n",
      "process 18350 peaks takes 16.8 s\n",
      "process 18400 peaks takes 16.8 s\n",
      "process 18450 peaks takes 16.9 s\n",
      "process 18500 peaks takes 16.9 s\n",
      "process 18550 peaks takes 16.9 s\n",
      "process 18600 peaks takes 17.0 s\n",
      "process 18650 peaks takes 17.0 s\n",
      "process 18700 peaks takes 17.1 s\n",
      "process 18750 peaks takes 17.1 s\n",
      "process 18800 peaks takes 17.2 s\n",
      "process 18850 peaks takes 17.2 s\n",
      "process 18900 peaks takes 17.3 s\n",
      "process 18950 peaks takes 17.3 s\n",
      "process 19000 peaks takes 17.4 s\n",
      "process 19050 peaks takes 17.4 s\n",
      "process 19100 peaks takes 17.4 s\n",
      "process 19150 peaks takes 17.5 s\n",
      "process 19200 peaks takes 17.5 s\n",
      "process 19250 peaks takes 17.6 s\n",
      "process 19300 peaks takes 17.6 s\n",
      "process 19350 peaks takes 17.7 s\n",
      "process 19400 peaks takes 17.7 s\n",
      "process 19450 peaks takes 17.8 s\n",
      "process 19500 peaks takes 17.8 s\n",
      "process 19550 peaks takes 17.9 s\n",
      "process 19600 peaks takes 17.9 s\n",
      "process 19650 peaks takes 18.0 s\n",
      "process 19700 peaks takes 18.0 s\n",
      "process 19750 peaks takes 18.1 s\n",
      "process 19800 peaks takes 18.1 s\n",
      "process 19850 peaks takes 18.2 s\n",
      "process 19900 peaks takes 18.2 s\n",
      "process 19950 peaks takes 18.3 s\n",
      "process 20000 peaks takes 18.3 s\n",
      "process 20050 peaks takes 18.3 s\n",
      "process 20100 peaks takes 18.4 s\n",
      "process 20150 peaks takes 18.4 s\n",
      "process 20200 peaks takes 18.5 s\n",
      "process 20250 peaks takes 18.5 s\n",
      "process 20300 peaks takes 18.6 s\n",
      "process 20350 peaks takes 18.6 s\n",
      "process 20400 peaks takes 18.7 s\n",
      "process 20450 peaks takes 18.7 s\n",
      "process 20500 peaks takes 18.8 s\n",
      "process 20550 peaks takes 18.8 s\n",
      "process 20600 peaks takes 18.9 s\n",
      "process 20650 peaks takes 18.9 s\n",
      "process 20700 peaks takes 19.0 s\n",
      "process 20750 peaks takes 19.0 s\n",
      "process 20800 peaks takes 19.0 s\n",
      "process 20850 peaks takes 19.1 s\n",
      "process 20900 peaks takes 19.1 s\n",
      "process 20950 peaks takes 19.1 s\n",
      "process 21000 peaks takes 19.2 s\n",
      "process 21050 peaks takes 19.2 s\n",
      "process 21100 peaks takes 19.3 s\n",
      "process 21150 peaks takes 19.3 s\n",
      "process 21200 peaks takes 19.3 s\n",
      "process 21250 peaks takes 19.4 s\n",
      "process 21300 peaks takes 19.4 s\n",
      "process 21350 peaks takes 19.5 s\n",
      "process 21400 peaks takes 19.5 s\n",
      "process 21450 peaks takes 19.6 s\n",
      "process 21500 peaks takes 19.6 s\n",
      "process 21550 peaks takes 19.6 s\n",
      "process 21600 peaks takes 19.7 s\n",
      "process 21650 peaks takes 19.7 s\n",
      "process 21700 peaks takes 19.8 s\n",
      "process 21750 peaks takes 19.8 s\n",
      "process 21800 peaks takes 19.9 s\n",
      "process 21850 peaks takes 19.9 s\n",
      "process 21900 peaks takes 19.9 s\n",
      "process 21950 peaks takes 20.0 s\n",
      "process 22000 peaks takes 20.0 s\n",
      "process 22050 peaks takes 20.1 s\n",
      "process 22100 peaks takes 20.1 s\n",
      "process 22150 peaks takes 20.2 s\n",
      "process 22200 peaks takes 20.2 s\n",
      "process 22250 peaks takes 20.3 s\n",
      "process 22300 peaks takes 20.3 s\n",
      "process 22350 peaks takes 20.4 s\n",
      "process 22400 peaks takes 20.4 s\n",
      "process 22450 peaks takes 20.5 s\n",
      "process 22500 peaks takes 20.5 s\n",
      "process 22550 peaks takes 20.5 s\n",
      "process 22600 peaks takes 20.6 s\n",
      "process 22650 peaks takes 20.6 s\n",
      "process 22700 peaks takes 20.7 s\n",
      "process 22750 peaks takes 20.7 s\n",
      "process 22800 peaks takes 20.7 s\n",
      "process 22850 peaks takes 20.8 s\n",
      "process 22900 peaks takes 20.8 s\n",
      "process 22950 peaks takes 20.9 s\n",
      "process 23000 peaks takes 20.9 s\n",
      "process 23050 peaks takes 20.9 s\n",
      "process 23100 peaks takes 21.0 s\n",
      "process 23150 peaks takes 21.0 s\n",
      "process 23200 peaks takes 21.1 s\n",
      "process 23250 peaks takes 21.1 s\n",
      "process 23300 peaks takes 21.2 s\n",
      "process 23350 peaks takes 21.2 s\n",
      "process 23400 peaks takes 21.2 s\n",
      "process 23450 peaks takes 21.3 s\n",
      "process 23500 peaks takes 21.3 s\n",
      "process 23550 peaks takes 21.4 s\n",
      "process 23600 peaks takes 21.4 s\n",
      "process 23650 peaks takes 21.5 s\n",
      "process 23700 peaks takes 21.5 s\n",
      "process 23750 peaks takes 21.5 s\n",
      "process 23800 peaks takes 21.6 s\n",
      "process 23850 peaks takes 21.6 s\n",
      "process 23900 peaks takes 21.7 s\n",
      "process 23950 peaks takes 21.7 s\n",
      "process 24000 peaks takes 21.8 s\n",
      "process 24050 peaks takes 21.8 s\n",
      "process 24100 peaks takes 21.8 s\n",
      "process 24150 peaks takes 21.9 s\n",
      "process 24200 peaks takes 21.9 s\n",
      "process 24250 peaks takes 22.0 s\n",
      "process 24300 peaks takes 22.0 s\n",
      "process 24350 peaks takes 22.0 s\n",
      "process 24400 peaks takes 22.1 s\n",
      "process 24450 peaks takes 22.1 s\n",
      "process 24500 peaks takes 22.2 s\n",
      "process 24550 peaks takes 22.2 s\n",
      "process 24600 peaks takes 22.3 s\n",
      "process 24650 peaks takes 22.3 s\n",
      "process 24700 peaks takes 22.3 s\n",
      "process 24750 peaks takes 22.4 s\n",
      "process 24800 peaks takes 22.4 s\n",
      "process 24850 peaks takes 22.5 s\n",
      "process 24900 peaks takes 22.5 s\n",
      "process 24950 peaks takes 22.5 s\n",
      "process 25000 peaks takes 22.6 s\n",
      "process 25050 peaks takes 22.6 s\n",
      "process 25100 peaks takes 22.7 s\n",
      "process 25150 peaks takes 22.7 s\n",
      "process 25200 peaks takes 22.8 s\n",
      "process 25250 peaks takes 22.8 s\n",
      "process 25300 peaks takes 22.9 s\n",
      "process 25350 peaks takes 22.9 s\n",
      "process 25400 peaks takes 23.0 s\n",
      "process 25450 peaks takes 23.0 s\n",
      "process 25500 peaks takes 23.0 s\n",
      "process 25550 peaks takes 23.1 s\n",
      "process 25600 peaks takes 23.1 s\n",
      "process 25650 peaks takes 23.2 s\n",
      "process 25700 peaks takes 23.2 s\n",
      "process 25750 peaks takes 23.3 s\n",
      "process 25800 peaks takes 23.3 s\n",
      "process 25850 peaks takes 23.4 s\n",
      "process 25900 peaks takes 23.4 s\n",
      "process 25950 peaks takes 23.4 s\n",
      "process 26000 peaks takes 23.5 s\n",
      "process 26050 peaks takes 23.5 s\n",
      "process 26100 peaks takes 23.6 s\n",
      "process 26150 peaks takes 23.6 s\n",
      "process 26200 peaks takes 23.7 s\n",
      "process 26250 peaks takes 23.7 s\n",
      "process 26300 peaks takes 23.7 s\n",
      "process 26350 peaks takes 23.8 s\n",
      "process 26400 peaks takes 23.8 s\n",
      "process 26450 peaks takes 23.9 s\n",
      "process 26500 peaks takes 23.9 s\n",
      "process 26550 peaks takes 24.0 s\n",
      "process 26600 peaks takes 24.0 s\n",
      "process 26650 peaks takes 24.1 s\n",
      "process 26700 peaks takes 24.1 s\n",
      "process 26750 peaks takes 24.2 s\n",
      "process 26800 peaks takes 24.2 s\n",
      "process 26850 peaks takes 24.3 s\n",
      "process 26900 peaks takes 24.3 s\n",
      "process 26950 peaks takes 24.4 s\n",
      "\n",
      "test\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "\n",
      "val\n",
      "1499 29\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs10000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:39:20.758113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:39:20.854638: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:39:20.857854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:20.857886: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:39:21.346459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:21.346539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:21.346547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.9GB.\n",
      "2024-05-13 06:39:24.112397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:39:24.112505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:39:24.112845: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:39:24.113170: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5877)      193941      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5877)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5877)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,713,751\n",
      "Trainable params: 4,707,901\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "211/211 [==============================] - 359s 2s/step - loss: 0.2577 - auc: 0.6508 - auc_1: 0.1280 - val_loss: 0.2391 - val_auc: 0.7073 - val_auc_1: 0.2029\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs10000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs10000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad\n",
      "(5877, 30000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs10000_var30000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000 --batch 50\n",
      "2024-05-13 06:45:29.399464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:45:29.507232: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:45:29.510403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:45:29.510439: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:45:29.984336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:45:29.984426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:45:29.984434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[27001, 1500, 1499]\n",
      "30000 600\n",
      "process 0 peaks takes 0.3 s\n",
      "process 50 peaks takes 0.4 s\n",
      "process 100 peaks takes 0.4 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.5 s\n",
      "process 250 peaks takes 0.6 s\n",
      "process 300 peaks takes 0.6 s\n",
      "process 350 peaks takes 0.7 s\n",
      "process 400 peaks takes 0.7 s\n",
      "process 450 peaks takes 0.7 s\n",
      "process 500 peaks takes 0.8 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.9 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.6 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.7 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 2.9 s\n",
      "process 3150 peaks takes 3.0 s\n",
      "process 3200 peaks takes 3.0 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.1 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.2 s\n",
      "process 3500 peaks takes 3.3 s\n",
      "process 3550 peaks takes 3.3 s\n",
      "process 3600 peaks takes 3.3 s\n",
      "process 3650 peaks takes 3.4 s\n",
      "process 3700 peaks takes 3.4 s\n",
      "process 3750 peaks takes 3.5 s\n",
      "process 3800 peaks takes 3.5 s\n",
      "process 3850 peaks takes 3.6 s\n",
      "process 3900 peaks takes 3.6 s\n",
      "process 3950 peaks takes 3.7 s\n",
      "process 4000 peaks takes 3.7 s\n",
      "process 4050 peaks takes 3.7 s\n",
      "process 4100 peaks takes 3.8 s\n",
      "process 4150 peaks takes 3.8 s\n",
      "process 4200 peaks takes 3.9 s\n",
      "process 4250 peaks takes 3.9 s\n",
      "process 4300 peaks takes 3.9 s\n",
      "process 4350 peaks takes 4.0 s\n",
      "process 4400 peaks takes 4.0 s\n",
      "process 4450 peaks takes 4.1 s\n",
      "process 4500 peaks takes 4.1 s\n",
      "process 4550 peaks takes 4.1 s\n",
      "process 4600 peaks takes 4.2 s\n",
      "process 4650 peaks takes 4.2 s\n",
      "process 4700 peaks takes 4.3 s\n",
      "process 4750 peaks takes 4.3 s\n",
      "process 4800 peaks takes 4.3 s\n",
      "process 4850 peaks takes 4.4 s\n",
      "process 4900 peaks takes 4.4 s\n",
      "process 4950 peaks takes 4.5 s\n",
      "process 5000 peaks takes 4.5 s\n",
      "process 5050 peaks takes 4.6 s\n",
      "process 5100 peaks takes 4.6 s\n",
      "process 5150 peaks takes 4.7 s\n",
      "process 5200 peaks takes 4.7 s\n",
      "process 5250 peaks takes 4.7 s\n",
      "process 5300 peaks takes 4.8 s\n",
      "process 5350 peaks takes 4.8 s\n",
      "process 5400 peaks takes 4.9 s\n",
      "process 5450 peaks takes 4.9 s\n",
      "process 5500 peaks takes 5.0 s\n",
      "process 5550 peaks takes 5.0 s\n",
      "process 5600 peaks takes 5.0 s\n",
      "process 5650 peaks takes 5.1 s\n",
      "process 5700 peaks takes 5.1 s\n",
      "process 5750 peaks takes 5.2 s\n",
      "process 5800 peaks takes 5.2 s\n",
      "process 5850 peaks takes 5.3 s\n",
      "process 5900 peaks takes 5.3 s\n",
      "process 5950 peaks takes 5.3 s\n",
      "process 6000 peaks takes 5.4 s\n",
      "process 6050 peaks takes 5.4 s\n",
      "process 6100 peaks takes 5.5 s\n",
      "process 6150 peaks takes 5.5 s\n",
      "process 6200 peaks takes 5.5 s\n",
      "process 6250 peaks takes 5.6 s\n",
      "process 6300 peaks takes 5.6 s\n",
      "process 6350 peaks takes 5.7 s\n",
      "process 6400 peaks takes 5.7 s\n",
      "process 6450 peaks takes 5.8 s\n",
      "process 6500 peaks takes 5.8 s\n",
      "process 6550 peaks takes 5.9 s\n",
      "process 6600 peaks takes 5.9 s\n",
      "process 6650 peaks takes 5.9 s\n",
      "process 6700 peaks takes 6.0 s\n",
      "process 6750 peaks takes 6.0 s\n",
      "process 6800 peaks takes 6.1 s\n",
      "process 6850 peaks takes 6.1 s\n",
      "process 6900 peaks takes 6.1 s\n",
      "process 6950 peaks takes 6.2 s\n",
      "process 7000 peaks takes 6.2 s\n",
      "process 7050 peaks takes 6.3 s\n",
      "process 7100 peaks takes 6.3 s\n",
      "process 7150 peaks takes 6.4 s\n",
      "process 7200 peaks takes 6.4 s\n",
      "process 7250 peaks takes 6.4 s\n",
      "process 7300 peaks takes 6.5 s\n",
      "process 7350 peaks takes 6.5 s\n",
      "process 7400 peaks takes 6.5 s\n",
      "process 7450 peaks takes 6.6 s\n",
      "process 7500 peaks takes 6.6 s\n",
      "process 7550 peaks takes 6.7 s\n",
      "process 7600 peaks takes 6.7 s\n",
      "process 7650 peaks takes 6.7 s\n",
      "process 7700 peaks takes 6.8 s\n",
      "process 7750 peaks takes 6.8 s\n",
      "process 7800 peaks takes 6.9 s\n",
      "process 7850 peaks takes 6.9 s\n",
      "process 7900 peaks takes 6.9 s\n",
      "process 7950 peaks takes 7.0 s\n",
      "process 8000 peaks takes 7.0 s\n",
      "process 8050 peaks takes 7.0 s\n",
      "process 8100 peaks takes 7.1 s\n",
      "process 8150 peaks takes 7.1 s\n",
      "process 8200 peaks takes 7.1 s\n",
      "process 8250 peaks takes 7.2 s\n",
      "process 8300 peaks takes 7.2 s\n",
      "process 8350 peaks takes 7.3 s\n",
      "process 8400 peaks takes 7.3 s\n",
      "process 8450 peaks takes 7.4 s\n",
      "process 8500 peaks takes 7.4 s\n",
      "process 8550 peaks takes 7.5 s\n",
      "process 8600 peaks takes 7.5 s\n",
      "process 8650 peaks takes 7.5 s\n",
      "process 8700 peaks takes 7.6 s\n",
      "process 8750 peaks takes 7.6 s\n",
      "process 8800 peaks takes 7.6 s\n",
      "process 8850 peaks takes 7.7 s\n",
      "process 8900 peaks takes 7.7 s\n",
      "process 8950 peaks takes 7.8 s\n",
      "process 9000 peaks takes 7.8 s\n",
      "process 9050 peaks takes 7.9 s\n",
      "process 9100 peaks takes 7.9 s\n",
      "process 9150 peaks takes 8.0 s\n",
      "process 9200 peaks takes 8.0 s\n",
      "process 9250 peaks takes 8.0 s\n",
      "process 9300 peaks takes 8.1 s\n",
      "process 9350 peaks takes 8.1 s\n",
      "process 9400 peaks takes 8.1 s\n",
      "process 9450 peaks takes 8.2 s\n",
      "process 9500 peaks takes 8.2 s\n",
      "process 9550 peaks takes 8.3 s\n",
      "process 9600 peaks takes 8.3 s\n",
      "process 9650 peaks takes 8.3 s\n",
      "process 9700 peaks takes 8.4 s\n",
      "process 9750 peaks takes 8.4 s\n",
      "process 9800 peaks takes 8.5 s\n",
      "process 9850 peaks takes 8.5 s\n",
      "process 9900 peaks takes 8.5 s\n",
      "process 9950 peaks takes 8.6 s\n",
      "process 10000 peaks takes 8.6 s\n",
      "process 10050 peaks takes 8.7 s\n",
      "process 10100 peaks takes 8.7 s\n",
      "process 10150 peaks takes 8.7 s\n",
      "process 10200 peaks takes 8.8 s\n",
      "process 10250 peaks takes 8.8 s\n",
      "process 10300 peaks takes 8.8 s\n",
      "process 10350 peaks takes 8.9 s\n",
      "process 10400 peaks takes 8.9 s\n",
      "process 10450 peaks takes 9.0 s\n",
      "process 10500 peaks takes 9.0 s\n",
      "process 10550 peaks takes 9.1 s\n",
      "process 10600 peaks takes 9.1 s\n",
      "process 10650 peaks takes 9.1 s\n",
      "process 10700 peaks takes 9.2 s\n",
      "process 10750 peaks takes 9.2 s\n",
      "process 10800 peaks takes 9.3 s\n",
      "process 10850 peaks takes 9.3 s\n",
      "process 10900 peaks takes 9.4 s\n",
      "process 10950 peaks takes 9.4 s\n",
      "process 11000 peaks takes 9.4 s\n",
      "process 11050 peaks takes 9.5 s\n",
      "process 11100 peaks takes 9.5 s\n",
      "process 11150 peaks takes 9.6 s\n",
      "process 11200 peaks takes 9.6 s\n",
      "process 11250 peaks takes 9.6 s\n",
      "process 11300 peaks takes 9.7 s\n",
      "process 11350 peaks takes 9.7 s\n",
      "process 11400 peaks takes 9.8 s\n",
      "process 11450 peaks takes 9.8 s\n",
      "process 11500 peaks takes 9.8 s\n",
      "process 11550 peaks takes 9.9 s\n",
      "process 11600 peaks takes 9.9 s\n",
      "process 11650 peaks takes 10.0 s\n",
      "process 11700 peaks takes 10.0 s\n",
      "process 11750 peaks takes 10.0 s\n",
      "process 11800 peaks takes 10.1 s\n",
      "process 11850 peaks takes 10.1 s\n",
      "process 11900 peaks takes 10.2 s\n",
      "process 11950 peaks takes 10.2 s\n",
      "process 12000 peaks takes 10.2 s\n",
      "process 12050 peaks takes 10.3 s\n",
      "process 12100 peaks takes 10.3 s\n",
      "process 12150 peaks takes 10.4 s\n",
      "process 12200 peaks takes 10.4 s\n",
      "process 12250 peaks takes 10.4 s\n",
      "process 12300 peaks takes 10.5 s\n",
      "process 12350 peaks takes 10.5 s\n",
      "process 12400 peaks takes 10.6 s\n",
      "process 12450 peaks takes 10.6 s\n",
      "process 12500 peaks takes 10.6 s\n",
      "process 12550 peaks takes 10.7 s\n",
      "process 12600 peaks takes 10.7 s\n",
      "process 12650 peaks takes 10.8 s\n",
      "process 12700 peaks takes 10.8 s\n",
      "process 12750 peaks takes 10.9 s\n",
      "process 12800 peaks takes 10.9 s\n",
      "process 12850 peaks takes 10.9 s\n",
      "process 12900 peaks takes 11.0 s\n",
      "process 12950 peaks takes 11.0 s\n",
      "process 13000 peaks takes 11.1 s\n",
      "process 13050 peaks takes 11.1 s\n",
      "process 13100 peaks takes 11.1 s\n",
      "process 13150 peaks takes 11.2 s\n",
      "process 13200 peaks takes 11.2 s\n",
      "process 13250 peaks takes 11.3 s\n",
      "process 13300 peaks takes 11.3 s\n",
      "process 13350 peaks takes 11.3 s\n",
      "process 13400 peaks takes 11.4 s\n",
      "process 13450 peaks takes 11.4 s\n",
      "process 13500 peaks takes 11.5 s\n",
      "process 13550 peaks takes 11.5 s\n",
      "process 13600 peaks takes 11.5 s\n",
      "process 13650 peaks takes 11.6 s\n",
      "process 13700 peaks takes 11.6 s\n",
      "process 13750 peaks takes 11.7 s\n",
      "process 13800 peaks takes 11.7 s\n",
      "process 13850 peaks takes 11.7 s\n",
      "process 13900 peaks takes 11.8 s\n",
      "process 13950 peaks takes 11.8 s\n",
      "process 14000 peaks takes 11.9 s\n",
      "process 14050 peaks takes 11.9 s\n",
      "process 14100 peaks takes 11.9 s\n",
      "process 14150 peaks takes 12.0 s\n",
      "process 14200 peaks takes 12.0 s\n",
      "process 14250 peaks takes 12.1 s\n",
      "process 14300 peaks takes 12.1 s\n",
      "process 14350 peaks takes 12.1 s\n",
      "process 14400 peaks takes 12.2 s\n",
      "process 14450 peaks takes 12.2 s\n",
      "process 14500 peaks takes 12.3 s\n",
      "process 14550 peaks takes 12.3 s\n",
      "process 14600 peaks takes 12.3 s\n",
      "process 14650 peaks takes 12.4 s\n",
      "process 14700 peaks takes 12.4 s\n",
      "process 14750 peaks takes 12.4 s\n",
      "process 14800 peaks takes 12.5 s\n",
      "process 14850 peaks takes 12.5 s\n",
      "process 14900 peaks takes 12.6 s\n",
      "process 14950 peaks takes 12.6 s\n",
      "process 15000 peaks takes 12.7 s\n",
      "process 15050 peaks takes 12.7 s\n",
      "process 15100 peaks takes 12.7 s\n",
      "process 15150 peaks takes 12.8 s\n",
      "process 15200 peaks takes 12.8 s\n",
      "process 15250 peaks takes 12.8 s\n",
      "process 15300 peaks takes 12.9 s\n",
      "process 15350 peaks takes 12.9 s\n",
      "process 15400 peaks takes 13.0 s\n",
      "process 15450 peaks takes 13.0 s\n",
      "process 15500 peaks takes 13.1 s\n",
      "process 15550 peaks takes 13.1 s\n",
      "process 15600 peaks takes 13.1 s\n",
      "process 15650 peaks takes 13.2 s\n",
      "process 15700 peaks takes 13.2 s\n",
      "process 15750 peaks takes 13.2 s\n",
      "process 15800 peaks takes 13.3 s\n",
      "process 15850 peaks takes 13.3 s\n",
      "process 15900 peaks takes 13.4 s\n",
      "process 15950 peaks takes 13.4 s\n",
      "process 16000 peaks takes 13.4 s\n",
      "process 16050 peaks takes 13.5 s\n",
      "process 16100 peaks takes 13.5 s\n",
      "process 16150 peaks takes 13.6 s\n",
      "process 16200 peaks takes 13.6 s\n",
      "process 16250 peaks takes 13.7 s\n",
      "process 16300 peaks takes 13.7 s\n",
      "process 16350 peaks takes 13.7 s\n",
      "process 16400 peaks takes 13.8 s\n",
      "process 16450 peaks takes 13.8 s\n",
      "process 16500 peaks takes 13.9 s\n",
      "process 16550 peaks takes 13.9 s\n",
      "process 16600 peaks takes 13.9 s\n",
      "process 16650 peaks takes 14.0 s\n",
      "process 16700 peaks takes 14.0 s\n",
      "process 16750 peaks takes 14.1 s\n",
      "process 16800 peaks takes 14.1 s\n",
      "process 16850 peaks takes 14.1 s\n",
      "process 16900 peaks takes 14.2 s\n",
      "process 16950 peaks takes 14.2 s\n",
      "process 17000 peaks takes 14.3 s\n",
      "process 17050 peaks takes 14.3 s\n",
      "process 17100 peaks takes 14.3 s\n",
      "process 17150 peaks takes 14.4 s\n",
      "process 17200 peaks takes 14.4 s\n",
      "process 17250 peaks takes 14.5 s\n",
      "process 17300 peaks takes 14.5 s\n",
      "process 17350 peaks takes 14.5 s\n",
      "process 17400 peaks takes 14.6 s\n",
      "process 17450 peaks takes 14.6 s\n",
      "process 17500 peaks takes 14.7 s\n",
      "process 17550 peaks takes 14.7 s\n",
      "process 17600 peaks takes 14.7 s\n",
      "process 17650 peaks takes 14.8 s\n",
      "process 17700 peaks takes 14.8 s\n",
      "process 17750 peaks takes 14.9 s\n",
      "process 17800 peaks takes 14.9 s\n",
      "process 17850 peaks takes 14.9 s\n",
      "process 17900 peaks takes 15.0 s\n",
      "process 17950 peaks takes 15.0 s\n",
      "process 18000 peaks takes 15.1 s\n",
      "process 18050 peaks takes 15.1 s\n",
      "process 18100 peaks takes 15.1 s\n",
      "process 18150 peaks takes 15.2 s\n",
      "process 18200 peaks takes 15.2 s\n",
      "process 18250 peaks takes 15.2 s\n",
      "process 18300 peaks takes 15.3 s\n",
      "process 18350 peaks takes 15.3 s\n",
      "process 18400 peaks takes 15.4 s\n",
      "process 18450 peaks takes 15.4 s\n",
      "process 18500 peaks takes 15.5 s\n",
      "process 18550 peaks takes 15.5 s\n",
      "process 18600 peaks takes 15.5 s\n",
      "process 18650 peaks takes 15.6 s\n",
      "process 18700 peaks takes 15.6 s\n",
      "process 18750 peaks takes 15.7 s\n",
      "process 18800 peaks takes 15.7 s\n",
      "process 18850 peaks takes 15.7 s\n",
      "process 18900 peaks takes 15.8 s\n",
      "process 18950 peaks takes 15.8 s\n",
      "process 19000 peaks takes 15.9 s\n",
      "process 19050 peaks takes 15.9 s\n",
      "process 19100 peaks takes 15.9 s\n",
      "process 19150 peaks takes 16.0 s\n",
      "process 19200 peaks takes 16.0 s\n",
      "process 19250 peaks takes 16.1 s\n",
      "process 19300 peaks takes 16.1 s\n",
      "process 19350 peaks takes 16.1 s\n",
      "process 19400 peaks takes 16.2 s\n",
      "process 19450 peaks takes 16.2 s\n",
      "process 19500 peaks takes 16.3 s\n",
      "process 19550 peaks takes 16.3 s\n",
      "process 19600 peaks takes 16.3 s\n",
      "process 19650 peaks takes 16.4 s\n",
      "process 19700 peaks takes 16.4 s\n",
      "process 19750 peaks takes 16.4 s\n",
      "process 19800 peaks takes 16.5 s\n",
      "process 19850 peaks takes 16.5 s\n",
      "process 19900 peaks takes 16.6 s\n",
      "process 19950 peaks takes 16.6 s\n",
      "process 20000 peaks takes 16.7 s\n",
      "process 20050 peaks takes 16.7 s\n",
      "process 20100 peaks takes 16.7 s\n",
      "process 20150 peaks takes 16.8 s\n",
      "process 20200 peaks takes 16.8 s\n",
      "process 20250 peaks takes 16.9 s\n",
      "process 20300 peaks takes 16.9 s\n",
      "process 20350 peaks takes 16.9 s\n",
      "process 20400 peaks takes 17.0 s\n",
      "process 20450 peaks takes 17.0 s\n",
      "process 20500 peaks takes 17.0 s\n",
      "process 20550 peaks takes 17.1 s\n",
      "process 20600 peaks takes 17.1 s\n",
      "process 20650 peaks takes 17.2 s\n",
      "process 20700 peaks takes 17.2 s\n",
      "process 20750 peaks takes 17.3 s\n",
      "process 20800 peaks takes 17.3 s\n",
      "process 20850 peaks takes 17.3 s\n",
      "process 20900 peaks takes 17.4 s\n",
      "process 20950 peaks takes 17.4 s\n",
      "process 21000 peaks takes 17.5 s\n",
      "process 21050 peaks takes 17.5 s\n",
      "process 21100 peaks takes 17.5 s\n",
      "process 21150 peaks takes 17.6 s\n",
      "process 21200 peaks takes 17.6 s\n",
      "process 21250 peaks takes 17.7 s\n",
      "process 21300 peaks takes 17.7 s\n",
      "process 21350 peaks takes 17.7 s\n",
      "process 21400 peaks takes 17.8 s\n",
      "process 21450 peaks takes 17.8 s\n",
      "process 21500 peaks takes 17.9 s\n",
      "process 21550 peaks takes 17.9 s\n",
      "process 21600 peaks takes 18.0 s\n",
      "process 21650 peaks takes 18.0 s\n",
      "process 21700 peaks takes 18.0 s\n",
      "process 21750 peaks takes 18.1 s\n",
      "process 21800 peaks takes 18.1 s\n",
      "process 21850 peaks takes 18.2 s\n",
      "process 21900 peaks takes 18.2 s\n",
      "process 21950 peaks takes 18.2 s\n",
      "process 22000 peaks takes 18.3 s\n",
      "process 22050 peaks takes 18.3 s\n",
      "process 22100 peaks takes 18.4 s\n",
      "process 22150 peaks takes 18.4 s\n",
      "process 22200 peaks takes 18.4 s\n",
      "process 22250 peaks takes 18.5 s\n",
      "process 22300 peaks takes 18.5 s\n",
      "process 22350 peaks takes 18.6 s\n",
      "process 22400 peaks takes 18.6 s\n",
      "process 22450 peaks takes 18.6 s\n",
      "process 22500 peaks takes 18.7 s\n",
      "process 22550 peaks takes 18.7 s\n",
      "process 22600 peaks takes 18.8 s\n",
      "process 22650 peaks takes 18.8 s\n",
      "process 22700 peaks takes 18.9 s\n",
      "process 22750 peaks takes 18.9 s\n",
      "process 22800 peaks takes 18.9 s\n",
      "process 22850 peaks takes 19.0 s\n",
      "process 22900 peaks takes 19.0 s\n",
      "process 22950 peaks takes 19.0 s\n",
      "process 23000 peaks takes 19.1 s\n",
      "process 23050 peaks takes 19.1 s\n",
      "process 23100 peaks takes 19.2 s\n",
      "process 23150 peaks takes 19.2 s\n",
      "process 23200 peaks takes 19.2 s\n",
      "process 23250 peaks takes 19.3 s\n",
      "process 23300 peaks takes 19.3 s\n",
      "process 23350 peaks takes 19.4 s\n",
      "process 23400 peaks takes 19.4 s\n",
      "process 23450 peaks takes 19.5 s\n",
      "process 23500 peaks takes 19.5 s\n",
      "process 23550 peaks takes 19.5 s\n",
      "process 23600 peaks takes 19.6 s\n",
      "process 23650 peaks takes 19.6 s\n",
      "process 23700 peaks takes 19.7 s\n",
      "process 23750 peaks takes 19.7 s\n",
      "process 23800 peaks takes 19.7 s\n",
      "process 23850 peaks takes 19.8 s\n",
      "process 23900 peaks takes 19.8 s\n",
      "process 23950 peaks takes 19.9 s\n",
      "process 24000 peaks takes 19.9 s\n",
      "process 24050 peaks takes 19.9 s\n",
      "process 24100 peaks takes 20.0 s\n",
      "process 24150 peaks takes 20.0 s\n",
      "process 24200 peaks takes 20.1 s\n",
      "process 24250 peaks takes 20.1 s\n",
      "process 24300 peaks takes 20.1 s\n",
      "process 24350 peaks takes 20.2 s\n",
      "process 24400 peaks takes 20.3 s\n",
      "process 24450 peaks takes 20.3 s\n",
      "process 24500 peaks takes 20.3 s\n",
      "process 24550 peaks takes 20.4 s\n",
      "process 24600 peaks takes 20.4 s\n",
      "process 24650 peaks takes 20.5 s\n",
      "process 24700 peaks takes 20.5 s\n",
      "process 24750 peaks takes 20.6 s\n",
      "process 24800 peaks takes 20.6 s\n",
      "process 24850 peaks takes 20.6 s\n",
      "process 24900 peaks takes 20.7 s\n",
      "process 24950 peaks takes 20.7 s\n",
      "process 25000 peaks takes 20.8 s\n",
      "process 25050 peaks takes 20.8 s\n",
      "process 25100 peaks takes 20.9 s\n",
      "process 25150 peaks takes 20.9 s\n",
      "process 25200 peaks takes 20.9 s\n",
      "process 25250 peaks takes 21.0 s\n",
      "process 25300 peaks takes 21.0 s\n",
      "process 25350 peaks takes 21.1 s\n",
      "process 25400 peaks takes 21.1 s\n",
      "process 25450 peaks takes 21.2 s\n",
      "process 25500 peaks takes 21.2 s\n",
      "process 25550 peaks takes 21.2 s\n",
      "process 25600 peaks takes 21.3 s\n",
      "process 25650 peaks takes 21.3 s\n",
      "process 25700 peaks takes 21.4 s\n",
      "process 25750 peaks takes 21.4 s\n",
      "process 25800 peaks takes 21.4 s\n",
      "process 25850 peaks takes 21.5 s\n",
      "process 25900 peaks takes 21.5 s\n",
      "process 25950 peaks takes 21.5 s\n",
      "process 26000 peaks takes 21.6 s\n",
      "process 26050 peaks takes 21.6 s\n",
      "process 26100 peaks takes 21.7 s\n",
      "process 26150 peaks takes 21.7 s\n",
      "process 26200 peaks takes 21.8 s\n",
      "process 26250 peaks takes 21.8 s\n",
      "process 26300 peaks takes 21.8 s\n",
      "process 26350 peaks takes 21.9 s\n",
      "process 26400 peaks takes 21.9 s\n",
      "process 26450 peaks takes 21.9 s\n",
      "process 26500 peaks takes 22.0 s\n",
      "process 26550 peaks takes 22.0 s\n",
      "process 26600 peaks takes 22.1 s\n",
      "process 26650 peaks takes 22.1 s\n",
      "process 26700 peaks takes 22.2 s\n",
      "process 26750 peaks takes 22.2 s\n",
      "process 26800 peaks takes 22.3 s\n",
      "process 26850 peaks takes 22.3 s\n",
      "process 26900 peaks takes 22.3 s\n",
      "process 26950 peaks takes 22.4 s\n",
      "process 27000 peaks takes 22.4 s\n",
      "process 27050 peaks takes 22.5 s\n",
      "process 27100 peaks takes 22.5 s\n",
      "process 27150 peaks takes 22.5 s\n",
      "process 27200 peaks takes 22.6 s\n",
      "process 27250 peaks takes 22.6 s\n",
      "process 27300 peaks takes 22.7 s\n",
      "process 27350 peaks takes 22.7 s\n",
      "process 27400 peaks takes 22.7 s\n",
      "process 27450 peaks takes 22.8 s\n",
      "process 27500 peaks takes 22.8 s\n",
      "process 27550 peaks takes 22.9 s\n",
      "process 27600 peaks takes 22.9 s\n",
      "process 27650 peaks takes 23.0 s\n",
      "process 27700 peaks takes 23.0 s\n",
      "process 27750 peaks takes 23.0 s\n",
      "process 27800 peaks takes 23.1 s\n",
      "process 27850 peaks takes 23.1 s\n",
      "process 27900 peaks takes 23.2 s\n",
      "process 27950 peaks takes 23.2 s\n",
      "process 28000 peaks takes 23.3 s\n",
      "process 28050 peaks takes 23.3 s\n",
      "process 28100 peaks takes 23.3 s\n",
      "process 28150 peaks takes 23.4 s\n",
      "process 28200 peaks takes 23.4 s\n",
      "process 28250 peaks takes 23.5 s\n",
      "process 28300 peaks takes 23.5 s\n",
      "process 28350 peaks takes 23.6 s\n",
      "process 28400 peaks takes 23.6 s\n",
      "process 28450 peaks takes 23.6 s\n",
      "process 28500 peaks takes 23.7 s\n",
      "process 28550 peaks takes 23.7 s\n",
      "process 28600 peaks takes 23.8 s\n",
      "process 28650 peaks takes 23.8 s\n",
      "process 28700 peaks takes 23.9 s\n",
      "process 28750 peaks takes 23.9 s\n",
      "process 28800 peaks takes 23.9 s\n",
      "process 28850 peaks takes 24.0 s\n",
      "process 28900 peaks takes 24.0 s\n",
      "process 28950 peaks takes 24.1 s\n",
      "process 29000 peaks takes 24.1 s\n",
      "process 29050 peaks takes 24.1 s\n",
      "process 29100 peaks takes 24.2 s\n",
      "process 29150 peaks takes 24.2 s\n",
      "process 29200 peaks takes 24.3 s\n",
      "process 29250 peaks takes 24.3 s\n",
      "process 29300 peaks takes 24.3 s\n",
      "process 29350 peaks takes 24.4 s\n",
      "process 29400 peaks takes 24.4 s\n",
      "process 29450 peaks takes 24.5 s\n",
      "process 29500 peaks takes 24.5 s\n",
      "process 29550 peaks takes 24.5 s\n",
      "process 29600 peaks takes 24.6 s\n",
      "process 29650 peaks takes 24.6 s\n",
      "process 29700 peaks takes 24.7 s\n",
      "process 29750 peaks takes 24.7 s\n",
      "process 29800 peaks takes 24.8 s\n",
      "process 29850 peaks takes 24.8 s\n",
      "process 29900 peaks takes 24.8 s\n",
      "process 29950 peaks takes 24.9 s\n",
      "\n",
      "train\n",
      "27001 540\n",
      "process 0 peaks takes 0.4 s\n",
      "process 50 peaks takes 0.4 s\n",
      "process 100 peaks takes 0.5 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.6 s\n",
      "process 250 peaks takes 0.6 s\n",
      "process 300 peaks takes 0.6 s\n",
      "process 350 peaks takes 0.7 s\n",
      "process 400 peaks takes 0.7 s\n",
      "process 450 peaks takes 0.8 s\n",
      "process 500 peaks takes 0.8 s\n",
      "process 550 peaks takes 0.9 s\n",
      "process 600 peaks takes 0.9 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.1 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.2 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.3 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.4 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.5 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.6 s\n",
      "process 3850 peaks takes 3.6 s\n",
      "process 3900 peaks takes 3.7 s\n",
      "process 3950 peaks takes 3.7 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.8 s\n",
      "process 4100 peaks takes 3.9 s\n",
      "process 4150 peaks takes 3.9 s\n",
      "process 4200 peaks takes 3.9 s\n",
      "process 4250 peaks takes 4.0 s\n",
      "process 4300 peaks takes 4.0 s\n",
      "process 4350 peaks takes 4.1 s\n",
      "process 4400 peaks takes 4.1 s\n",
      "process 4450 peaks takes 4.1 s\n",
      "process 4500 peaks takes 4.2 s\n",
      "process 4550 peaks takes 4.2 s\n",
      "process 4600 peaks takes 4.3 s\n",
      "process 4650 peaks takes 4.3 s\n",
      "process 4700 peaks takes 4.4 s\n",
      "process 4750 peaks takes 4.4 s\n",
      "process 4800 peaks takes 4.4 s\n",
      "process 4850 peaks takes 4.5 s\n",
      "process 4900 peaks takes 4.5 s\n",
      "process 4950 peaks takes 4.6 s\n",
      "process 5000 peaks takes 4.6 s\n",
      "process 5050 peaks takes 4.7 s\n",
      "process 5100 peaks takes 4.7 s\n",
      "process 5150 peaks takes 4.7 s\n",
      "process 5200 peaks takes 4.8 s\n",
      "process 5250 peaks takes 4.8 s\n",
      "process 5300 peaks takes 4.9 s\n",
      "process 5350 peaks takes 4.9 s\n",
      "process 5400 peaks takes 4.9 s\n",
      "process 5450 peaks takes 5.0 s\n",
      "process 5500 peaks takes 5.0 s\n",
      "process 5550 peaks takes 5.1 s\n",
      "process 5600 peaks takes 5.1 s\n",
      "process 5650 peaks takes 5.1 s\n",
      "process 5700 peaks takes 5.2 s\n",
      "process 5750 peaks takes 5.2 s\n",
      "process 5800 peaks takes 5.3 s\n",
      "process 5850 peaks takes 5.3 s\n",
      "process 5900 peaks takes 5.3 s\n",
      "process 5950 peaks takes 5.4 s\n",
      "process 6000 peaks takes 5.4 s\n",
      "process 6050 peaks takes 5.5 s\n",
      "process 6100 peaks takes 5.5 s\n",
      "process 6150 peaks takes 5.5 s\n",
      "process 6200 peaks takes 5.6 s\n",
      "process 6250 peaks takes 5.6 s\n",
      "process 6300 peaks takes 5.7 s\n",
      "process 6350 peaks takes 5.7 s\n",
      "process 6400 peaks takes 5.8 s\n",
      "process 6450 peaks takes 5.8 s\n",
      "process 6500 peaks takes 5.8 s\n",
      "process 6550 peaks takes 5.9 s\n",
      "process 6600 peaks takes 5.9 s\n",
      "process 6650 peaks takes 6.0 s\n",
      "process 6700 peaks takes 6.0 s\n",
      "process 6750 peaks takes 6.1 s\n",
      "process 6800 peaks takes 6.1 s\n",
      "process 6850 peaks takes 6.1 s\n",
      "process 6900 peaks takes 6.2 s\n",
      "process 6950 peaks takes 6.2 s\n",
      "process 7000 peaks takes 6.3 s\n",
      "process 7050 peaks takes 6.3 s\n",
      "process 7100 peaks takes 6.3 s\n",
      "process 7150 peaks takes 6.4 s\n",
      "process 7200 peaks takes 6.4 s\n",
      "process 7250 peaks takes 6.5 s\n",
      "process 7300 peaks takes 6.5 s\n",
      "process 7350 peaks takes 6.5 s\n",
      "process 7400 peaks takes 6.6 s\n",
      "process 7450 peaks takes 6.6 s\n",
      "process 7500 peaks takes 6.6 s\n",
      "process 7550 peaks takes 6.7 s\n",
      "process 7600 peaks takes 6.7 s\n",
      "process 7650 peaks takes 6.8 s\n",
      "process 7700 peaks takes 6.8 s\n",
      "process 7750 peaks takes 6.9 s\n",
      "process 7800 peaks takes 6.9 s\n",
      "process 7850 peaks takes 7.0 s\n",
      "process 7900 peaks takes 7.0 s\n",
      "process 7950 peaks takes 7.1 s\n",
      "process 8000 peaks takes 7.1 s\n",
      "process 8050 peaks takes 7.1 s\n",
      "process 8100 peaks takes 7.2 s\n",
      "process 8150 peaks takes 7.2 s\n",
      "process 8200 peaks takes 7.3 s\n",
      "process 8250 peaks takes 7.3 s\n",
      "process 8300 peaks takes 7.4 s\n",
      "process 8350 peaks takes 7.4 s\n",
      "process 8400 peaks takes 7.4 s\n",
      "process 8450 peaks takes 7.5 s\n",
      "process 8500 peaks takes 7.5 s\n",
      "process 8550 peaks takes 7.6 s\n",
      "process 8600 peaks takes 7.6 s\n",
      "process 8650 peaks takes 7.7 s\n",
      "process 8700 peaks takes 7.7 s\n",
      "process 8750 peaks takes 7.7 s\n",
      "process 8800 peaks takes 7.8 s\n",
      "process 8850 peaks takes 7.8 s\n",
      "process 8900 peaks takes 7.9 s\n",
      "process 8950 peaks takes 7.9 s\n",
      "process 9000 peaks takes 7.9 s\n",
      "process 9050 peaks takes 8.0 s\n",
      "process 9100 peaks takes 8.0 s\n",
      "process 9150 peaks takes 8.0 s\n",
      "process 9200 peaks takes 8.1 s\n",
      "process 9250 peaks takes 8.1 s\n",
      "process 9300 peaks takes 8.2 s\n",
      "process 9350 peaks takes 8.2 s\n",
      "process 9400 peaks takes 8.3 s\n",
      "process 9450 peaks takes 8.3 s\n",
      "process 9500 peaks takes 8.3 s\n",
      "process 9550 peaks takes 8.4 s\n",
      "process 9600 peaks takes 8.4 s\n",
      "process 9650 peaks takes 8.5 s\n",
      "process 9700 peaks takes 8.5 s\n",
      "process 9750 peaks takes 8.6 s\n",
      "process 9800 peaks takes 8.6 s\n",
      "process 9850 peaks takes 8.6 s\n",
      "process 9900 peaks takes 8.7 s\n",
      "process 9950 peaks takes 8.8 s\n",
      "process 10000 peaks takes 8.8 s\n",
      "process 10050 peaks takes 8.8 s\n",
      "process 10100 peaks takes 8.9 s\n",
      "process 10150 peaks takes 8.9 s\n",
      "process 10200 peaks takes 9.0 s\n",
      "process 10250 peaks takes 9.0 s\n",
      "process 10300 peaks takes 9.0 s\n",
      "process 10350 peaks takes 9.1 s\n",
      "process 10400 peaks takes 9.1 s\n",
      "process 10450 peaks takes 9.2 s\n",
      "process 10500 peaks takes 9.2 s\n",
      "process 10550 peaks takes 9.2 s\n",
      "process 10600 peaks takes 9.3 s\n",
      "process 10650 peaks takes 9.3 s\n",
      "process 10700 peaks takes 9.3 s\n",
      "process 10750 peaks takes 9.4 s\n",
      "process 10800 peaks takes 9.4 s\n",
      "process 10850 peaks takes 9.5 s\n",
      "process 10900 peaks takes 9.5 s\n",
      "process 10950 peaks takes 9.5 s\n",
      "process 11000 peaks takes 9.6 s\n",
      "process 11050 peaks takes 9.6 s\n",
      "process 11100 peaks takes 9.7 s\n",
      "process 11150 peaks takes 9.7 s\n",
      "process 11200 peaks takes 9.7 s\n",
      "process 11250 peaks takes 9.8 s\n",
      "process 11300 peaks takes 9.8 s\n",
      "process 11350 peaks takes 9.9 s\n",
      "process 11400 peaks takes 9.9 s\n",
      "process 11450 peaks takes 10.0 s\n",
      "process 11500 peaks takes 10.0 s\n",
      "process 11550 peaks takes 10.1 s\n",
      "process 11600 peaks takes 10.1 s\n",
      "process 11650 peaks takes 10.1 s\n",
      "process 11700 peaks takes 10.2 s\n",
      "process 11750 peaks takes 10.2 s\n",
      "process 11800 peaks takes 10.3 s\n",
      "process 11850 peaks takes 10.3 s\n",
      "process 11900 peaks takes 10.3 s\n",
      "process 11950 peaks takes 10.4 s\n",
      "process 12000 peaks takes 10.4 s\n",
      "process 12050 peaks takes 10.4 s\n",
      "process 12100 peaks takes 10.5 s\n",
      "process 12150 peaks takes 10.5 s\n",
      "process 12200 peaks takes 10.6 s\n",
      "process 12250 peaks takes 10.6 s\n",
      "process 12300 peaks takes 10.7 s\n",
      "process 12350 peaks takes 10.7 s\n",
      "process 12400 peaks takes 10.7 s\n",
      "process 12450 peaks takes 10.8 s\n",
      "process 12500 peaks takes 10.8 s\n",
      "process 12550 peaks takes 10.9 s\n",
      "process 12600 peaks takes 10.9 s\n",
      "process 12650 peaks takes 10.9 s\n",
      "process 12700 peaks takes 11.0 s\n",
      "process 12750 peaks takes 11.0 s\n",
      "process 12800 peaks takes 11.0 s\n",
      "process 12850 peaks takes 11.1 s\n",
      "process 12900 peaks takes 11.1 s\n",
      "process 12950 peaks takes 11.2 s\n",
      "process 13000 peaks takes 11.2 s\n",
      "process 13050 peaks takes 11.2 s\n",
      "process 13100 peaks takes 11.3 s\n",
      "process 13150 peaks takes 11.3 s\n",
      "process 13200 peaks takes 11.4 s\n",
      "process 13250 peaks takes 11.4 s\n",
      "process 13300 peaks takes 11.5 s\n",
      "process 13350 peaks takes 11.5 s\n",
      "process 13400 peaks takes 11.5 s\n",
      "process 13450 peaks takes 11.6 s\n",
      "process 13500 peaks takes 11.6 s\n",
      "process 13550 peaks takes 11.6 s\n",
      "process 13600 peaks takes 11.7 s\n",
      "process 13650 peaks takes 11.7 s\n",
      "process 13700 peaks takes 11.8 s\n",
      "process 13750 peaks takes 11.8 s\n",
      "process 13800 peaks takes 11.9 s\n",
      "process 13850 peaks takes 11.9 s\n",
      "process 13900 peaks takes 11.9 s\n",
      "process 13950 peaks takes 12.0 s\n",
      "process 14000 peaks takes 12.0 s\n",
      "process 14050 peaks takes 12.1 s\n",
      "process 14100 peaks takes 12.1 s\n",
      "process 14150 peaks takes 12.1 s\n",
      "process 14200 peaks takes 12.2 s\n",
      "process 14250 peaks takes 12.2 s\n",
      "process 14300 peaks takes 12.3 s\n",
      "process 14350 peaks takes 12.3 s\n",
      "process 14400 peaks takes 12.3 s\n",
      "process 14450 peaks takes 12.4 s\n",
      "process 14500 peaks takes 12.4 s\n",
      "process 14550 peaks takes 12.5 s\n",
      "process 14600 peaks takes 12.5 s\n",
      "process 14650 peaks takes 12.6 s\n",
      "process 14700 peaks takes 12.6 s\n",
      "process 14750 peaks takes 12.6 s\n",
      "process 14800 peaks takes 12.7 s\n",
      "process 14850 peaks takes 12.7 s\n",
      "process 14900 peaks takes 12.8 s\n",
      "process 14950 peaks takes 12.8 s\n",
      "process 15000 peaks takes 12.8 s\n",
      "process 15050 peaks takes 12.9 s\n",
      "process 15100 peaks takes 12.9 s\n",
      "process 15150 peaks takes 12.9 s\n",
      "process 15200 peaks takes 13.0 s\n",
      "process 15250 peaks takes 13.0 s\n",
      "process 15300 peaks takes 13.1 s\n",
      "process 15350 peaks takes 13.1 s\n",
      "process 15400 peaks takes 13.1 s\n",
      "process 15450 peaks takes 13.2 s\n",
      "process 15500 peaks takes 13.2 s\n",
      "process 15550 peaks takes 13.3 s\n",
      "process 15600 peaks takes 13.3 s\n",
      "process 15650 peaks takes 13.4 s\n",
      "process 15700 peaks takes 13.4 s\n",
      "process 15750 peaks takes 13.5 s\n",
      "process 15800 peaks takes 13.5 s\n",
      "process 15850 peaks takes 13.5 s\n",
      "process 15900 peaks takes 13.6 s\n",
      "process 15950 peaks takes 13.6 s\n",
      "process 16000 peaks takes 13.7 s\n",
      "process 16050 peaks takes 13.7 s\n",
      "process 16100 peaks takes 13.7 s\n",
      "process 16150 peaks takes 13.8 s\n",
      "process 16200 peaks takes 13.8 s\n",
      "process 16250 peaks takes 13.9 s\n",
      "process 16300 peaks takes 13.9 s\n",
      "process 16350 peaks takes 14.0 s\n",
      "process 16400 peaks takes 14.0 s\n",
      "process 16450 peaks takes 14.1 s\n",
      "process 16500 peaks takes 14.1 s\n",
      "process 16550 peaks takes 14.1 s\n",
      "process 16600 peaks takes 14.2 s\n",
      "process 16650 peaks takes 14.2 s\n",
      "process 16700 peaks takes 14.3 s\n",
      "process 16750 peaks takes 14.3 s\n",
      "process 16800 peaks takes 14.4 s\n",
      "process 16850 peaks takes 14.4 s\n",
      "process 16900 peaks takes 14.5 s\n",
      "process 16950 peaks takes 14.5 s\n",
      "process 17000 peaks takes 14.6 s\n",
      "process 17050 peaks takes 14.6 s\n",
      "process 17100 peaks takes 14.6 s\n",
      "process 17150 peaks takes 14.7 s\n",
      "process 17200 peaks takes 14.7 s\n",
      "process 17250 peaks takes 14.8 s\n",
      "process 17300 peaks takes 14.8 s\n",
      "process 17350 peaks takes 14.9 s\n",
      "process 17400 peaks takes 14.9 s\n",
      "process 17450 peaks takes 14.9 s\n",
      "process 17500 peaks takes 15.0 s\n",
      "process 17550 peaks takes 15.0 s\n",
      "process 17600 peaks takes 15.1 s\n",
      "process 17650 peaks takes 15.1 s\n",
      "process 17700 peaks takes 15.2 s\n",
      "process 17750 peaks takes 15.2 s\n",
      "process 17800 peaks takes 15.3 s\n",
      "process 17850 peaks takes 15.3 s\n",
      "process 17900 peaks takes 15.3 s\n",
      "process 17950 peaks takes 15.4 s\n",
      "process 18000 peaks takes 15.4 s\n",
      "process 18050 peaks takes 15.5 s\n",
      "process 18100 peaks takes 15.5 s\n",
      "process 18150 peaks takes 15.6 s\n",
      "process 18200 peaks takes 15.6 s\n",
      "process 18250 peaks takes 15.7 s\n",
      "process 18300 peaks takes 15.8 s\n",
      "process 18350 peaks takes 15.8 s\n",
      "process 18400 peaks takes 15.8 s\n",
      "process 18450 peaks takes 15.9 s\n",
      "process 18500 peaks takes 15.9 s\n",
      "process 18550 peaks takes 16.0 s\n",
      "process 18600 peaks takes 16.0 s\n",
      "process 18650 peaks takes 16.1 s\n",
      "process 18700 peaks takes 16.1 s\n",
      "process 18750 peaks takes 16.2 s\n",
      "process 18800 peaks takes 16.2 s\n",
      "process 18850 peaks takes 16.3 s\n",
      "process 18900 peaks takes 16.3 s\n",
      "process 18950 peaks takes 16.4 s\n",
      "process 19000 peaks takes 16.4 s\n",
      "process 19050 peaks takes 16.5 s\n",
      "process 19100 peaks takes 16.5 s\n",
      "process 19150 peaks takes 16.6 s\n",
      "process 19200 peaks takes 16.6 s\n",
      "process 19250 peaks takes 16.8 s\n",
      "process 19300 peaks takes 16.8 s\n",
      "process 19350 peaks takes 16.9 s\n",
      "process 19400 peaks takes 16.9 s\n",
      "process 19450 peaks takes 17.0 s\n",
      "process 19500 peaks takes 17.0 s\n",
      "process 19550 peaks takes 17.1 s\n",
      "process 19600 peaks takes 17.1 s\n",
      "process 19650 peaks takes 17.1 s\n",
      "process 19700 peaks takes 17.2 s\n",
      "process 19750 peaks takes 17.2 s\n",
      "process 19800 peaks takes 17.3 s\n",
      "process 19850 peaks takes 17.3 s\n",
      "process 19900 peaks takes 17.4 s\n",
      "process 19950 peaks takes 17.4 s\n",
      "process 20000 peaks takes 17.5 s\n",
      "process 20050 peaks takes 17.5 s\n",
      "process 20100 peaks takes 17.5 s\n",
      "process 20150 peaks takes 17.6 s\n",
      "process 20200 peaks takes 17.7 s\n",
      "process 20250 peaks takes 17.7 s\n",
      "process 20300 peaks takes 17.7 s\n",
      "process 20350 peaks takes 17.8 s\n",
      "process 20400 peaks takes 17.8 s\n",
      "process 20450 peaks takes 17.9 s\n",
      "process 20500 peaks takes 17.9 s\n",
      "process 20550 peaks takes 18.0 s\n",
      "process 20600 peaks takes 18.0 s\n",
      "process 20650 peaks takes 18.1 s\n",
      "process 20700 peaks takes 18.1 s\n",
      "process 20750 peaks takes 18.2 s\n",
      "process 20800 peaks takes 18.2 s\n",
      "process 20850 peaks takes 18.3 s\n",
      "process 20900 peaks takes 18.3 s\n",
      "process 20950 peaks takes 18.3 s\n",
      "process 21000 peaks takes 18.4 s\n",
      "process 21050 peaks takes 18.5 s\n",
      "process 21100 peaks takes 18.5 s\n",
      "process 21150 peaks takes 18.5 s\n",
      "process 21200 peaks takes 18.6 s\n",
      "process 21250 peaks takes 18.6 s\n",
      "process 21300 peaks takes 18.7 s\n",
      "process 21350 peaks takes 18.7 s\n",
      "process 21400 peaks takes 18.7 s\n",
      "process 21450 peaks takes 18.8 s\n",
      "process 21500 peaks takes 18.8 s\n",
      "process 21550 peaks takes 18.9 s\n",
      "process 21600 peaks takes 18.9 s\n",
      "process 21650 peaks takes 18.9 s\n",
      "process 21700 peaks takes 19.0 s\n",
      "process 21750 peaks takes 19.0 s\n",
      "process 21800 peaks takes 19.1 s\n",
      "process 21850 peaks takes 19.1 s\n",
      "process 21900 peaks takes 19.2 s\n",
      "process 21950 peaks takes 19.2 s\n",
      "process 22000 peaks takes 19.3 s\n",
      "process 22050 peaks takes 19.3 s\n",
      "process 22100 peaks takes 19.3 s\n",
      "process 22150 peaks takes 19.4 s\n",
      "process 22200 peaks takes 19.4 s\n",
      "process 22250 peaks takes 19.5 s\n",
      "process 22300 peaks takes 19.5 s\n",
      "process 22350 peaks takes 19.6 s\n",
      "process 22400 peaks takes 19.6 s\n",
      "process 22450 peaks takes 19.7 s\n",
      "process 22500 peaks takes 19.7 s\n",
      "process 22550 peaks takes 19.7 s\n",
      "process 22600 peaks takes 19.8 s\n",
      "process 22650 peaks takes 19.8 s\n",
      "process 22700 peaks takes 19.9 s\n",
      "process 22750 peaks takes 19.9 s\n",
      "process 22800 peaks takes 20.0 s\n",
      "process 22850 peaks takes 20.0 s\n",
      "process 22900 peaks takes 20.1 s\n",
      "process 22950 peaks takes 20.1 s\n",
      "process 23000 peaks takes 20.2 s\n",
      "process 23050 peaks takes 20.2 s\n",
      "process 23100 peaks takes 20.3 s\n",
      "process 23150 peaks takes 20.3 s\n",
      "process 23200 peaks takes 20.4 s\n",
      "process 23250 peaks takes 20.4 s\n",
      "process 23300 peaks takes 20.5 s\n",
      "process 23350 peaks takes 20.5 s\n",
      "process 23400 peaks takes 20.6 s\n",
      "process 23450 peaks takes 20.6 s\n",
      "process 23500 peaks takes 20.7 s\n",
      "process 23550 peaks takes 20.7 s\n",
      "process 23600 peaks takes 20.8 s\n",
      "process 23650 peaks takes 20.8 s\n",
      "process 23700 peaks takes 20.8 s\n",
      "process 23750 peaks takes 20.9 s\n",
      "process 23800 peaks takes 21.0 s\n",
      "process 23850 peaks takes 21.0 s\n",
      "process 23900 peaks takes 21.0 s\n",
      "process 23950 peaks takes 21.1 s\n",
      "process 24000 peaks takes 21.1 s\n",
      "process 24050 peaks takes 21.2 s\n",
      "process 24100 peaks takes 21.3 s\n",
      "process 24150 peaks takes 21.3 s\n",
      "process 24200 peaks takes 21.4 s\n",
      "process 24250 peaks takes 21.4 s\n",
      "process 24300 peaks takes 21.5 s\n",
      "process 24350 peaks takes 21.5 s\n",
      "process 24400 peaks takes 21.6 s\n",
      "process 24450 peaks takes 21.6 s\n",
      "process 24500 peaks takes 21.7 s\n",
      "process 24550 peaks takes 21.7 s\n",
      "process 24600 peaks takes 21.8 s\n",
      "process 24650 peaks takes 21.8 s\n",
      "process 24700 peaks takes 21.9 s\n",
      "process 24750 peaks takes 21.9 s\n",
      "process 24800 peaks takes 22.0 s\n",
      "process 24850 peaks takes 22.0 s\n",
      "process 24900 peaks takes 22.1 s\n",
      "process 24950 peaks takes 22.1 s\n",
      "process 25000 peaks takes 22.2 s\n",
      "process 25050 peaks takes 22.2 s\n",
      "process 25100 peaks takes 22.3 s\n",
      "process 25150 peaks takes 22.3 s\n",
      "process 25200 peaks takes 22.4 s\n",
      "process 25250 peaks takes 22.4 s\n",
      "process 25300 peaks takes 22.5 s\n",
      "process 25350 peaks takes 22.5 s\n",
      "process 25400 peaks takes 22.6 s\n",
      "process 25450 peaks takes 22.6 s\n",
      "process 25500 peaks takes 22.7 s\n",
      "process 25550 peaks takes 22.7 s\n",
      "process 25600 peaks takes 22.8 s\n",
      "process 25650 peaks takes 22.8 s\n",
      "process 25700 peaks takes 22.9 s\n",
      "process 25750 peaks takes 22.9 s\n",
      "process 25800 peaks takes 23.0 s\n",
      "process 25850 peaks takes 23.0 s\n",
      "process 25900 peaks takes 23.1 s\n",
      "process 25950 peaks takes 23.1 s\n",
      "process 26000 peaks takes 23.2 s\n",
      "process 26050 peaks takes 23.2 s\n",
      "process 26100 peaks takes 23.3 s\n",
      "process 26150 peaks takes 23.3 s\n",
      "process 26200 peaks takes 23.3 s\n",
      "process 26250 peaks takes 23.4 s\n",
      "process 26300 peaks takes 23.4 s\n",
      "process 26350 peaks takes 23.5 s\n",
      "process 26400 peaks takes 23.5 s\n",
      "process 26450 peaks takes 23.6 s\n",
      "process 26500 peaks takes 23.6 s\n",
      "process 26550 peaks takes 23.6 s\n",
      "process 26600 peaks takes 23.7 s\n",
      "process 26650 peaks takes 23.7 s\n",
      "process 26700 peaks takes 23.8 s\n",
      "process 26750 peaks takes 23.8 s\n",
      "process 26800 peaks takes 23.9 s\n",
      "process 26850 peaks takes 23.9 s\n",
      "process 26900 peaks takes 24.0 s\n",
      "process 26950 peaks takes 24.0 s\n",
      "\n",
      "test\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "\n",
      "val\n",
      "1499 29\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs10000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs10000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:46:26.322444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:46:26.418449: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:46:26.421385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:26.421414: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:46:26.904122: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:26.904209: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:26.904216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.9GB.\n",
      "2024-05-13 06:46:29.772223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:46:29.772367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772718: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:46:29.772736: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:46:29.773068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5877)      193941      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5877)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5877)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,713,751\n",
      "Trainable params: 4,707,901\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "211/211 [==============================] - 354s 2s/step - loss: 0.2658 - auc: 0.6435 - auc_1: 0.1209 - val_loss: 0.2329 - val_auc: 0.7016 - val_auc_1: 0.2005\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs10000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs1000_var3000.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs1000_var3000.h5ad\n",
      "noack_2022 random /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs1000_var3000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs1000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs1000_var3000.h5ad\n",
      "(1000, 3000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs1000_var3000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000 --batch 50\n",
      "2024-05-13 06:52:26.957133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:52:27.063681: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:52:27.066614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:27.066645: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:52:27.537966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:27.538041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:27.538060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[2701, 150, 149]\n",
      "3000 60\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.7 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.8 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.9 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 2.0 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.1 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.2 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.4 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.6 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.8 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.9 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 3.0 s\n",
      "process 2650 peaks takes 3.1 s\n",
      "process 2700 peaks takes 3.1 s\n",
      "process 2750 peaks takes 3.2 s\n",
      "process 2800 peaks takes 3.2 s\n",
      "process 2850 peaks takes 3.3 s\n",
      "process 2900 peaks takes 3.3 s\n",
      "process 2950 peaks takes 3.4 s\n",
      "\n",
      "train\n",
      "2701 54\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "\n",
      "test\n",
      "150 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "149 2\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs1000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:52:36.011275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:52:36.110039: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:52:36.112863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:36.112891: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:52:36.658193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:36.658316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:36.658330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:52:38.394826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:52:38.394948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:52:38.395331: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:52:38.395698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "22/22 [==============================] - 49s 2s/step - loss: 0.3907 - auc: 0.5736 - auc_1: 0.0906 - val_loss: 0.6679 - val_auc: 0.6190 - val_auc_1: 0.1295\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs1000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs1000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs1000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs1000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:53:28.847142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:53:28.948438: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:53:28.951383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:28.951412: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:53:29.454788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:29.454859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:29.454865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:53:31.084622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:53:31.084752: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.084819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.084863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.084918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.084963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.085025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.085069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.085124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:53:31.085142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:53:31.085506: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "22/22 [==============================] - 48s 2s/step - loss: 0.4808 - auc: 0.5806 - auc_1: 0.0939 - val_loss: 0.3786 - val_auc: 0.6004 - val_auc_1: 0.0992\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs1000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "noack_2022 episcanpy /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/scbasset_input/obs500\n",
      "out False /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/scbasset_output/obs500_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/episcanpy/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "\n",
      "pancreatic_endocrinogenesis\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "(500, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --batch 50\n",
      "2024-05-13 06:54:22.522128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:54:22.627577: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:54:22.630745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:22.630777: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:54:23.114187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:23.114292: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:23.114299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "\n",
      "train\n",
      "1351 27\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "\n",
      "test\n",
      "75 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "val\n",
      "74 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:54:28.040465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:54:28.130545: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:54:28.133416: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:28.133445: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:54:28.627864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:28.627958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:28.627976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:54:30.165245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:54:30.165381: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165465: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165551: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:54:30.165753: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:54:30.166113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.4493 - auc: 0.5718 - auc_1: 0.0695 - val_loss: 0.6087 - val_auc: 0.5839 - val_auc_1: 0.1532\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "(500, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --batch 50\n",
      "2024-05-13 06:55:04.900260: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:55:05.006704: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:55:05.009564: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:05.009594: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:55:05.519082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:05.519242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:05.519286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "\n",
      "train\n",
      "1351 27\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.5 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "\n",
      "test\n",
      "75 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "val\n",
      "74 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:55:10.192635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:55:10.288651: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:55:10.291392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:10.291418: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:55:10.756943: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:10.757043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:10.757073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 06:55:12.271344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:55:12.271468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271552: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271773: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:12.271832: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:55:12.272150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.5997 - auc: 0.5897 - auc_1: 0.0733 - val_loss: 0.6436 - val_auc: 0.4886 - val_auc_1: 0.0571\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e1/poisson\n",
      "mm10\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 06:55:47.258964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:55:47.381991: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:55:47.385273: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:47.385305: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:55:47.898747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:47.898828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:55:47.898847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.3 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.4 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.5 s\n",
      "process 2400 peaks takes 2.6 s\n",
      "process 2450 peaks takes 2.6 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.7 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.8 s\n",
      "process 2700 peaks takes 2.9 s\n",
      "process 2750 peaks takes 2.9 s\n",
      "process 2800 peaks takes 3.0 s\n",
      "process 2850 peaks takes 3.0 s\n",
      "process 2900 peaks takes 3.1 s\n",
      "process 2950 peaks takes 3.1 s\n",
      "process 3000 peaks takes 3.2 s\n",
      "process 3050 peaks takes 3.2 s\n",
      "process 3100 peaks takes 3.3 s\n",
      "process 3150 peaks takes 3.4 s\n",
      "process 3200 peaks takes 3.4 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.5 s\n",
      "process 3350 peaks takes 3.6 s\n",
      "process 3400 peaks takes 3.6 s\n",
      "process 3450 peaks takes 3.7 s\n",
      "process 3500 peaks takes 3.8 s\n",
      "process 3550 peaks takes 3.8 s\n",
      "process 3600 peaks takes 3.9 s\n",
      "process 3650 peaks takes 3.9 s\n",
      "process 3700 peaks takes 4.0 s\n",
      "process 3750 peaks takes 4.1 s\n",
      "process 3800 peaks takes 4.1 s\n",
      "process 3850 peaks takes 4.2 s\n",
      "process 3900 peaks takes 4.2 s\n",
      "process 3950 peaks takes 4.3 s\n",
      "process 4000 peaks takes 4.3 s\n",
      "process 4050 peaks takes 4.4 s\n",
      "process 4100 peaks takes 4.4 s\n",
      "process 4150 peaks takes 4.5 s\n",
      "process 4200 peaks takes 4.6 s\n",
      "process 4250 peaks takes 4.6 s\n",
      "process 4300 peaks takes 4.6 s\n",
      "process 4350 peaks takes 4.7 s\n",
      "process 4400 peaks takes 4.7 s\n",
      "process 4450 peaks takes 4.8 s\n",
      "process 4500 peaks takes 4.8 s\n",
      "process 4550 peaks takes 4.9 s\n",
      "process 4600 peaks takes 4.9 s\n",
      "process 4650 peaks takes 5.0 s\n",
      "process 4700 peaks takes 5.0 s\n",
      "process 4750 peaks takes 5.1 s\n",
      "process 4800 peaks takes 5.1 s\n",
      "process 4850 peaks takes 5.2 s\n",
      "process 4900 peaks takes 5.2 s\n",
      "process 4950 peaks takes 5.3 s\n",
      "process 5000 peaks takes 5.3 s\n",
      "process 5050 peaks takes 5.4 s\n",
      "process 5100 peaks takes 5.5 s\n",
      "process 5150 peaks takes 5.5 s\n",
      "process 5200 peaks takes 5.6 s\n",
      "process 5250 peaks takes 5.6 s\n",
      "process 5300 peaks takes 5.7 s\n",
      "process 5350 peaks takes 5.7 s\n",
      "process 5400 peaks takes 5.7 s\n",
      "process 5450 peaks takes 5.8 s\n",
      "process 5500 peaks takes 5.9 s\n",
      "process 5550 peaks takes 5.9 s\n",
      "process 5600 peaks takes 6.0 s\n",
      "process 5650 peaks takes 6.0 s\n",
      "process 5700 peaks takes 6.0 s\n",
      "process 5750 peaks takes 6.1 s\n",
      "process 5800 peaks takes 6.1 s\n",
      "process 5850 peaks takes 6.2 s\n",
      "process 5900 peaks takes 6.3 s\n",
      "process 5950 peaks takes 6.3 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.5 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.6 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.7 s\n",
      "process 1850 peaks takes 1.7 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 1.9 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.0 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.1 s\n",
      "process 2300 peaks takes 2.1 s\n",
      "process 2350 peaks takes 2.2 s\n",
      "process 2400 peaks takes 2.2 s\n",
      "process 2450 peaks takes 2.3 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.5 s\n",
      "process 2750 peaks takes 2.5 s\n",
      "process 2800 peaks takes 2.6 s\n",
      "process 2850 peaks takes 2.6 s\n",
      "process 2900 peaks takes 2.7 s\n",
      "process 2950 peaks takes 2.7 s\n",
      "process 3000 peaks takes 2.7 s\n",
      "process 3050 peaks takes 2.8 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.9 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 3.0 s\n",
      "process 3300 peaks takes 3.0 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.1 s\n",
      "process 3450 peaks takes 3.2 s\n",
      "process 3500 peaks takes 3.2 s\n",
      "process 3550 peaks takes 3.3 s\n",
      "process 3600 peaks takes 3.3 s\n",
      "process 3650 peaks takes 3.3 s\n",
      "process 3700 peaks takes 3.4 s\n",
      "process 3750 peaks takes 3.4 s\n",
      "process 3800 peaks takes 3.5 s\n",
      "process 3850 peaks takes 3.5 s\n",
      "process 3900 peaks takes 3.6 s\n",
      "process 3950 peaks takes 3.6 s\n",
      "process 4000 peaks takes 3.6 s\n",
      "process 4050 peaks takes 3.7 s\n",
      "process 4100 peaks takes 3.7 s\n",
      "process 4150 peaks takes 3.8 s\n",
      "process 4200 peaks takes 3.8 s\n",
      "process 4250 peaks takes 3.9 s\n",
      "process 4300 peaks takes 3.9 s\n",
      "process 4350 peaks takes 3.9 s\n",
      "process 4400 peaks takes 4.0 s\n",
      "process 4450 peaks takes 4.0 s\n",
      "process 4500 peaks takes 4.1 s\n",
      "process 4550 peaks takes 4.1 s\n",
      "process 4600 peaks takes 4.2 s\n",
      "process 4650 peaks takes 4.2 s\n",
      "process 4700 peaks takes 4.3 s\n",
      "process 4750 peaks takes 4.3 s\n",
      "process 4800 peaks takes 4.4 s\n",
      "process 4850 peaks takes 4.4 s\n",
      "process 4900 peaks takes 4.5 s\n",
      "process 4950 peaks takes 4.5 s\n",
      "process 5000 peaks takes 4.6 s\n",
      "process 5050 peaks takes 4.6 s\n",
      "process 5100 peaks takes 4.6 s\n",
      "process 5150 peaks takes 4.7 s\n",
      "process 5200 peaks takes 4.7 s\n",
      "process 5250 peaks takes 4.8 s\n",
      "process 5300 peaks takes 4.8 s\n",
      "process 5350 peaks takes 4.9 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:56:01.724167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:56:01.825424: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:56:01.828665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:01.828708: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:56:02.299004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:02.299070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:02.299077: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:56:03.833581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:56:03.833693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.833766: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.833808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.833849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.833892: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.833935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.833977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.834018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:56:03.834035: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:56:03.834372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "43/43 [==============================] - 80s 2s/step - loss: 0.2873 - auc: 0.6525 - auc_1: 0.0947 - val_loss: 0.2352 - val_auc: 0.7482 - val_auc_1: 0.1698\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 06:57:27.606985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:57:27.730373: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:57:27.733333: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:27.733367: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:57:28.194529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:28.194652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:28.194659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.6 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.7 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.8 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.0 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.1 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.2 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.3 s\n",
      "process 1450 peaks takes 1.3 s\n",
      "process 1500 peaks takes 1.4 s\n",
      "process 1550 peaks takes 1.4 s\n",
      "process 1600 peaks takes 1.5 s\n",
      "process 1650 peaks takes 1.5 s\n",
      "process 1700 peaks takes 1.6 s\n",
      "process 1750 peaks takes 1.6 s\n",
      "process 1800 peaks takes 1.6 s\n",
      "process 1850 peaks takes 1.7 s\n",
      "process 1900 peaks takes 1.7 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.8 s\n",
      "process 2050 peaks takes 1.8 s\n",
      "process 2100 peaks takes 1.9 s\n",
      "process 2150 peaks takes 2.0 s\n",
      "process 2200 peaks takes 2.0 s\n",
      "process 2250 peaks takes 2.1 s\n",
      "process 2300 peaks takes 2.1 s\n",
      "process 2350 peaks takes 2.1 s\n",
      "process 2400 peaks takes 2.2 s\n",
      "process 2450 peaks takes 2.2 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.3 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.4 s\n",
      "process 2700 peaks takes 2.4 s\n",
      "process 2750 peaks takes 2.5 s\n",
      "process 2800 peaks takes 2.5 s\n",
      "process 2850 peaks takes 2.6 s\n",
      "process 2900 peaks takes 2.6 s\n",
      "process 2950 peaks takes 2.7 s\n",
      "process 3000 peaks takes 2.7 s\n",
      "process 3050 peaks takes 2.7 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.8 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 2.9 s\n",
      "process 3300 peaks takes 3.0 s\n",
      "process 3350 peaks takes 3.0 s\n",
      "process 3400 peaks takes 3.1 s\n",
      "process 3450 peaks takes 3.1 s\n",
      "process 3500 peaks takes 3.2 s\n",
      "process 3550 peaks takes 3.2 s\n",
      "process 3600 peaks takes 3.3 s\n",
      "process 3650 peaks takes 3.3 s\n",
      "process 3700 peaks takes 3.3 s\n",
      "process 3750 peaks takes 3.4 s\n",
      "process 3800 peaks takes 3.4 s\n",
      "process 3850 peaks takes 3.5 s\n",
      "process 3900 peaks takes 3.5 s\n",
      "process 3950 peaks takes 3.6 s\n",
      "process 4000 peaks takes 3.6 s\n",
      "process 4050 peaks takes 3.6 s\n",
      "process 4100 peaks takes 3.7 s\n",
      "process 4150 peaks takes 3.7 s\n",
      "process 4200 peaks takes 3.8 s\n",
      "process 4250 peaks takes 3.8 s\n",
      "process 4300 peaks takes 3.9 s\n",
      "process 4350 peaks takes 3.9 s\n",
      "process 4400 peaks takes 4.0 s\n",
      "process 4450 peaks takes 4.0 s\n",
      "process 4500 peaks takes 4.1 s\n",
      "process 4550 peaks takes 4.1 s\n",
      "process 4600 peaks takes 4.1 s\n",
      "process 4650 peaks takes 4.2 s\n",
      "process 4700 peaks takes 4.2 s\n",
      "process 4750 peaks takes 4.3 s\n",
      "process 4800 peaks takes 4.3 s\n",
      "process 4850 peaks takes 4.4 s\n",
      "process 4900 peaks takes 4.4 s\n",
      "process 4950 peaks takes 4.5 s\n",
      "process 5000 peaks takes 4.5 s\n",
      "process 5050 peaks takes 4.5 s\n",
      "process 5100 peaks takes 4.6 s\n",
      "process 5150 peaks takes 4.6 s\n",
      "process 5200 peaks takes 4.7 s\n",
      "process 5250 peaks takes 4.7 s\n",
      "process 5300 peaks takes 4.8 s\n",
      "process 5350 peaks takes 4.8 s\n",
      "process 5400 peaks takes 4.8 s\n",
      "process 5450 peaks takes 4.9 s\n",
      "process 5500 peaks takes 4.9 s\n",
      "process 5550 peaks takes 5.0 s\n",
      "process 5600 peaks takes 5.0 s\n",
      "process 5650 peaks takes 5.1 s\n",
      "process 5700 peaks takes 5.1 s\n",
      "process 5750 peaks takes 5.1 s\n",
      "process 5800 peaks takes 5.2 s\n",
      "process 5850 peaks takes 5.2 s\n",
      "process 5900 peaks takes 5.3 s\n",
      "process 5950 peaks takes 5.3 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 0.9 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.1 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.2 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.3 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.4 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.5 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.6 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.7 s\n",
      "process 1850 peaks takes 1.7 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.8 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 1.9 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.0 s\n",
      "process 2200 peaks takes 2.0 s\n",
      "process 2250 peaks takes 2.1 s\n",
      "process 2300 peaks takes 2.1 s\n",
      "process 2350 peaks takes 2.2 s\n",
      "process 2400 peaks takes 2.2 s\n",
      "process 2450 peaks takes 2.3 s\n",
      "process 2500 peaks takes 2.3 s\n",
      "process 2550 peaks takes 2.3 s\n",
      "process 2600 peaks takes 2.4 s\n",
      "process 2650 peaks takes 2.4 s\n",
      "process 2700 peaks takes 2.5 s\n",
      "process 2750 peaks takes 2.5 s\n",
      "process 2800 peaks takes 2.6 s\n",
      "process 2850 peaks takes 2.6 s\n",
      "process 2900 peaks takes 2.7 s\n",
      "process 2950 peaks takes 2.7 s\n",
      "process 3000 peaks takes 2.8 s\n",
      "process 3050 peaks takes 2.8 s\n",
      "process 3100 peaks takes 2.8 s\n",
      "process 3150 peaks takes 2.9 s\n",
      "process 3200 peaks takes 2.9 s\n",
      "process 3250 peaks takes 3.0 s\n",
      "process 3300 peaks takes 3.0 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.1 s\n",
      "process 3450 peaks takes 3.2 s\n",
      "process 3500 peaks takes 3.2 s\n",
      "process 3550 peaks takes 3.3 s\n",
      "process 3600 peaks takes 3.3 s\n",
      "process 3650 peaks takes 3.4 s\n",
      "process 3700 peaks takes 3.4 s\n",
      "process 3750 peaks takes 3.4 s\n",
      "process 3800 peaks takes 3.5 s\n",
      "process 3850 peaks takes 3.5 s\n",
      "process 3900 peaks takes 3.6 s\n",
      "process 3950 peaks takes 3.6 s\n",
      "process 4000 peaks takes 3.7 s\n",
      "process 4050 peaks takes 3.7 s\n",
      "process 4100 peaks takes 3.8 s\n",
      "process 4150 peaks takes 3.8 s\n",
      "process 4200 peaks takes 3.9 s\n",
      "process 4250 peaks takes 3.9 s\n",
      "process 4300 peaks takes 4.0 s\n",
      "process 4350 peaks takes 4.0 s\n",
      "process 4400 peaks takes 4.0 s\n",
      "process 4450 peaks takes 4.1 s\n",
      "process 4500 peaks takes 4.1 s\n",
      "process 4550 peaks takes 4.2 s\n",
      "process 4600 peaks takes 4.2 s\n",
      "process 4650 peaks takes 4.3 s\n",
      "process 4700 peaks takes 4.3 s\n",
      "process 4750 peaks takes 4.4 s\n",
      "process 4800 peaks takes 4.4 s\n",
      "process 4850 peaks takes 4.5 s\n",
      "process 4900 peaks takes 4.5 s\n",
      "process 4950 peaks takes 4.5 s\n",
      "process 5000 peaks takes 4.6 s\n",
      "process 5050 peaks takes 4.6 s\n",
      "process 5100 peaks takes 4.7 s\n",
      "process 5150 peaks takes 4.7 s\n",
      "process 5200 peaks takes 4.8 s\n",
      "process 5250 peaks takes 4.8 s\n",
      "process 5300 peaks takes 4.9 s\n",
      "process 5350 peaks takes 4.9 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 06:57:40.990793: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:57:41.089786: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:57:41.092673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:41.092700: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:57:41.615552: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:41.615661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:41.615670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:57:43.195264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:57:43.195384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:57:43.195728: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:57:43.196046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "43/43 [==============================] - 83s 2s/step - loss: 0.3525 - auc: 0.6319 - auc_1: 0.0849 - val_loss: 0.2588 - val_auc: 0.7409 - val_auc_1: 0.1603\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e1/poisson\n",
      "mm10\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 06:59:10.175765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:59:10.301446: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:59:10.304808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:10.304839: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:59:10.832234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:10.832320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:10.832327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.3 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 2.0 s\n",
      "process 1750 peaks takes 2.0 s\n",
      "process 1800 peaks takes 2.1 s\n",
      "process 1850 peaks takes 2.1 s\n",
      "process 1900 peaks takes 2.2 s\n",
      "process 1950 peaks takes 2.2 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.3 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.4 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.5 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.6 s\n",
      "process 2400 peaks takes 2.7 s\n",
      "process 2450 peaks takes 2.7 s\n",
      "process 2500 peaks takes 2.8 s\n",
      "process 2550 peaks takes 2.8 s\n",
      "process 2600 peaks takes 2.9 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 3.0 s\n",
      "process 2750 peaks takes 3.1 s\n",
      "process 2800 peaks takes 3.1 s\n",
      "process 2850 peaks takes 3.1 s\n",
      "process 2900 peaks takes 3.2 s\n",
      "process 2950 peaks takes 3.2 s\n",
      "process 3000 peaks takes 3.3 s\n",
      "process 3050 peaks takes 3.3 s\n",
      "process 3100 peaks takes 3.4 s\n",
      "process 3150 peaks takes 3.4 s\n",
      "process 3200 peaks takes 3.5 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.6 s\n",
      "process 3350 peaks takes 3.6 s\n",
      "process 3400 peaks takes 3.7 s\n",
      "process 3450 peaks takes 3.8 s\n",
      "process 3500 peaks takes 3.8 s\n",
      "process 3550 peaks takes 3.9 s\n",
      "process 3600 peaks takes 3.9 s\n",
      "process 3650 peaks takes 3.9 s\n",
      "process 3700 peaks takes 4.0 s\n",
      "process 3750 peaks takes 4.0 s\n",
      "process 3800 peaks takes 4.1 s\n",
      "process 3850 peaks takes 4.1 s\n",
      "process 3900 peaks takes 4.2 s\n",
      "process 3950 peaks takes 4.2 s\n",
      "process 4000 peaks takes 4.3 s\n",
      "process 4050 peaks takes 4.3 s\n",
      "process 4100 peaks takes 4.4 s\n",
      "process 4150 peaks takes 4.4 s\n",
      "process 4200 peaks takes 4.5 s\n",
      "process 4250 peaks takes 4.5 s\n",
      "process 4300 peaks takes 4.5 s\n",
      "process 4350 peaks takes 4.6 s\n",
      "process 4400 peaks takes 4.7 s\n",
      "process 4450 peaks takes 4.7 s\n",
      "process 4500 peaks takes 4.8 s\n",
      "process 4550 peaks takes 4.8 s\n",
      "process 4600 peaks takes 4.8 s\n",
      "process 4650 peaks takes 4.9 s\n",
      "process 4700 peaks takes 5.0 s\n",
      "process 4750 peaks takes 5.0 s\n",
      "process 4800 peaks takes 5.0 s\n",
      "process 4850 peaks takes 5.1 s\n",
      "process 4900 peaks takes 5.1 s\n",
      "process 4950 peaks takes 5.2 s\n",
      "process 5000 peaks takes 5.2 s\n",
      "process 5050 peaks takes 5.3 s\n",
      "process 5100 peaks takes 5.3 s\n",
      "process 5150 peaks takes 5.4 s\n",
      "process 5200 peaks takes 5.4 s\n",
      "process 5250 peaks takes 5.5 s\n",
      "process 5300 peaks takes 5.5 s\n",
      "process 5350 peaks takes 5.6 s\n",
      "process 5400 peaks takes 5.6 s\n",
      "process 5450 peaks takes 5.7 s\n",
      "process 5500 peaks takes 5.7 s\n",
      "process 5550 peaks takes 5.8 s\n",
      "process 5600 peaks takes 5.8 s\n",
      "process 5650 peaks takes 5.9 s\n",
      "process 5700 peaks takes 5.9 s\n",
      "process 5750 peaks takes 6.0 s\n",
      "process 5800 peaks takes 6.0 s\n",
      "process 5850 peaks takes 6.1 s\n",
      "process 5900 peaks takes 6.1 s\n",
      "process 5950 peaks takes 6.1 s\n",
      "process 6000 peaks takes 6.2 s\n",
      "process 6050 peaks takes 6.2 s\n",
      "process 6100 peaks takes 6.3 s\n",
      "process 6150 peaks takes 6.3 s\n",
      "process 6200 peaks takes 6.4 s\n",
      "process 6250 peaks takes 6.4 s\n",
      "process 6300 peaks takes 6.5 s\n",
      "process 6350 peaks takes 6.5 s\n",
      "process 6400 peaks takes 6.6 s\n",
      "process 6450 peaks takes 6.6 s\n",
      "process 6500 peaks takes 6.7 s\n",
      "process 6550 peaks takes 6.7 s\n",
      "process 6600 peaks takes 6.8 s\n",
      "process 6650 peaks takes 6.8 s\n",
      "process 6700 peaks takes 6.8 s\n",
      "process 6750 peaks takes 6.9 s\n",
      "process 6800 peaks takes 7.0 s\n",
      "process 6850 peaks takes 7.0 s\n",
      "process 6900 peaks takes 7.1 s\n",
      "process 6950 peaks takes 7.1 s\n",
      "process 7000 peaks takes 7.1 s\n",
      "process 7050 peaks takes 7.2 s\n",
      "process 7100 peaks takes 7.2 s\n",
      "process 7150 peaks takes 7.3 s\n",
      "process 7200 peaks takes 7.3 s\n",
      "process 7250 peaks takes 7.4 s\n",
      "process 7300 peaks takes 7.4 s\n",
      "process 7350 peaks takes 7.5 s\n",
      "process 7400 peaks takes 7.5 s\n",
      "process 7450 peaks takes 7.6 s\n",
      "process 7500 peaks takes 7.6 s\n",
      "process 7550 peaks takes 7.7 s\n",
      "process 7600 peaks takes 7.7 s\n",
      "process 7650 peaks takes 7.8 s\n",
      "process 7700 peaks takes 7.8 s\n",
      "process 7750 peaks takes 7.9 s\n",
      "process 7800 peaks takes 7.9 s\n",
      "process 7850 peaks takes 8.0 s\n",
      "process 7900 peaks takes 8.0 s\n",
      "process 7950 peaks takes 8.1 s\n",
      "process 8000 peaks takes 8.1 s\n",
      "process 8050 peaks takes 8.2 s\n",
      "process 8100 peaks takes 8.2 s\n",
      "process 8150 peaks takes 8.3 s\n",
      "process 8200 peaks takes 8.3 s\n",
      "process 8250 peaks takes 8.4 s\n",
      "process 8300 peaks takes 8.4 s\n",
      "process 8350 peaks takes 8.5 s\n",
      "process 8400 peaks takes 8.5 s\n",
      "process 8450 peaks takes 8.6 s\n",
      "process 8500 peaks takes 8.6 s\n",
      "process 8550 peaks takes 8.6 s\n",
      "process 8600 peaks takes 8.7 s\n",
      "process 8650 peaks takes 8.8 s\n",
      "process 8700 peaks takes 8.8 s\n",
      "process 8750 peaks takes 8.8 s\n",
      "process 8800 peaks takes 8.9 s\n",
      "process 8850 peaks takes 8.9 s\n",
      "process 8900 peaks takes 9.0 s\n",
      "process 8950 peaks takes 9.0 s\n",
      "process 9000 peaks takes 9.1 s\n",
      "process 9050 peaks takes 9.1 s\n",
      "process 9100 peaks takes 9.2 s\n",
      "process 9150 peaks takes 9.2 s\n",
      "process 9200 peaks takes 9.3 s\n",
      "process 9250 peaks takes 9.4 s\n",
      "process 9300 peaks takes 9.4 s\n",
      "process 9350 peaks takes 9.4 s\n",
      "process 9400 peaks takes 9.5 s\n",
      "process 9450 peaks takes 9.5 s\n",
      "process 9500 peaks takes 9.6 s\n",
      "process 9550 peaks takes 9.6 s\n",
      "process 9600 peaks takes 9.7 s\n",
      "process 9650 peaks takes 9.7 s\n",
      "process 9700 peaks takes 9.8 s\n",
      "process 9750 peaks takes 9.8 s\n",
      "process 9800 peaks takes 9.9 s\n",
      "process 9850 peaks takes 9.9 s\n",
      "process 9900 peaks takes 10.0 s\n",
      "process 9950 peaks takes 10.0 s\n",
      "process 10000 peaks takes 10.1 s\n",
      "process 10050 peaks takes 10.1 s\n",
      "process 10100 peaks takes 10.2 s\n",
      "process 10150 peaks takes 10.2 s\n",
      "process 10200 peaks takes 10.3 s\n",
      "process 10250 peaks takes 10.3 s\n",
      "process 10300 peaks takes 10.4 s\n",
      "process 10350 peaks takes 10.4 s\n",
      "process 10400 peaks takes 10.5 s\n",
      "process 10450 peaks takes 10.5 s\n",
      "process 10500 peaks takes 10.6 s\n",
      "process 10550 peaks takes 10.6 s\n",
      "process 10600 peaks takes 10.7 s\n",
      "process 10650 peaks takes 10.7 s\n",
      "process 10700 peaks takes 10.8 s\n",
      "process 10750 peaks takes 10.8 s\n",
      "process 10800 peaks takes 10.9 s\n",
      "process 10850 peaks takes 11.0 s\n",
      "process 10900 peaks takes 11.0 s\n",
      "process 10950 peaks takes 11.0 s\n",
      "process 11000 peaks takes 11.1 s\n",
      "process 11050 peaks takes 11.1 s\n",
      "process 11100 peaks takes 11.2 s\n",
      "process 11150 peaks takes 11.3 s\n",
      "process 11200 peaks takes 11.3 s\n",
      "process 11250 peaks takes 11.4 s\n",
      "process 11300 peaks takes 11.4 s\n",
      "process 11350 peaks takes 11.5 s\n",
      "process 11400 peaks takes 11.5 s\n",
      "process 11450 peaks takes 11.5 s\n",
      "process 11500 peaks takes 11.6 s\n",
      "process 11550 peaks takes 11.6 s\n",
      "process 11600 peaks takes 11.7 s\n",
      "process 11650 peaks takes 11.7 s\n",
      "process 11700 peaks takes 11.8 s\n",
      "process 11750 peaks takes 11.8 s\n",
      "process 11800 peaks takes 11.9 s\n",
      "process 11850 peaks takes 11.9 s\n",
      "process 11900 peaks takes 12.0 s\n",
      "process 11950 peaks takes 12.0 s\n",
      "process 12000 peaks takes 12.1 s\n",
      "process 12050 peaks takes 12.1 s\n",
      "process 12100 peaks takes 12.2 s\n",
      "process 12150 peaks takes 12.2 s\n",
      "process 12200 peaks takes 12.3 s\n",
      "process 12250 peaks takes 12.3 s\n",
      "process 12300 peaks takes 12.4 s\n",
      "process 12350 peaks takes 12.4 s\n",
      "process 12400 peaks takes 12.5 s\n",
      "process 12450 peaks takes 12.5 s\n",
      "process 12500 peaks takes 12.6 s\n",
      "process 12550 peaks takes 12.6 s\n",
      "process 12600 peaks takes 12.7 s\n",
      "process 12650 peaks takes 12.7 s\n",
      "process 12700 peaks takes 12.8 s\n",
      "process 12750 peaks takes 12.8 s\n",
      "process 12800 peaks takes 12.9 s\n",
      "process 12850 peaks takes 12.9 s\n",
      "process 12900 peaks takes 13.0 s\n",
      "process 12950 peaks takes 13.0 s\n",
      "process 13000 peaks takes 13.1 s\n",
      "process 13050 peaks takes 13.1 s\n",
      "process 13100 peaks takes 13.2 s\n",
      "process 13150 peaks takes 13.2 s\n",
      "process 13200 peaks takes 13.3 s\n",
      "process 13250 peaks takes 13.3 s\n",
      "process 13300 peaks takes 13.4 s\n",
      "process 13350 peaks takes 13.4 s\n",
      "process 13400 peaks takes 13.4 s\n",
      "process 13450 peaks takes 13.5 s\n",
      "process 13500 peaks takes 13.6 s\n",
      "process 13550 peaks takes 13.6 s\n",
      "process 13600 peaks takes 13.7 s\n",
      "process 13650 peaks takes 13.7 s\n",
      "process 13700 peaks takes 13.7 s\n",
      "process 13750 peaks takes 13.8 s\n",
      "process 13800 peaks takes 13.8 s\n",
      "process 13850 peaks takes 13.9 s\n",
      "process 13900 peaks takes 14.0 s\n",
      "process 13950 peaks takes 14.0 s\n",
      "process 14000 peaks takes 14.0 s\n",
      "process 14050 peaks takes 14.1 s\n",
      "process 14100 peaks takes 14.1 s\n",
      "process 14150 peaks takes 14.2 s\n",
      "process 14200 peaks takes 14.2 s\n",
      "process 14250 peaks takes 14.3 s\n",
      "process 14300 peaks takes 14.3 s\n",
      "process 14350 peaks takes 14.4 s\n",
      "process 14400 peaks takes 14.4 s\n",
      "process 14450 peaks takes 14.5 s\n",
      "process 14500 peaks takes 14.5 s\n",
      "process 14550 peaks takes 14.5 s\n",
      "process 14600 peaks takes 14.6 s\n",
      "process 14650 peaks takes 14.7 s\n",
      "process 14700 peaks takes 14.7 s\n",
      "process 14750 peaks takes 14.8 s\n",
      "process 14800 peaks takes 14.8 s\n",
      "process 14850 peaks takes 14.9 s\n",
      "process 14900 peaks takes 14.9 s\n",
      "process 14950 peaks takes 15.0 s\n",
      "\n",
      "train\n",
      "13501 270\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.4 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.5 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.6 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.7 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.8 s\n",
      "process 3950 peaks takes 3.9 s\n",
      "process 4000 peaks takes 3.9 s\n",
      "process 4050 peaks takes 4.0 s\n",
      "process 4100 peaks takes 4.0 s\n",
      "process 4150 peaks takes 4.1 s\n",
      "process 4200 peaks takes 4.1 s\n",
      "process 4250 peaks takes 4.2 s\n",
      "process 4300 peaks takes 4.2 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.3 s\n",
      "process 4450 peaks takes 4.3 s\n",
      "process 4500 peaks takes 4.4 s\n",
      "process 4550 peaks takes 4.4 s\n",
      "process 4600 peaks takes 4.5 s\n",
      "process 4650 peaks takes 4.6 s\n",
      "process 4700 peaks takes 4.6 s\n",
      "process 4750 peaks takes 4.6 s\n",
      "process 4800 peaks takes 4.7 s\n",
      "process 4850 peaks takes 4.7 s\n",
      "process 4900 peaks takes 4.8 s\n",
      "process 4950 peaks takes 4.8 s\n",
      "process 5000 peaks takes 4.9 s\n",
      "process 5050 peaks takes 4.9 s\n",
      "process 5100 peaks takes 5.0 s\n",
      "process 5150 peaks takes 5.0 s\n",
      "process 5200 peaks takes 5.1 s\n",
      "process 5250 peaks takes 5.1 s\n",
      "process 5300 peaks takes 5.2 s\n",
      "process 5350 peaks takes 5.2 s\n",
      "process 5400 peaks takes 5.3 s\n",
      "process 5450 peaks takes 5.3 s\n",
      "process 5500 peaks takes 5.4 s\n",
      "process 5550 peaks takes 5.4 s\n",
      "process 5600 peaks takes 5.5 s\n",
      "process 5650 peaks takes 5.5 s\n",
      "process 5700 peaks takes 5.6 s\n",
      "process 5750 peaks takes 5.6 s\n",
      "process 5800 peaks takes 5.7 s\n",
      "process 5850 peaks takes 5.7 s\n",
      "process 5900 peaks takes 5.8 s\n",
      "process 5950 peaks takes 5.8 s\n",
      "process 6000 peaks takes 5.9 s\n",
      "process 6050 peaks takes 5.9 s\n",
      "process 6100 peaks takes 6.0 s\n",
      "process 6150 peaks takes 6.0 s\n",
      "process 6200 peaks takes 6.1 s\n",
      "process 6250 peaks takes 6.1 s\n",
      "process 6300 peaks takes 6.2 s\n",
      "process 6350 peaks takes 6.2 s\n",
      "process 6400 peaks takes 6.3 s\n",
      "process 6450 peaks takes 6.4 s\n",
      "process 6500 peaks takes 6.4 s\n",
      "process 6550 peaks takes 6.5 s\n",
      "process 6600 peaks takes 6.5 s\n",
      "process 6650 peaks takes 6.6 s\n",
      "process 6700 peaks takes 6.6 s\n",
      "process 6750 peaks takes 6.7 s\n",
      "process 6800 peaks takes 6.8 s\n",
      "process 6850 peaks takes 6.8 s\n",
      "process 6900 peaks takes 6.9 s\n",
      "process 6950 peaks takes 6.9 s\n",
      "process 7000 peaks takes 6.9 s\n",
      "process 7050 peaks takes 7.0 s\n",
      "process 7100 peaks takes 7.1 s\n",
      "process 7150 peaks takes 7.1 s\n",
      "process 7200 peaks takes 7.1 s\n",
      "process 7250 peaks takes 7.2 s\n",
      "process 7300 peaks takes 7.2 s\n",
      "process 7350 peaks takes 7.3 s\n",
      "process 7400 peaks takes 7.3 s\n",
      "process 7450 peaks takes 7.4 s\n",
      "process 7500 peaks takes 7.4 s\n",
      "process 7550 peaks takes 7.5 s\n",
      "process 7600 peaks takes 7.6 s\n",
      "process 7650 peaks takes 7.6 s\n",
      "process 7700 peaks takes 7.7 s\n",
      "process 7750 peaks takes 7.7 s\n",
      "process 7800 peaks takes 7.8 s\n",
      "process 7850 peaks takes 7.8 s\n",
      "process 7900 peaks takes 7.9 s\n",
      "process 7950 peaks takes 7.9 s\n",
      "process 8000 peaks takes 8.0 s\n",
      "process 8050 peaks takes 8.0 s\n",
      "process 8100 peaks takes 8.1 s\n",
      "process 8150 peaks takes 8.2 s\n",
      "process 8200 peaks takes 8.2 s\n",
      "process 8250 peaks takes 8.3 s\n",
      "process 8300 peaks takes 8.3 s\n",
      "process 8350 peaks takes 8.4 s\n",
      "process 8400 peaks takes 8.4 s\n",
      "process 8450 peaks takes 8.5 s\n",
      "process 8500 peaks takes 8.5 s\n",
      "process 8550 peaks takes 8.6 s\n",
      "process 8600 peaks takes 8.6 s\n",
      "process 8650 peaks takes 8.7 s\n",
      "process 8700 peaks takes 8.7 s\n",
      "process 8750 peaks takes 8.8 s\n",
      "process 8800 peaks takes 8.9 s\n",
      "process 8850 peaks takes 8.9 s\n",
      "process 8900 peaks takes 9.0 s\n",
      "process 8950 peaks takes 9.0 s\n",
      "process 9000 peaks takes 9.1 s\n",
      "process 9050 peaks takes 9.1 s\n",
      "process 9100 peaks takes 9.2 s\n",
      "process 9150 peaks takes 9.2 s\n",
      "process 9200 peaks takes 9.3 s\n",
      "process 9250 peaks takes 9.3 s\n",
      "process 9300 peaks takes 9.4 s\n",
      "process 9350 peaks takes 9.4 s\n",
      "process 9400 peaks takes 9.5 s\n",
      "process 9450 peaks takes 9.5 s\n",
      "process 9500 peaks takes 9.5 s\n",
      "process 9550 peaks takes 9.6 s\n",
      "process 9600 peaks takes 9.7 s\n",
      "process 9650 peaks takes 9.7 s\n",
      "process 9700 peaks takes 9.8 s\n",
      "process 9750 peaks takes 9.8 s\n",
      "process 9800 peaks takes 9.9 s\n",
      "process 9850 peaks takes 9.9 s\n",
      "process 9900 peaks takes 10.0 s\n",
      "process 9950 peaks takes 10.0 s\n",
      "process 10000 peaks takes 10.1 s\n",
      "process 10050 peaks takes 10.1 s\n",
      "process 10100 peaks takes 10.2 s\n",
      "process 10150 peaks takes 10.3 s\n",
      "process 10200 peaks takes 10.3 s\n",
      "process 10250 peaks takes 10.4 s\n",
      "process 10300 peaks takes 10.4 s\n",
      "process 10350 peaks takes 10.5 s\n",
      "process 10400 peaks takes 10.5 s\n",
      "process 10450 peaks takes 10.6 s\n",
      "process 10500 peaks takes 10.6 s\n",
      "process 10550 peaks takes 10.7 s\n",
      "process 10600 peaks takes 10.8 s\n",
      "process 10650 peaks takes 10.8 s\n",
      "process 10700 peaks takes 10.9 s\n",
      "process 10750 peaks takes 10.9 s\n",
      "process 10800 peaks takes 11.0 s\n",
      "process 10850 peaks takes 11.1 s\n",
      "process 10900 peaks takes 11.1 s\n",
      "process 10950 peaks takes 11.2 s\n",
      "process 11000 peaks takes 11.2 s\n",
      "process 11050 peaks takes 11.3 s\n",
      "process 11100 peaks takes 11.3 s\n",
      "process 11150 peaks takes 11.4 s\n",
      "process 11200 peaks takes 11.4 s\n",
      "process 11250 peaks takes 11.5 s\n",
      "process 11300 peaks takes 11.5 s\n",
      "process 11350 peaks takes 11.5 s\n",
      "process 11400 peaks takes 11.6 s\n",
      "process 11450 peaks takes 11.6 s\n",
      "process 11500 peaks takes 11.7 s\n",
      "process 11550 peaks takes 11.7 s\n",
      "process 11600 peaks takes 11.8 s\n",
      "process 11650 peaks takes 11.8 s\n",
      "process 11700 peaks takes 11.9 s\n",
      "process 11750 peaks takes 11.9 s\n",
      "process 11800 peaks takes 12.0 s\n",
      "process 11850 peaks takes 12.0 s\n",
      "process 11900 peaks takes 12.1 s\n",
      "process 11950 peaks takes 12.1 s\n",
      "process 12000 peaks takes 12.2 s\n",
      "process 12050 peaks takes 12.2 s\n",
      "process 12100 peaks takes 12.3 s\n",
      "process 12150 peaks takes 12.3 s\n",
      "process 12200 peaks takes 12.4 s\n",
      "process 12250 peaks takes 12.4 s\n",
      "process 12300 peaks takes 12.5 s\n",
      "process 12350 peaks takes 12.5 s\n",
      "process 12400 peaks takes 12.6 s\n",
      "process 12450 peaks takes 12.6 s\n",
      "process 12500 peaks takes 12.7 s\n",
      "process 12550 peaks takes 12.7 s\n",
      "process 12600 peaks takes 12.8 s\n",
      "process 12650 peaks takes 12.8 s\n",
      "process 12700 peaks takes 12.9 s\n",
      "process 12750 peaks takes 12.9 s\n",
      "process 12800 peaks takes 13.0 s\n",
      "process 12850 peaks takes 13.0 s\n",
      "process 12900 peaks takes 13.1 s\n",
      "process 12950 peaks takes 13.1 s\n",
      "process 13000 peaks takes 13.2 s\n",
      "process 13050 peaks takes 13.2 s\n",
      "process 13100 peaks takes 13.3 s\n",
      "process 13150 peaks takes 13.4 s\n",
      "process 13200 peaks takes 13.4 s\n",
      "process 13250 peaks takes 13.5 s\n",
      "process 13300 peaks takes 13.5 s\n",
      "process 13350 peaks takes 13.6 s\n",
      "process 13400 peaks takes 13.6 s\n",
      "process 13450 peaks takes 13.7 s\n",
      "\n",
      "test\n",
      "750 15\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "\n",
      "val\n",
      "749 14\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 06:59:43.638492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 06:59:43.741084: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 06:59:43.744778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:43.744820: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 06:59:44.241309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:44.241378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:44.241383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 06:59:46.061360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 06:59:46.061459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 06:59:46.061789: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 06:59:46.062118: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5000)      165000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,684,810\n",
      "Trainable params: 4,678,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "106/106 [==============================] - 189s 2s/step - loss: 0.2382 - auc: 0.6913 - auc_1: 0.1226 - val_loss: 0.1871 - val_auc: 0.7115 - val_auc_1: 0.2432\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 07:02:59.406737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:02:59.521929: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:02:59.526903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:02:59.526934: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:03:00.005625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:00.005734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:00.005757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.3 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.4 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.5 s\n",
      "process 2400 peaks takes 2.6 s\n",
      "process 2450 peaks takes 2.6 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.8 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 2.9 s\n",
      "process 2750 peaks takes 2.9 s\n",
      "process 2800 peaks takes 3.0 s\n",
      "process 2850 peaks takes 3.1 s\n",
      "process 2900 peaks takes 3.1 s\n",
      "process 2950 peaks takes 3.2 s\n",
      "process 3000 peaks takes 3.2 s\n",
      "process 3050 peaks takes 3.3 s\n",
      "process 3100 peaks takes 3.3 s\n",
      "process 3150 peaks takes 3.4 s\n",
      "process 3200 peaks takes 3.4 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.5 s\n",
      "process 3350 peaks takes 3.6 s\n",
      "process 3400 peaks takes 3.6 s\n",
      "process 3450 peaks takes 3.7 s\n",
      "process 3500 peaks takes 3.7 s\n",
      "process 3550 peaks takes 3.8 s\n",
      "process 3600 peaks takes 3.8 s\n",
      "process 3650 peaks takes 3.8 s\n",
      "process 3700 peaks takes 3.9 s\n",
      "process 3750 peaks takes 3.9 s\n",
      "process 3800 peaks takes 4.0 s\n",
      "process 3850 peaks takes 4.0 s\n",
      "process 3900 peaks takes 4.1 s\n",
      "process 3950 peaks takes 4.1 s\n",
      "process 4000 peaks takes 4.1 s\n",
      "process 4050 peaks takes 4.2 s\n",
      "process 4100 peaks takes 4.2 s\n",
      "process 4150 peaks takes 4.3 s\n",
      "process 4200 peaks takes 4.3 s\n",
      "process 4250 peaks takes 4.4 s\n",
      "process 4300 peaks takes 4.4 s\n",
      "process 4350 peaks takes 4.5 s\n",
      "process 4400 peaks takes 4.5 s\n",
      "process 4450 peaks takes 4.6 s\n",
      "process 4500 peaks takes 4.6 s\n",
      "process 4550 peaks takes 4.7 s\n",
      "process 4600 peaks takes 4.7 s\n",
      "process 4650 peaks takes 4.8 s\n",
      "process 4700 peaks takes 4.8 s\n",
      "process 4750 peaks takes 4.8 s\n",
      "process 4800 peaks takes 4.9 s\n",
      "process 4850 peaks takes 4.9 s\n",
      "process 4900 peaks takes 5.0 s\n",
      "process 4950 peaks takes 5.0 s\n",
      "process 5000 peaks takes 5.0 s\n",
      "process 5050 peaks takes 5.1 s\n",
      "process 5100 peaks takes 5.1 s\n",
      "process 5150 peaks takes 5.2 s\n",
      "process 5200 peaks takes 5.2 s\n",
      "process 5250 peaks takes 5.3 s\n",
      "process 5300 peaks takes 5.3 s\n",
      "process 5350 peaks takes 5.4 s\n",
      "process 5400 peaks takes 5.4 s\n",
      "process 5450 peaks takes 5.5 s\n",
      "process 5500 peaks takes 5.5 s\n",
      "process 5550 peaks takes 5.5 s\n",
      "process 5600 peaks takes 5.6 s\n",
      "process 5650 peaks takes 5.6 s\n",
      "process 5700 peaks takes 5.7 s\n",
      "process 5750 peaks takes 5.7 s\n",
      "process 5800 peaks takes 5.8 s\n",
      "process 5850 peaks takes 5.8 s\n",
      "process 5900 peaks takes 5.9 s\n",
      "process 5950 peaks takes 5.9 s\n",
      "process 6000 peaks takes 6.0 s\n",
      "process 6050 peaks takes 6.0 s\n",
      "process 6100 peaks takes 6.1 s\n",
      "process 6150 peaks takes 6.1 s\n",
      "process 6200 peaks takes 6.1 s\n",
      "process 6250 peaks takes 6.2 s\n",
      "process 6300 peaks takes 6.2 s\n",
      "process 6350 peaks takes 6.3 s\n",
      "process 6400 peaks takes 6.3 s\n",
      "process 6450 peaks takes 6.4 s\n",
      "process 6500 peaks takes 6.4 s\n",
      "process 6550 peaks takes 6.5 s\n",
      "process 6600 peaks takes 6.5 s\n",
      "process 6650 peaks takes 6.6 s\n",
      "process 6700 peaks takes 6.6 s\n",
      "process 6750 peaks takes 6.7 s\n",
      "process 6800 peaks takes 6.7 s\n",
      "process 6850 peaks takes 6.8 s\n",
      "process 6900 peaks takes 6.8 s\n",
      "process 6950 peaks takes 6.8 s\n",
      "process 7000 peaks takes 6.9 s\n",
      "process 7050 peaks takes 6.9 s\n",
      "process 7100 peaks takes 7.0 s\n",
      "process 7150 peaks takes 7.0 s\n",
      "process 7200 peaks takes 7.1 s\n",
      "process 7250 peaks takes 7.1 s\n",
      "process 7300 peaks takes 7.2 s\n",
      "process 7350 peaks takes 7.2 s\n",
      "process 7400 peaks takes 7.3 s\n",
      "process 7450 peaks takes 7.3 s\n",
      "process 7500 peaks takes 7.4 s\n",
      "process 7550 peaks takes 7.4 s\n",
      "process 7600 peaks takes 7.4 s\n",
      "process 7650 peaks takes 7.5 s\n",
      "process 7700 peaks takes 7.5 s\n",
      "process 7750 peaks takes 7.6 s\n",
      "process 7800 peaks takes 7.6 s\n",
      "process 7850 peaks takes 7.7 s\n",
      "process 7900 peaks takes 7.7 s\n",
      "process 7950 peaks takes 7.8 s\n",
      "process 8000 peaks takes 7.8 s\n",
      "process 8050 peaks takes 7.8 s\n",
      "process 8100 peaks takes 7.9 s\n",
      "process 8150 peaks takes 7.9 s\n",
      "process 8200 peaks takes 8.0 s\n",
      "process 8250 peaks takes 8.0 s\n",
      "process 8300 peaks takes 8.1 s\n",
      "process 8350 peaks takes 8.1 s\n",
      "process 8400 peaks takes 8.1 s\n",
      "process 8450 peaks takes 8.2 s\n",
      "process 8500 peaks takes 8.2 s\n",
      "process 8550 peaks takes 8.3 s\n",
      "process 8600 peaks takes 8.3 s\n",
      "process 8650 peaks takes 8.4 s\n",
      "process 8700 peaks takes 8.4 s\n",
      "process 8750 peaks takes 8.5 s\n",
      "process 8800 peaks takes 8.5 s\n",
      "process 8850 peaks takes 8.6 s\n",
      "process 8900 peaks takes 8.6 s\n",
      "process 8950 peaks takes 8.7 s\n",
      "process 9000 peaks takes 8.7 s\n",
      "process 9050 peaks takes 8.8 s\n",
      "process 9100 peaks takes 8.8 s\n",
      "process 9150 peaks takes 8.8 s\n",
      "process 9200 peaks takes 8.9 s\n",
      "process 9250 peaks takes 9.0 s\n",
      "process 9300 peaks takes 9.0 s\n",
      "process 9350 peaks takes 9.0 s\n",
      "process 9400 peaks takes 9.1 s\n",
      "process 9450 peaks takes 9.1 s\n",
      "process 9500 peaks takes 9.2 s\n",
      "process 9550 peaks takes 9.2 s\n",
      "process 9600 peaks takes 9.3 s\n",
      "process 9650 peaks takes 9.3 s\n",
      "process 9700 peaks takes 9.3 s\n",
      "process 9750 peaks takes 9.4 s\n",
      "process 9800 peaks takes 9.5 s\n",
      "process 9850 peaks takes 9.5 s\n",
      "process 9900 peaks takes 9.5 s\n",
      "process 9950 peaks takes 9.6 s\n",
      "process 10000 peaks takes 9.6 s\n",
      "process 10050 peaks takes 9.7 s\n",
      "process 10100 peaks takes 9.7 s\n",
      "process 10150 peaks takes 9.8 s\n",
      "process 10200 peaks takes 9.8 s\n",
      "process 10250 peaks takes 9.9 s\n",
      "process 10300 peaks takes 9.9 s\n",
      "process 10350 peaks takes 10.0 s\n",
      "process 10400 peaks takes 10.0 s\n",
      "process 10450 peaks takes 10.1 s\n",
      "process 10500 peaks takes 10.1 s\n",
      "process 10550 peaks takes 10.2 s\n",
      "process 10600 peaks takes 10.2 s\n",
      "process 10650 peaks takes 10.2 s\n",
      "process 10700 peaks takes 10.3 s\n",
      "process 10750 peaks takes 10.3 s\n",
      "process 10800 peaks takes 10.4 s\n",
      "process 10850 peaks takes 10.4 s\n",
      "process 10900 peaks takes 10.5 s\n",
      "process 10950 peaks takes 10.5 s\n",
      "process 11000 peaks takes 10.5 s\n",
      "process 11050 peaks takes 10.6 s\n",
      "process 11100 peaks takes 10.7 s\n",
      "process 11150 peaks takes 10.7 s\n",
      "process 11200 peaks takes 10.7 s\n",
      "process 11250 peaks takes 10.8 s\n",
      "process 11300 peaks takes 10.8 s\n",
      "process 11350 peaks takes 10.9 s\n",
      "process 11400 peaks takes 10.9 s\n",
      "process 11450 peaks takes 10.9 s\n",
      "process 11500 peaks takes 11.0 s\n",
      "process 11550 peaks takes 11.0 s\n",
      "process 11600 peaks takes 11.1 s\n",
      "process 11650 peaks takes 11.1 s\n",
      "process 11700 peaks takes 11.2 s\n",
      "process 11750 peaks takes 11.2 s\n",
      "process 11800 peaks takes 11.3 s\n",
      "process 11850 peaks takes 11.3 s\n",
      "process 11900 peaks takes 11.4 s\n",
      "process 11950 peaks takes 11.4 s\n",
      "process 12000 peaks takes 11.5 s\n",
      "process 12050 peaks takes 11.5 s\n",
      "process 12100 peaks takes 11.6 s\n",
      "process 12150 peaks takes 11.6 s\n",
      "process 12200 peaks takes 11.6 s\n",
      "process 12250 peaks takes 11.7 s\n",
      "process 12300 peaks takes 11.7 s\n",
      "process 12350 peaks takes 11.8 s\n",
      "process 12400 peaks takes 11.8 s\n",
      "process 12450 peaks takes 11.9 s\n",
      "process 12500 peaks takes 11.9 s\n",
      "process 12550 peaks takes 11.9 s\n",
      "process 12600 peaks takes 12.0 s\n",
      "process 12650 peaks takes 12.0 s\n",
      "process 12700 peaks takes 12.1 s\n",
      "process 12750 peaks takes 12.1 s\n",
      "process 12800 peaks takes 12.2 s\n",
      "process 12850 peaks takes 12.2 s\n",
      "process 12900 peaks takes 12.3 s\n",
      "process 12950 peaks takes 12.3 s\n",
      "process 13000 peaks takes 12.4 s\n",
      "process 13050 peaks takes 12.4 s\n",
      "process 13100 peaks takes 12.5 s\n",
      "process 13150 peaks takes 12.5 s\n",
      "process 13200 peaks takes 12.6 s\n",
      "process 13250 peaks takes 12.6 s\n",
      "process 13300 peaks takes 12.7 s\n",
      "process 13350 peaks takes 12.7 s\n",
      "process 13400 peaks takes 12.8 s\n",
      "process 13450 peaks takes 12.9 s\n",
      "process 13500 peaks takes 12.9 s\n",
      "process 13550 peaks takes 13.0 s\n",
      "process 13600 peaks takes 13.0 s\n",
      "process 13650 peaks takes 13.1 s\n",
      "process 13700 peaks takes 13.1 s\n",
      "process 13750 peaks takes 13.2 s\n",
      "process 13800 peaks takes 13.2 s\n",
      "process 13850 peaks takes 13.3 s\n",
      "process 13900 peaks takes 13.3 s\n",
      "process 13950 peaks takes 13.4 s\n",
      "process 14000 peaks takes 13.4 s\n",
      "process 14050 peaks takes 13.5 s\n",
      "process 14100 peaks takes 13.5 s\n",
      "process 14150 peaks takes 13.6 s\n",
      "process 14200 peaks takes 13.6 s\n",
      "process 14250 peaks takes 13.7 s\n",
      "process 14300 peaks takes 13.8 s\n",
      "process 14350 peaks takes 13.8 s\n",
      "process 14400 peaks takes 13.9 s\n",
      "process 14450 peaks takes 13.9 s\n",
      "process 14500 peaks takes 14.0 s\n",
      "process 14550 peaks takes 14.0 s\n",
      "process 14600 peaks takes 14.1 s\n",
      "process 14650 peaks takes 14.1 s\n",
      "process 14700 peaks takes 14.2 s\n",
      "process 14750 peaks takes 14.2 s\n",
      "process 14800 peaks takes 14.3 s\n",
      "process 14850 peaks takes 14.4 s\n",
      "process 14900 peaks takes 14.4 s\n",
      "process 14950 peaks takes 14.5 s\n",
      "\n",
      "train\n",
      "13501 270\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.3 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.6 s\n",
      "process 2800 peaks takes 2.6 s\n",
      "process 2850 peaks takes 2.7 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 2.9 s\n",
      "process 3150 peaks takes 3.0 s\n",
      "process 3200 peaks takes 3.0 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.1 s\n",
      "process 3350 peaks takes 3.1 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.2 s\n",
      "process 3500 peaks takes 3.3 s\n",
      "process 3550 peaks takes 3.3 s\n",
      "process 3600 peaks takes 3.3 s\n",
      "process 3650 peaks takes 3.4 s\n",
      "process 3700 peaks takes 3.4 s\n",
      "process 3750 peaks takes 3.5 s\n",
      "process 3800 peaks takes 3.5 s\n",
      "process 3850 peaks takes 3.6 s\n",
      "process 3900 peaks takes 3.6 s\n",
      "process 3950 peaks takes 3.7 s\n",
      "process 4000 peaks takes 3.7 s\n",
      "process 4050 peaks takes 3.7 s\n",
      "process 4100 peaks takes 3.8 s\n",
      "process 4150 peaks takes 3.8 s\n",
      "process 4200 peaks takes 3.9 s\n",
      "process 4250 peaks takes 3.9 s\n",
      "process 4300 peaks takes 4.0 s\n",
      "process 4350 peaks takes 4.0 s\n",
      "process 4400 peaks takes 4.1 s\n",
      "process 4450 peaks takes 4.2 s\n",
      "process 4500 peaks takes 4.2 s\n",
      "process 4550 peaks takes 4.3 s\n",
      "process 4600 peaks takes 4.3 s\n",
      "process 4650 peaks takes 4.4 s\n",
      "process 4700 peaks takes 4.4 s\n",
      "process 4750 peaks takes 4.4 s\n",
      "process 4800 peaks takes 4.5 s\n",
      "process 4850 peaks takes 4.5 s\n",
      "process 4900 peaks takes 4.6 s\n",
      "process 4950 peaks takes 4.6 s\n",
      "process 5000 peaks takes 4.7 s\n",
      "process 5050 peaks takes 4.7 s\n",
      "process 5100 peaks takes 4.8 s\n",
      "process 5150 peaks takes 4.8 s\n",
      "process 5200 peaks takes 4.9 s\n",
      "process 5250 peaks takes 4.9 s\n",
      "process 5300 peaks takes 5.0 s\n",
      "process 5350 peaks takes 5.0 s\n",
      "process 5400 peaks takes 5.0 s\n",
      "process 5450 peaks takes 5.1 s\n",
      "process 5500 peaks takes 5.1 s\n",
      "process 5550 peaks takes 5.2 s\n",
      "process 5600 peaks takes 5.2 s\n",
      "process 5650 peaks takes 5.3 s\n",
      "process 5700 peaks takes 5.3 s\n",
      "process 5750 peaks takes 5.4 s\n",
      "process 5800 peaks takes 5.4 s\n",
      "process 5850 peaks takes 5.5 s\n",
      "process 5900 peaks takes 5.5 s\n",
      "process 5950 peaks takes 5.6 s\n",
      "process 6000 peaks takes 5.6 s\n",
      "process 6050 peaks takes 5.6 s\n",
      "process 6100 peaks takes 5.7 s\n",
      "process 6150 peaks takes 5.7 s\n",
      "process 6200 peaks takes 5.8 s\n",
      "process 6250 peaks takes 5.8 s\n",
      "process 6300 peaks takes 5.9 s\n",
      "process 6350 peaks takes 5.9 s\n",
      "process 6400 peaks takes 6.0 s\n",
      "process 6450 peaks takes 6.0 s\n",
      "process 6500 peaks takes 6.0 s\n",
      "process 6550 peaks takes 6.1 s\n",
      "process 6600 peaks takes 6.1 s\n",
      "process 6650 peaks takes 6.2 s\n",
      "process 6700 peaks takes 6.2 s\n",
      "process 6750 peaks takes 6.3 s\n",
      "process 6800 peaks takes 6.3 s\n",
      "process 6850 peaks takes 6.4 s\n",
      "process 6900 peaks takes 6.4 s\n",
      "process 6950 peaks takes 6.5 s\n",
      "process 7000 peaks takes 6.5 s\n",
      "process 7050 peaks takes 6.6 s\n",
      "process 7100 peaks takes 6.6 s\n",
      "process 7150 peaks takes 6.6 s\n",
      "process 7200 peaks takes 6.7 s\n",
      "process 7250 peaks takes 6.7 s\n",
      "process 7300 peaks takes 6.8 s\n",
      "process 7350 peaks takes 6.8 s\n",
      "process 7400 peaks takes 6.8 s\n",
      "process 7450 peaks takes 6.9 s\n",
      "process 7500 peaks takes 6.9 s\n",
      "process 7550 peaks takes 7.0 s\n",
      "process 7600 peaks takes 7.0 s\n",
      "process 7650 peaks takes 7.1 s\n",
      "process 7700 peaks takes 7.1 s\n",
      "process 7750 peaks takes 7.2 s\n",
      "process 7800 peaks takes 7.2 s\n",
      "process 7850 peaks takes 7.2 s\n",
      "process 7900 peaks takes 7.3 s\n",
      "process 7950 peaks takes 7.3 s\n",
      "process 8000 peaks takes 7.4 s\n",
      "process 8050 peaks takes 7.4 s\n",
      "process 8100 peaks takes 7.5 s\n",
      "process 8150 peaks takes 7.5 s\n",
      "process 8200 peaks takes 7.6 s\n",
      "process 8250 peaks takes 7.6 s\n",
      "process 8300 peaks takes 7.7 s\n",
      "process 8350 peaks takes 7.7 s\n",
      "process 8400 peaks takes 7.8 s\n",
      "process 8450 peaks takes 7.8 s\n",
      "process 8500 peaks takes 7.8 s\n",
      "process 8550 peaks takes 7.9 s\n",
      "process 8600 peaks takes 7.9 s\n",
      "process 8650 peaks takes 8.0 s\n",
      "process 8700 peaks takes 8.0 s\n",
      "process 8750 peaks takes 8.1 s\n",
      "process 8800 peaks takes 8.1 s\n",
      "process 8850 peaks takes 8.2 s\n",
      "process 8900 peaks takes 8.2 s\n",
      "process 8950 peaks takes 8.3 s\n",
      "process 9000 peaks takes 8.3 s\n",
      "process 9050 peaks takes 8.4 s\n",
      "process 9100 peaks takes 8.4 s\n",
      "process 9150 peaks takes 8.5 s\n",
      "process 9200 peaks takes 8.5 s\n",
      "process 9250 peaks takes 8.5 s\n",
      "process 9300 peaks takes 8.6 s\n",
      "process 9350 peaks takes 8.6 s\n",
      "process 9400 peaks takes 8.7 s\n",
      "process 9450 peaks takes 8.7 s\n",
      "process 9500 peaks takes 8.8 s\n",
      "process 9550 peaks takes 8.8 s\n",
      "process 9600 peaks takes 8.9 s\n",
      "process 9650 peaks takes 8.9 s\n",
      "process 9700 peaks takes 9.0 s\n",
      "process 9750 peaks takes 9.0 s\n",
      "process 9800 peaks takes 9.1 s\n",
      "process 9850 peaks takes 9.1 s\n",
      "process 9900 peaks takes 9.2 s\n",
      "process 9950 peaks takes 9.2 s\n",
      "process 10000 peaks takes 9.2 s\n",
      "process 10050 peaks takes 9.3 s\n",
      "process 10100 peaks takes 9.3 s\n",
      "process 10150 peaks takes 9.4 s\n",
      "process 10200 peaks takes 9.4 s\n",
      "process 10250 peaks takes 9.5 s\n",
      "process 10300 peaks takes 9.5 s\n",
      "process 10350 peaks takes 9.5 s\n",
      "process 10400 peaks takes 9.6 s\n",
      "process 10450 peaks takes 9.7 s\n",
      "process 10500 peaks takes 9.7 s\n",
      "process 10550 peaks takes 9.7 s\n",
      "process 10600 peaks takes 9.8 s\n",
      "process 10650 peaks takes 9.9 s\n",
      "process 10700 peaks takes 9.9 s\n",
      "process 10750 peaks takes 9.9 s\n",
      "process 10800 peaks takes 10.0 s\n",
      "process 10850 peaks takes 10.0 s\n",
      "process 10900 peaks takes 10.1 s\n",
      "process 10950 peaks takes 10.1 s\n",
      "process 11000 peaks takes 10.2 s\n",
      "process 11050 peaks takes 10.2 s\n",
      "process 11100 peaks takes 10.3 s\n",
      "process 11150 peaks takes 10.3 s\n",
      "process 11200 peaks takes 10.4 s\n",
      "process 11250 peaks takes 10.4 s\n",
      "process 11300 peaks takes 10.4 s\n",
      "process 11350 peaks takes 10.5 s\n",
      "process 11400 peaks takes 10.5 s\n",
      "process 11450 peaks takes 10.6 s\n",
      "process 11500 peaks takes 10.6 s\n",
      "process 11550 peaks takes 10.7 s\n",
      "process 11600 peaks takes 10.7 s\n",
      "process 11650 peaks takes 10.7 s\n",
      "process 11700 peaks takes 10.8 s\n",
      "process 11750 peaks takes 10.8 s\n",
      "process 11800 peaks takes 10.9 s\n",
      "process 11850 peaks takes 10.9 s\n",
      "process 11900 peaks takes 11.0 s\n",
      "process 11950 peaks takes 11.0 s\n",
      "process 12000 peaks takes 11.1 s\n",
      "process 12050 peaks takes 11.1 s\n",
      "process 12100 peaks takes 11.2 s\n",
      "process 12150 peaks takes 11.2 s\n",
      "process 12200 peaks takes 11.3 s\n",
      "process 12250 peaks takes 11.3 s\n",
      "process 12300 peaks takes 11.4 s\n",
      "process 12350 peaks takes 11.4 s\n",
      "process 12400 peaks takes 11.5 s\n",
      "process 12450 peaks takes 11.5 s\n",
      "process 12500 peaks takes 11.6 s\n",
      "process 12550 peaks takes 11.6 s\n",
      "process 12600 peaks takes 11.7 s\n",
      "process 12650 peaks takes 11.7 s\n",
      "process 12700 peaks takes 11.8 s\n",
      "process 12750 peaks takes 11.8 s\n",
      "process 12800 peaks takes 11.9 s\n",
      "process 12850 peaks takes 11.9 s\n",
      "process 12900 peaks takes 12.0 s\n",
      "process 12950 peaks takes 12.0 s\n",
      "process 13000 peaks takes 12.1 s\n",
      "process 13050 peaks takes 12.1 s\n",
      "process 13100 peaks takes 12.2 s\n",
      "process 13150 peaks takes 12.2 s\n",
      "process 13200 peaks takes 12.2 s\n",
      "process 13250 peaks takes 12.3 s\n",
      "process 13300 peaks takes 12.3 s\n",
      "process 13350 peaks takes 12.4 s\n",
      "process 13400 peaks takes 12.4 s\n",
      "process 13450 peaks takes 12.5 s\n",
      "\n",
      "test\n",
      "750 15\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "\n",
      "val\n",
      "749 14\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:03:31.318457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:03:31.418446: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:03:31.421366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:31.421395: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:03:31.917951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:31.918021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:31.918027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:03:33.733578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:03:33.733683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733872: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.733996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:03:33.734014: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:03:33.734334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5000)      165000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,684,810\n",
      "Trainable params: 4,678,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "106/106 [==============================] - 176s 2s/step - loss: 0.2616 - auc: 0.6769 - auc_1: 0.1119 - val_loss: 0.1828 - val_auc: 0.7319 - val_auc_1: 0.2515\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs10000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "(10000, 30000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000 --batch 50\n",
      "2024-05-13 07:06:35.999638: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:06:36.103437: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:06:36.106330: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:06:36.106362: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:06:36.584921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:06:36.585037: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:06:36.585067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[27001, 1500, 1499]\n",
      "30000 600\n",
      "process 0 peaks takes 0.5 s\n",
      "process 50 peaks takes 0.5 s\n",
      "process 100 peaks takes 0.6 s\n",
      "process 150 peaks takes 0.6 s\n",
      "process 200 peaks takes 0.7 s\n",
      "process 250 peaks takes 0.7 s\n",
      "process 300 peaks takes 0.8 s\n",
      "process 350 peaks takes 0.8 s\n",
      "process 400 peaks takes 0.9 s\n",
      "process 450 peaks takes 0.9 s\n",
      "process 500 peaks takes 0.9 s\n",
      "process 550 peaks takes 1.0 s\n",
      "process 600 peaks takes 1.0 s\n",
      "process 650 peaks takes 1.1 s\n",
      "process 700 peaks takes 1.2 s\n",
      "process 750 peaks takes 1.2 s\n",
      "process 800 peaks takes 1.2 s\n",
      "process 850 peaks takes 1.3 s\n",
      "process 900 peaks takes 1.4 s\n",
      "process 950 peaks takes 1.4 s\n",
      "process 1000 peaks takes 1.5 s\n",
      "process 1050 peaks takes 1.5 s\n",
      "process 1100 peaks takes 1.6 s\n",
      "process 1150 peaks takes 1.6 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.7 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.9 s\n",
      "process 1500 peaks takes 1.9 s\n",
      "process 1550 peaks takes 2.0 s\n",
      "process 1600 peaks takes 2.0 s\n",
      "process 1650 peaks takes 2.1 s\n",
      "process 1700 peaks takes 2.1 s\n",
      "process 1750 peaks takes 2.2 s\n",
      "process 1800 peaks takes 2.2 s\n",
      "process 1850 peaks takes 2.3 s\n",
      "process 1900 peaks takes 2.3 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.4 s\n",
      "process 2050 peaks takes 2.4 s\n",
      "process 2100 peaks takes 2.5 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.6 s\n",
      "process 2250 peaks takes 2.6 s\n",
      "process 2300 peaks takes 2.7 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.8 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.9 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 2.9 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "process 2700 peaks takes 3.0 s\n",
      "process 2750 peaks takes 3.1 s\n",
      "process 2800 peaks takes 3.1 s\n",
      "process 2850 peaks takes 3.2 s\n",
      "process 2900 peaks takes 3.2 s\n",
      "process 2950 peaks takes 3.2 s\n",
      "process 3000 peaks takes 3.3 s\n",
      "process 3050 peaks takes 3.3 s\n",
      "process 3100 peaks takes 3.4 s\n",
      "process 3150 peaks takes 3.4 s\n",
      "process 3200 peaks takes 3.5 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.6 s\n",
      "process 3350 peaks takes 3.6 s\n",
      "process 3400 peaks takes 3.7 s\n",
      "process 3450 peaks takes 3.7 s\n",
      "process 3500 peaks takes 3.8 s\n",
      "process 3550 peaks takes 3.8 s\n",
      "process 3600 peaks takes 3.9 s\n",
      "process 3650 peaks takes 3.9 s\n",
      "process 3700 peaks takes 3.9 s\n",
      "process 3750 peaks takes 4.0 s\n",
      "process 3800 peaks takes 4.1 s\n",
      "process 3850 peaks takes 4.1 s\n",
      "process 3900 peaks takes 4.1 s\n",
      "process 3950 peaks takes 4.2 s\n",
      "process 4000 peaks takes 4.2 s\n",
      "process 4050 peaks takes 4.3 s\n",
      "process 4100 peaks takes 4.3 s\n",
      "process 4150 peaks takes 4.4 s\n",
      "process 4200 peaks takes 4.4 s\n",
      "process 4250 peaks takes 4.5 s\n",
      "process 4300 peaks takes 4.5 s\n",
      "process 4350 peaks takes 4.6 s\n",
      "process 4400 peaks takes 4.6 s\n",
      "process 4450 peaks takes 4.7 s\n",
      "process 4500 peaks takes 4.7 s\n",
      "process 4550 peaks takes 4.8 s\n",
      "process 4600 peaks takes 4.8 s\n",
      "process 4650 peaks takes 4.8 s\n",
      "process 4700 peaks takes 4.9 s\n",
      "process 4750 peaks takes 4.9 s\n",
      "process 4800 peaks takes 5.0 s\n",
      "process 4850 peaks takes 5.0 s\n",
      "process 4900 peaks takes 5.1 s\n",
      "process 4950 peaks takes 5.1 s\n",
      "process 5000 peaks takes 5.2 s\n",
      "process 5050 peaks takes 5.2 s\n",
      "process 5100 peaks takes 5.3 s\n",
      "process 5150 peaks takes 5.3 s\n",
      "process 5200 peaks takes 5.4 s\n",
      "process 5250 peaks takes 5.4 s\n",
      "process 5300 peaks takes 5.5 s\n",
      "process 5350 peaks takes 5.5 s\n",
      "process 5400 peaks takes 5.5 s\n",
      "process 5450 peaks takes 5.6 s\n",
      "process 5500 peaks takes 5.6 s\n",
      "process 5550 peaks takes 5.7 s\n",
      "process 5600 peaks takes 5.7 s\n",
      "process 5650 peaks takes 5.8 s\n",
      "process 5700 peaks takes 5.8 s\n",
      "process 5750 peaks takes 5.9 s\n",
      "process 5800 peaks takes 5.9 s\n",
      "process 5850 peaks takes 6.0 s\n",
      "process 5900 peaks takes 6.0 s\n",
      "process 5950 peaks takes 6.1 s\n",
      "process 6000 peaks takes 6.1 s\n",
      "process 6050 peaks takes 6.2 s\n",
      "process 6100 peaks takes 6.2 s\n",
      "process 6150 peaks takes 6.3 s\n",
      "process 6200 peaks takes 6.3 s\n",
      "process 6250 peaks takes 6.4 s\n",
      "process 6300 peaks takes 6.4 s\n",
      "process 6350 peaks takes 6.5 s\n",
      "process 6400 peaks takes 6.5 s\n",
      "process 6450 peaks takes 6.5 s\n",
      "process 6500 peaks takes 6.6 s\n",
      "process 6550 peaks takes 6.6 s\n",
      "process 6600 peaks takes 6.7 s\n",
      "process 6650 peaks takes 6.7 s\n",
      "process 6700 peaks takes 6.8 s\n",
      "process 6750 peaks takes 6.8 s\n",
      "process 6800 peaks takes 6.9 s\n",
      "process 6850 peaks takes 6.9 s\n",
      "process 6900 peaks takes 7.0 s\n",
      "process 6950 peaks takes 7.0 s\n",
      "process 7000 peaks takes 7.1 s\n",
      "process 7050 peaks takes 7.1 s\n",
      "process 7100 peaks takes 7.2 s\n",
      "process 7150 peaks takes 7.2 s\n",
      "process 7200 peaks takes 7.2 s\n",
      "process 7250 peaks takes 7.3 s\n",
      "process 7300 peaks takes 7.3 s\n",
      "process 7350 peaks takes 7.4 s\n",
      "process 7400 peaks takes 7.4 s\n",
      "process 7450 peaks takes 7.5 s\n",
      "process 7500 peaks takes 7.5 s\n",
      "process 7550 peaks takes 7.5 s\n",
      "process 7600 peaks takes 7.6 s\n",
      "process 7650 peaks takes 7.6 s\n",
      "process 7700 peaks takes 7.6 s\n",
      "process 7750 peaks takes 7.7 s\n",
      "process 7800 peaks takes 7.8 s\n",
      "process 7850 peaks takes 7.8 s\n",
      "process 7900 peaks takes 7.8 s\n",
      "process 7950 peaks takes 7.9 s\n",
      "process 8000 peaks takes 7.9 s\n",
      "process 8050 peaks takes 8.0 s\n",
      "process 8100 peaks takes 8.0 s\n",
      "process 8150 peaks takes 8.0 s\n",
      "process 8200 peaks takes 8.1 s\n",
      "process 8250 peaks takes 8.2 s\n",
      "process 8300 peaks takes 8.2 s\n",
      "process 8350 peaks takes 8.3 s\n",
      "process 8400 peaks takes 8.3 s\n",
      "process 8450 peaks takes 8.4 s\n",
      "process 8500 peaks takes 8.4 s\n",
      "process 8550 peaks takes 8.5 s\n",
      "process 8600 peaks takes 8.5 s\n",
      "process 8650 peaks takes 8.6 s\n",
      "process 8700 peaks takes 8.6 s\n",
      "process 8750 peaks takes 8.7 s\n",
      "process 8800 peaks takes 8.7 s\n",
      "process 8850 peaks takes 8.8 s\n",
      "process 8900 peaks takes 8.8 s\n",
      "process 8950 peaks takes 8.9 s\n",
      "process 9000 peaks takes 8.9 s\n",
      "process 9050 peaks takes 9.0 s\n",
      "process 9100 peaks takes 9.0 s\n",
      "process 9150 peaks takes 9.1 s\n",
      "process 9200 peaks takes 9.1 s\n",
      "process 9250 peaks takes 9.2 s\n",
      "process 9300 peaks takes 9.2 s\n",
      "process 9350 peaks takes 9.2 s\n",
      "process 9400 peaks takes 9.3 s\n",
      "process 9450 peaks takes 9.4 s\n",
      "process 9500 peaks takes 9.4 s\n",
      "process 9550 peaks takes 9.4 s\n",
      "process 9600 peaks takes 9.5 s\n",
      "process 9650 peaks takes 9.5 s\n",
      "process 9700 peaks takes 9.6 s\n",
      "process 9750 peaks takes 9.6 s\n",
      "process 9800 peaks takes 9.7 s\n",
      "process 9850 peaks takes 9.7 s\n",
      "process 9900 peaks takes 9.8 s\n",
      "process 9950 peaks takes 9.8 s\n",
      "process 10000 peaks takes 9.8 s\n",
      "process 10050 peaks takes 9.9 s\n",
      "process 10100 peaks takes 10.0 s\n",
      "process 10150 peaks takes 10.0 s\n",
      "process 10200 peaks takes 10.0 s\n",
      "process 10250 peaks takes 10.1 s\n",
      "process 10300 peaks takes 10.1 s\n",
      "process 10350 peaks takes 10.2 s\n",
      "process 10400 peaks takes 10.3 s\n",
      "process 10450 peaks takes 10.3 s\n",
      "process 10500 peaks takes 10.3 s\n",
      "process 10550 peaks takes 10.4 s\n",
      "process 10600 peaks takes 10.5 s\n",
      "process 10650 peaks takes 10.5 s\n",
      "process 10700 peaks takes 10.6 s\n",
      "process 10750 peaks takes 10.6 s\n",
      "process 10800 peaks takes 10.6 s\n",
      "process 10850 peaks takes 10.7 s\n",
      "process 10900 peaks takes 10.8 s\n",
      "process 10950 peaks takes 10.8 s\n",
      "process 11000 peaks takes 10.9 s\n",
      "process 11050 peaks takes 10.9 s\n",
      "process 11100 peaks takes 11.0 s\n",
      "process 11150 peaks takes 11.0 s\n",
      "process 11200 peaks takes 11.0 s\n",
      "process 11250 peaks takes 11.1 s\n",
      "process 11300 peaks takes 11.1 s\n",
      "process 11350 peaks takes 11.2 s\n",
      "process 11400 peaks takes 11.2 s\n",
      "process 11450 peaks takes 11.3 s\n",
      "process 11500 peaks takes 11.4 s\n",
      "process 11550 peaks takes 11.4 s\n",
      "process 11600 peaks takes 11.4 s\n",
      "process 11650 peaks takes 11.5 s\n",
      "process 11700 peaks takes 11.5 s\n",
      "process 11750 peaks takes 11.6 s\n",
      "process 11800 peaks takes 11.6 s\n",
      "process 11850 peaks takes 11.7 s\n",
      "process 11900 peaks takes 11.7 s\n",
      "process 11950 peaks takes 11.8 s\n",
      "process 12000 peaks takes 11.8 s\n",
      "process 12050 peaks takes 11.9 s\n",
      "process 12100 peaks takes 11.9 s\n",
      "process 12150 peaks takes 12.0 s\n",
      "process 12200 peaks takes 12.0 s\n",
      "process 12250 peaks takes 12.0 s\n",
      "process 12300 peaks takes 12.1 s\n",
      "process 12350 peaks takes 12.1 s\n",
      "process 12400 peaks takes 12.2 s\n",
      "process 12450 peaks takes 12.2 s\n",
      "process 12500 peaks takes 12.3 s\n",
      "process 12550 peaks takes 12.3 s\n",
      "process 12600 peaks takes 12.4 s\n",
      "process 12650 peaks takes 12.4 s\n",
      "process 12700 peaks takes 12.5 s\n",
      "process 12750 peaks takes 12.5 s\n",
      "process 12800 peaks takes 12.6 s\n",
      "process 12850 peaks takes 12.6 s\n",
      "process 12900 peaks takes 12.7 s\n",
      "process 12950 peaks takes 12.7 s\n",
      "process 13000 peaks takes 12.8 s\n",
      "process 13050 peaks takes 12.8 s\n",
      "process 13100 peaks takes 12.9 s\n",
      "process 13150 peaks takes 12.9 s\n",
      "process 13200 peaks takes 13.0 s\n",
      "process 13250 peaks takes 13.0 s\n",
      "process 13300 peaks takes 13.1 s\n",
      "process 13350 peaks takes 13.1 s\n",
      "process 13400 peaks takes 13.2 s\n",
      "process 13450 peaks takes 13.2 s\n",
      "process 13500 peaks takes 13.3 s\n",
      "process 13550 peaks takes 13.3 s\n",
      "process 13600 peaks takes 13.4 s\n",
      "process 13650 peaks takes 13.4 s\n",
      "process 13700 peaks takes 13.5 s\n",
      "process 13750 peaks takes 13.5 s\n",
      "process 13800 peaks takes 13.6 s\n",
      "process 13850 peaks takes 13.6 s\n",
      "process 13900 peaks takes 13.7 s\n",
      "process 13950 peaks takes 13.7 s\n",
      "process 14000 peaks takes 13.8 s\n",
      "process 14050 peaks takes 13.8 s\n",
      "process 14100 peaks takes 13.9 s\n",
      "process 14150 peaks takes 13.9 s\n",
      "process 14200 peaks takes 14.0 s\n",
      "process 14250 peaks takes 14.0 s\n",
      "process 14300 peaks takes 14.1 s\n",
      "process 14350 peaks takes 14.1 s\n",
      "process 14400 peaks takes 14.1 s\n",
      "process 14450 peaks takes 14.2 s\n",
      "process 14500 peaks takes 14.2 s\n",
      "process 14550 peaks takes 14.3 s\n",
      "process 14600 peaks takes 14.3 s\n",
      "process 14650 peaks takes 14.4 s\n",
      "process 14700 peaks takes 14.4 s\n",
      "process 14750 peaks takes 14.5 s\n",
      "process 14800 peaks takes 14.5 s\n",
      "process 14850 peaks takes 14.6 s\n",
      "process 14900 peaks takes 14.6 s\n",
      "process 14950 peaks takes 14.7 s\n",
      "process 15000 peaks takes 14.7 s\n",
      "process 15050 peaks takes 14.8 s\n",
      "process 15100 peaks takes 14.8 s\n",
      "process 15150 peaks takes 14.9 s\n",
      "process 15200 peaks takes 14.9 s\n",
      "process 15250 peaks takes 15.0 s\n",
      "process 15300 peaks takes 15.0 s\n",
      "process 15350 peaks takes 15.1 s\n",
      "process 15400 peaks takes 15.1 s\n",
      "process 15450 peaks takes 15.1 s\n",
      "process 15500 peaks takes 15.2 s\n",
      "process 15550 peaks takes 15.2 s\n",
      "process 15600 peaks takes 15.3 s\n",
      "process 15650 peaks takes 15.3 s\n",
      "process 15700 peaks takes 15.4 s\n",
      "process 15750 peaks takes 15.4 s\n",
      "process 15800 peaks takes 15.5 s\n",
      "process 15850 peaks takes 15.5 s\n",
      "process 15900 peaks takes 15.6 s\n",
      "process 15950 peaks takes 15.6 s\n",
      "process 16000 peaks takes 15.6 s\n",
      "process 16050 peaks takes 15.7 s\n",
      "process 16100 peaks takes 15.8 s\n",
      "process 16150 peaks takes 15.8 s\n",
      "process 16200 peaks takes 15.8 s\n",
      "process 16250 peaks takes 15.9 s\n",
      "process 16300 peaks takes 15.9 s\n",
      "process 16350 peaks takes 16.0 s\n",
      "process 16400 peaks takes 16.0 s\n",
      "process 16450 peaks takes 16.1 s\n",
      "process 16500 peaks takes 16.1 s\n",
      "process 16550 peaks takes 16.2 s\n",
      "process 16600 peaks takes 16.2 s\n",
      "process 16650 peaks takes 16.3 s\n",
      "process 16700 peaks takes 16.3 s\n",
      "process 16750 peaks takes 16.4 s\n",
      "process 16800 peaks takes 16.4 s\n",
      "process 16850 peaks takes 16.5 s\n",
      "process 16900 peaks takes 16.5 s\n",
      "process 16950 peaks takes 16.6 s\n",
      "process 17000 peaks takes 16.6 s\n",
      "process 17050 peaks takes 16.7 s\n",
      "process 17100 peaks takes 16.7 s\n",
      "process 17150 peaks takes 16.8 s\n",
      "process 17200 peaks takes 16.8 s\n",
      "process 17250 peaks takes 16.9 s\n",
      "process 17300 peaks takes 16.9 s\n",
      "process 17350 peaks takes 17.0 s\n",
      "process 17400 peaks takes 17.0 s\n",
      "process 17450 peaks takes 17.1 s\n",
      "process 17500 peaks takes 17.1 s\n",
      "process 17550 peaks takes 17.2 s\n",
      "process 17600 peaks takes 17.2 s\n",
      "process 17650 peaks takes 17.3 s\n",
      "process 17700 peaks takes 17.3 s\n",
      "process 17750 peaks takes 17.4 s\n",
      "process 17800 peaks takes 17.4 s\n",
      "process 17850 peaks takes 17.4 s\n",
      "process 17900 peaks takes 17.5 s\n",
      "process 17950 peaks takes 17.6 s\n",
      "process 18000 peaks takes 17.6 s\n",
      "process 18050 peaks takes 17.6 s\n",
      "process 18100 peaks takes 17.7 s\n",
      "process 18150 peaks takes 17.7 s\n",
      "process 18200 peaks takes 17.8 s\n",
      "process 18250 peaks takes 17.8 s\n",
      "process 18300 peaks takes 17.9 s\n",
      "process 18350 peaks takes 17.9 s\n",
      "process 18400 peaks takes 18.0 s\n",
      "process 18450 peaks takes 18.0 s\n",
      "process 18500 peaks takes 18.1 s\n",
      "process 18550 peaks takes 18.1 s\n",
      "process 18600 peaks takes 18.2 s\n",
      "process 18650 peaks takes 18.2 s\n",
      "process 18700 peaks takes 18.3 s\n",
      "process 18750 peaks takes 18.3 s\n",
      "process 18800 peaks takes 18.4 s\n",
      "process 18850 peaks takes 18.4 s\n",
      "process 18900 peaks takes 18.5 s\n",
      "process 18950 peaks takes 18.5 s\n",
      "process 19000 peaks takes 18.6 s\n",
      "process 19050 peaks takes 18.6 s\n",
      "process 19100 peaks takes 18.7 s\n",
      "process 19150 peaks takes 18.7 s\n",
      "process 19200 peaks takes 18.8 s\n",
      "process 19250 peaks takes 18.8 s\n",
      "process 19300 peaks takes 18.9 s\n",
      "process 19350 peaks takes 18.9 s\n",
      "process 19400 peaks takes 19.0 s\n",
      "process 19450 peaks takes 19.0 s\n",
      "process 19500 peaks takes 19.1 s\n",
      "process 19550 peaks takes 19.1 s\n",
      "process 19600 peaks takes 19.2 s\n",
      "process 19650 peaks takes 19.2 s\n",
      "process 19700 peaks takes 19.2 s\n",
      "process 19750 peaks takes 19.3 s\n",
      "process 19800 peaks takes 19.3 s\n",
      "process 19850 peaks takes 19.4 s\n",
      "process 19900 peaks takes 19.4 s\n",
      "process 19950 peaks takes 19.5 s\n",
      "process 20000 peaks takes 19.5 s\n",
      "process 20050 peaks takes 19.6 s\n",
      "process 20100 peaks takes 19.6 s\n",
      "process 20150 peaks takes 19.6 s\n",
      "process 20200 peaks takes 19.7 s\n",
      "process 20250 peaks takes 19.8 s\n",
      "process 20300 peaks takes 19.8 s\n",
      "process 20350 peaks takes 19.8 s\n",
      "process 20400 peaks takes 19.9 s\n",
      "process 20450 peaks takes 19.9 s\n",
      "process 20500 peaks takes 20.0 s\n",
      "process 20550 peaks takes 20.0 s\n",
      "process 20600 peaks takes 20.1 s\n",
      "process 20650 peaks takes 20.1 s\n",
      "process 20700 peaks takes 20.2 s\n",
      "process 20750 peaks takes 20.2 s\n",
      "process 20800 peaks takes 20.3 s\n",
      "process 20850 peaks takes 20.3 s\n",
      "process 20900 peaks takes 20.4 s\n",
      "process 20950 peaks takes 20.4 s\n",
      "process 21000 peaks takes 20.5 s\n",
      "process 21050 peaks takes 20.5 s\n",
      "process 21100 peaks takes 20.6 s\n",
      "process 21150 peaks takes 20.6 s\n",
      "process 21200 peaks takes 20.6 s\n",
      "process 21250 peaks takes 20.7 s\n",
      "process 21300 peaks takes 20.7 s\n",
      "process 21350 peaks takes 20.8 s\n",
      "process 21400 peaks takes 20.8 s\n",
      "process 21450 peaks takes 20.9 s\n",
      "process 21500 peaks takes 20.9 s\n",
      "process 21550 peaks takes 21.0 s\n",
      "process 21600 peaks takes 21.0 s\n",
      "process 21650 peaks takes 21.1 s\n",
      "process 21700 peaks takes 21.1 s\n",
      "process 21750 peaks takes 21.2 s\n",
      "process 21800 peaks takes 21.2 s\n",
      "process 21850 peaks takes 21.3 s\n",
      "process 21900 peaks takes 21.3 s\n",
      "process 21950 peaks takes 21.3 s\n",
      "process 22000 peaks takes 21.4 s\n",
      "process 22050 peaks takes 21.4 s\n",
      "process 22100 peaks takes 21.5 s\n",
      "process 22150 peaks takes 21.5 s\n",
      "process 22200 peaks takes 21.6 s\n",
      "process 22250 peaks takes 21.6 s\n",
      "process 22300 peaks takes 21.7 s\n",
      "process 22350 peaks takes 21.7 s\n",
      "process 22400 peaks takes 21.8 s\n",
      "process 22450 peaks takes 21.8 s\n",
      "process 22500 peaks takes 21.9 s\n",
      "process 22550 peaks takes 21.9 s\n",
      "process 22600 peaks takes 22.0 s\n",
      "process 22650 peaks takes 22.0 s\n",
      "process 22700 peaks takes 22.1 s\n",
      "process 22750 peaks takes 22.1 s\n",
      "process 22800 peaks takes 22.2 s\n",
      "process 22850 peaks takes 22.2 s\n",
      "process 22900 peaks takes 22.3 s\n",
      "process 22950 peaks takes 22.4 s\n",
      "process 23000 peaks takes 22.4 s\n",
      "process 23050 peaks takes 22.5 s\n",
      "process 23100 peaks takes 22.5 s\n",
      "process 23150 peaks takes 22.6 s\n",
      "process 23200 peaks takes 22.6 s\n",
      "process 23250 peaks takes 22.7 s\n",
      "process 23300 peaks takes 22.7 s\n",
      "process 23350 peaks takes 22.8 s\n",
      "process 23400 peaks takes 22.8 s\n",
      "process 23450 peaks takes 22.9 s\n",
      "process 23500 peaks takes 22.9 s\n",
      "process 23550 peaks takes 22.9 s\n",
      "process 23600 peaks takes 23.0 s\n",
      "process 23650 peaks takes 23.1 s\n",
      "process 23700 peaks takes 23.1 s\n",
      "process 23750 peaks takes 23.2 s\n",
      "process 23800 peaks takes 23.2 s\n",
      "process 23850 peaks takes 23.3 s\n",
      "process 23900 peaks takes 23.3 s\n",
      "process 23950 peaks takes 23.4 s\n",
      "process 24000 peaks takes 23.4 s\n",
      "process 24050 peaks takes 23.5 s\n",
      "process 24100 peaks takes 23.6 s\n",
      "process 24150 peaks takes 23.6 s\n",
      "process 24200 peaks takes 23.7 s\n",
      "process 24250 peaks takes 23.7 s\n",
      "process 24300 peaks takes 23.8 s\n",
      "process 24350 peaks takes 23.8 s\n",
      "process 24400 peaks takes 23.9 s\n",
      "process 24450 peaks takes 24.0 s\n",
      "process 24500 peaks takes 24.0 s\n",
      "process 24550 peaks takes 24.1 s\n",
      "process 24600 peaks takes 24.1 s\n",
      "process 24650 peaks takes 24.2 s\n",
      "process 24700 peaks takes 24.3 s\n",
      "process 24750 peaks takes 24.3 s\n",
      "process 24800 peaks takes 24.3 s\n",
      "process 24850 peaks takes 24.4 s\n",
      "process 24900 peaks takes 24.5 s\n",
      "process 24950 peaks takes 24.5 s\n",
      "process 25000 peaks takes 24.6 s\n",
      "process 25050 peaks takes 24.6 s\n",
      "process 25100 peaks takes 24.7 s\n",
      "process 25150 peaks takes 24.7 s\n",
      "process 25200 peaks takes 24.8 s\n",
      "process 25250 peaks takes 24.8 s\n",
      "process 25300 peaks takes 24.9 s\n",
      "process 25350 peaks takes 24.9 s\n",
      "process 25400 peaks takes 25.0 s\n",
      "process 25450 peaks takes 25.0 s\n",
      "process 25500 peaks takes 25.1 s\n",
      "process 25550 peaks takes 25.1 s\n",
      "process 25600 peaks takes 25.2 s\n",
      "process 25650 peaks takes 25.3 s\n",
      "process 25700 peaks takes 25.3 s\n",
      "process 25750 peaks takes 25.4 s\n",
      "process 25800 peaks takes 25.4 s\n",
      "process 25850 peaks takes 25.5 s\n",
      "process 25900 peaks takes 25.5 s\n",
      "process 25950 peaks takes 25.6 s\n",
      "process 26000 peaks takes 25.6 s\n",
      "process 26050 peaks takes 25.7 s\n",
      "process 26100 peaks takes 25.7 s\n",
      "process 26150 peaks takes 25.8 s\n",
      "process 26200 peaks takes 25.8 s\n",
      "process 26250 peaks takes 25.8 s\n",
      "process 26300 peaks takes 25.9 s\n",
      "process 26350 peaks takes 25.9 s\n",
      "process 26400 peaks takes 26.0 s\n",
      "process 26450 peaks takes 26.0 s\n",
      "process 26500 peaks takes 26.1 s\n",
      "process 26550 peaks takes 26.1 s\n",
      "process 26600 peaks takes 26.2 s\n",
      "process 26650 peaks takes 26.2 s\n",
      "process 26700 peaks takes 26.3 s\n",
      "process 26750 peaks takes 26.3 s\n",
      "process 26800 peaks takes 26.4 s\n",
      "process 26850 peaks takes 26.4 s\n",
      "process 26900 peaks takes 26.5 s\n",
      "process 26950 peaks takes 26.5 s\n",
      "process 27000 peaks takes 26.6 s\n",
      "process 27050 peaks takes 26.6 s\n",
      "process 27100 peaks takes 26.7 s\n",
      "process 27150 peaks takes 26.7 s\n",
      "process 27200 peaks takes 26.8 s\n",
      "process 27250 peaks takes 26.8 s\n",
      "process 27300 peaks takes 26.9 s\n",
      "process 27350 peaks takes 26.9 s\n",
      "process 27400 peaks takes 27.0 s\n",
      "process 27450 peaks takes 27.1 s\n",
      "process 27500 peaks takes 27.1 s\n",
      "process 27550 peaks takes 27.2 s\n",
      "process 27600 peaks takes 27.3 s\n",
      "process 27650 peaks takes 27.3 s\n",
      "process 27700 peaks takes 27.4 s\n",
      "process 27750 peaks takes 27.4 s\n",
      "process 27800 peaks takes 27.5 s\n",
      "process 27850 peaks takes 27.5 s\n",
      "process 27900 peaks takes 27.6 s\n",
      "process 27950 peaks takes 27.6 s\n",
      "process 28000 peaks takes 27.7 s\n",
      "process 28050 peaks takes 27.8 s\n",
      "process 28100 peaks takes 27.8 s\n",
      "process 28150 peaks takes 27.9 s\n",
      "process 28200 peaks takes 27.9 s\n",
      "process 28250 peaks takes 28.0 s\n",
      "process 28300 peaks takes 28.0 s\n",
      "process 28350 peaks takes 28.1 s\n",
      "process 28400 peaks takes 28.1 s\n",
      "process 28450 peaks takes 28.2 s\n",
      "process 28500 peaks takes 28.2 s\n",
      "process 28550 peaks takes 28.3 s\n",
      "process 28600 peaks takes 28.3 s\n",
      "process 28650 peaks takes 28.4 s\n",
      "process 28700 peaks takes 28.4 s\n",
      "process 28750 peaks takes 28.5 s\n",
      "process 28800 peaks takes 28.5 s\n",
      "process 28850 peaks takes 28.6 s\n",
      "process 28900 peaks takes 28.6 s\n",
      "process 28950 peaks takes 28.7 s\n",
      "process 29000 peaks takes 28.7 s\n",
      "process 29050 peaks takes 28.8 s\n",
      "process 29100 peaks takes 28.8 s\n",
      "process 29150 peaks takes 28.9 s\n",
      "process 29200 peaks takes 28.9 s\n",
      "process 29250 peaks takes 29.0 s\n",
      "process 29300 peaks takes 29.0 s\n",
      "process 29350 peaks takes 29.1 s\n",
      "process 29400 peaks takes 29.2 s\n",
      "process 29450 peaks takes 29.2 s\n",
      "process 29500 peaks takes 29.3 s\n",
      "process 29550 peaks takes 29.3 s\n",
      "process 29600 peaks takes 29.4 s\n",
      "process 29650 peaks takes 29.5 s\n",
      "process 29700 peaks takes 29.5 s\n",
      "process 29750 peaks takes 29.6 s\n",
      "process 29800 peaks takes 29.6 s\n",
      "process 29850 peaks takes 29.7 s\n",
      "process 29900 peaks takes 29.8 s\n",
      "process 29950 peaks takes 29.8 s\n",
      "\n",
      "train\n",
      "27001 540\n",
      "process 0 peaks takes 0.5 s\n",
      "process 50 peaks takes 0.6 s\n",
      "process 100 peaks takes 0.6 s\n",
      "process 150 peaks takes 0.7 s\n",
      "process 200 peaks takes 0.7 s\n",
      "process 250 peaks takes 0.8 s\n",
      "process 300 peaks takes 0.8 s\n",
      "process 350 peaks takes 0.9 s\n",
      "process 400 peaks takes 1.0 s\n",
      "process 450 peaks takes 1.0 s\n",
      "process 500 peaks takes 1.1 s\n",
      "process 550 peaks takes 1.1 s\n",
      "process 600 peaks takes 1.2 s\n",
      "process 650 peaks takes 1.2 s\n",
      "process 700 peaks takes 1.3 s\n",
      "process 750 peaks takes 1.3 s\n",
      "process 800 peaks takes 1.4 s\n",
      "process 850 peaks takes 1.4 s\n",
      "process 900 peaks takes 1.5 s\n",
      "process 950 peaks takes 1.5 s\n",
      "process 1000 peaks takes 1.6 s\n",
      "process 1050 peaks takes 1.6 s\n",
      "process 1100 peaks takes 1.7 s\n",
      "process 1150 peaks takes 1.7 s\n",
      "process 1200 peaks takes 1.7 s\n",
      "process 1250 peaks takes 1.8 s\n",
      "process 1300 peaks takes 1.8 s\n",
      "process 1350 peaks takes 1.9 s\n",
      "process 1400 peaks takes 1.9 s\n",
      "process 1450 peaks takes 2.0 s\n",
      "process 1500 peaks takes 2.0 s\n",
      "process 1550 peaks takes 2.0 s\n",
      "process 1600 peaks takes 2.1 s\n",
      "process 1650 peaks takes 2.1 s\n",
      "process 1700 peaks takes 2.2 s\n",
      "process 1750 peaks takes 2.3 s\n",
      "process 1800 peaks takes 2.3 s\n",
      "process 1850 peaks takes 2.3 s\n",
      "process 1900 peaks takes 2.4 s\n",
      "process 1950 peaks takes 2.4 s\n",
      "process 2000 peaks takes 2.5 s\n",
      "process 2050 peaks takes 2.5 s\n",
      "process 2100 peaks takes 2.6 s\n",
      "process 2150 peaks takes 2.6 s\n",
      "process 2200 peaks takes 2.7 s\n",
      "process 2250 peaks takes 2.7 s\n",
      "process 2300 peaks takes 2.8 s\n",
      "process 2350 peaks takes 2.8 s\n",
      "process 2400 peaks takes 2.9 s\n",
      "process 2450 peaks takes 2.9 s\n",
      "process 2500 peaks takes 3.0 s\n",
      "process 2550 peaks takes 3.0 s\n",
      "process 2600 peaks takes 3.0 s\n",
      "process 2650 peaks takes 3.1 s\n",
      "process 2700 peaks takes 3.1 s\n",
      "process 2750 peaks takes 3.2 s\n",
      "process 2800 peaks takes 3.2 s\n",
      "process 2850 peaks takes 3.3 s\n",
      "process 2900 peaks takes 3.3 s\n",
      "process 2950 peaks takes 3.4 s\n",
      "process 3000 peaks takes 3.4 s\n",
      "process 3050 peaks takes 3.5 s\n",
      "process 3100 peaks takes 3.5 s\n",
      "process 3150 peaks takes 3.6 s\n",
      "process 3200 peaks takes 3.6 s\n",
      "process 3250 peaks takes 3.7 s\n",
      "process 3300 peaks takes 3.7 s\n",
      "process 3350 peaks takes 3.8 s\n",
      "process 3400 peaks takes 3.8 s\n",
      "process 3450 peaks takes 3.9 s\n",
      "process 3500 peaks takes 3.9 s\n",
      "process 3550 peaks takes 4.0 s\n",
      "process 3600 peaks takes 4.0 s\n",
      "process 3650 peaks takes 4.0 s\n",
      "process 3700 peaks takes 4.1 s\n",
      "process 3750 peaks takes 4.1 s\n",
      "process 3800 peaks takes 4.2 s\n",
      "process 3850 peaks takes 4.2 s\n",
      "process 3900 peaks takes 4.2 s\n",
      "process 3950 peaks takes 4.3 s\n",
      "process 4000 peaks takes 4.3 s\n",
      "process 4050 peaks takes 4.4 s\n",
      "process 4100 peaks takes 4.5 s\n",
      "process 4150 peaks takes 4.5 s\n",
      "process 4200 peaks takes 4.6 s\n",
      "process 4250 peaks takes 4.6 s\n",
      "process 4300 peaks takes 4.7 s\n",
      "process 4350 peaks takes 4.7 s\n",
      "process 4400 peaks takes 4.8 s\n",
      "process 4450 peaks takes 4.8 s\n",
      "process 4500 peaks takes 4.8 s\n",
      "process 4550 peaks takes 4.9 s\n",
      "process 4600 peaks takes 4.9 s\n",
      "process 4650 peaks takes 5.0 s\n",
      "process 4700 peaks takes 5.0 s\n",
      "process 4750 peaks takes 5.1 s\n",
      "process 4800 peaks takes 5.1 s\n",
      "process 4850 peaks takes 5.2 s\n",
      "process 4900 peaks takes 5.2 s\n",
      "process 4950 peaks takes 5.3 s\n",
      "process 5000 peaks takes 5.3 s\n",
      "process 5050 peaks takes 5.4 s\n",
      "process 5100 peaks takes 5.4 s\n",
      "process 5150 peaks takes 5.5 s\n",
      "process 5200 peaks takes 5.5 s\n",
      "process 5250 peaks takes 5.6 s\n",
      "process 5300 peaks takes 5.6 s\n",
      "process 5350 peaks takes 5.7 s\n",
      "process 5400 peaks takes 5.7 s\n",
      "process 5450 peaks takes 5.8 s\n",
      "process 5500 peaks takes 5.8 s\n",
      "process 5550 peaks takes 5.8 s\n",
      "process 5600 peaks takes 5.9 s\n",
      "process 5650 peaks takes 5.9 s\n",
      "process 5700 peaks takes 6.0 s\n",
      "process 5750 peaks takes 6.0 s\n",
      "process 5800 peaks takes 6.1 s\n",
      "process 5850 peaks takes 6.1 s\n",
      "process 5900 peaks takes 6.2 s\n",
      "process 5950 peaks takes 6.2 s\n",
      "process 6000 peaks takes 6.3 s\n",
      "process 6050 peaks takes 6.3 s\n",
      "process 6100 peaks takes 6.4 s\n",
      "process 6150 peaks takes 6.4 s\n",
      "process 6200 peaks takes 6.4 s\n",
      "process 6250 peaks takes 6.5 s\n",
      "process 6300 peaks takes 6.5 s\n",
      "process 6350 peaks takes 6.6 s\n",
      "process 6400 peaks takes 6.7 s\n",
      "process 6450 peaks takes 6.7 s\n",
      "process 6500 peaks takes 6.8 s\n",
      "process 6550 peaks takes 6.8 s\n",
      "process 6600 peaks takes 6.8 s\n",
      "process 6650 peaks takes 6.9 s\n",
      "process 6700 peaks takes 6.9 s\n",
      "process 6750 peaks takes 7.0 s\n",
      "process 6800 peaks takes 7.0 s\n",
      "process 6850 peaks takes 7.1 s\n",
      "process 6900 peaks takes 7.1 s\n",
      "process 6950 peaks takes 7.1 s\n",
      "process 7000 peaks takes 7.2 s\n",
      "process 7050 peaks takes 7.3 s\n",
      "process 7100 peaks takes 7.3 s\n",
      "process 7150 peaks takes 7.4 s\n",
      "process 7200 peaks takes 7.4 s\n",
      "process 7250 peaks takes 7.5 s\n",
      "process 7300 peaks takes 7.5 s\n",
      "process 7350 peaks takes 7.6 s\n",
      "process 7400 peaks takes 7.6 s\n",
      "process 7450 peaks takes 7.7 s\n",
      "process 7500 peaks takes 7.7 s\n",
      "process 7550 peaks takes 7.7 s\n",
      "process 7600 peaks takes 7.8 s\n",
      "process 7650 peaks takes 7.8 s\n",
      "process 7700 peaks takes 7.9 s\n",
      "process 7750 peaks takes 7.9 s\n",
      "process 7800 peaks takes 8.0 s\n",
      "process 7850 peaks takes 8.0 s\n",
      "process 7900 peaks takes 8.1 s\n",
      "process 7950 peaks takes 8.1 s\n",
      "process 8000 peaks takes 8.2 s\n",
      "process 8050 peaks takes 8.2 s\n",
      "process 8100 peaks takes 8.2 s\n",
      "process 8150 peaks takes 8.3 s\n",
      "process 8200 peaks takes 8.3 s\n",
      "process 8250 peaks takes 8.4 s\n",
      "process 8300 peaks takes 8.4 s\n",
      "process 8350 peaks takes 8.5 s\n",
      "process 8400 peaks takes 8.5 s\n",
      "process 8450 peaks takes 8.6 s\n",
      "process 8500 peaks takes 8.6 s\n",
      "process 8550 peaks takes 8.7 s\n",
      "process 8600 peaks takes 8.7 s\n",
      "process 8650 peaks takes 8.8 s\n",
      "process 8700 peaks takes 8.8 s\n",
      "process 8750 peaks takes 8.9 s\n",
      "process 8800 peaks takes 8.9 s\n",
      "process 8850 peaks takes 9.0 s\n",
      "process 8900 peaks takes 9.0 s\n",
      "process 8950 peaks takes 9.1 s\n",
      "process 9000 peaks takes 9.1 s\n",
      "process 9050 peaks takes 9.2 s\n",
      "process 9100 peaks takes 9.2 s\n",
      "process 9150 peaks takes 9.3 s\n",
      "process 9200 peaks takes 9.3 s\n",
      "process 9250 peaks takes 9.4 s\n",
      "process 9300 peaks takes 9.4 s\n",
      "process 9350 peaks takes 9.5 s\n",
      "process 9400 peaks takes 9.5 s\n",
      "process 9450 peaks takes 9.6 s\n",
      "process 9500 peaks takes 9.6 s\n",
      "process 9550 peaks takes 9.7 s\n",
      "process 9600 peaks takes 9.7 s\n",
      "process 9650 peaks takes 9.8 s\n",
      "process 9700 peaks takes 9.8 s\n",
      "process 9750 peaks takes 9.9 s\n",
      "process 9800 peaks takes 9.9 s\n",
      "process 9850 peaks takes 10.0 s\n",
      "process 9900 peaks takes 10.0 s\n",
      "process 9950 peaks takes 10.1 s\n",
      "process 10000 peaks takes 10.1 s\n",
      "process 10050 peaks takes 10.2 s\n",
      "process 10100 peaks takes 10.2 s\n",
      "process 10150 peaks takes 10.3 s\n",
      "process 10200 peaks takes 10.3 s\n",
      "process 10250 peaks takes 10.4 s\n",
      "process 10300 peaks takes 10.4 s\n",
      "process 10350 peaks takes 10.5 s\n",
      "process 10400 peaks takes 10.6 s\n",
      "process 10450 peaks takes 10.6 s\n",
      "process 10500 peaks takes 10.7 s\n",
      "process 10550 peaks takes 10.7 s\n",
      "process 10600 peaks takes 10.8 s\n",
      "process 10650 peaks takes 10.8 s\n",
      "process 10700 peaks takes 10.9 s\n",
      "process 10750 peaks takes 10.9 s\n",
      "process 10800 peaks takes 11.0 s\n",
      "process 10850 peaks takes 11.0 s\n",
      "process 10900 peaks takes 11.1 s\n",
      "process 10950 peaks takes 11.1 s\n",
      "process 11000 peaks takes 11.1 s\n",
      "process 11050 peaks takes 11.2 s\n",
      "process 11100 peaks takes 11.3 s\n",
      "process 11150 peaks takes 11.3 s\n",
      "process 11200 peaks takes 11.3 s\n",
      "process 11250 peaks takes 11.4 s\n",
      "process 11300 peaks takes 11.4 s\n",
      "process 11350 peaks takes 11.5 s\n",
      "process 11400 peaks takes 11.5 s\n",
      "process 11450 peaks takes 11.6 s\n",
      "process 11500 peaks takes 11.6 s\n",
      "process 11550 peaks takes 11.7 s\n",
      "process 11600 peaks takes 11.7 s\n",
      "process 11650 peaks takes 11.7 s\n",
      "process 11700 peaks takes 11.8 s\n",
      "process 11750 peaks takes 11.8 s\n",
      "process 11800 peaks takes 11.9 s\n",
      "process 11850 peaks takes 11.9 s\n",
      "process 11900 peaks takes 12.0 s\n",
      "process 11950 peaks takes 12.1 s\n",
      "process 12000 peaks takes 12.1 s\n",
      "process 12050 peaks takes 12.2 s\n",
      "process 12100 peaks takes 12.2 s\n",
      "process 12150 peaks takes 12.3 s\n",
      "process 12200 peaks takes 12.3 s\n",
      "process 12250 peaks takes 12.4 s\n",
      "process 12300 peaks takes 12.4 s\n",
      "process 12350 peaks takes 12.5 s\n",
      "process 12400 peaks takes 12.5 s\n",
      "process 12450 peaks takes 12.6 s\n",
      "process 12500 peaks takes 12.6 s\n",
      "process 12550 peaks takes 12.7 s\n",
      "process 12600 peaks takes 12.7 s\n",
      "process 12650 peaks takes 12.8 s\n",
      "process 12700 peaks takes 12.8 s\n",
      "process 12750 peaks takes 12.9 s\n",
      "process 12800 peaks takes 12.9 s\n",
      "process 12850 peaks takes 13.0 s\n",
      "process 12900 peaks takes 13.0 s\n",
      "process 12950 peaks takes 13.1 s\n",
      "process 13000 peaks takes 13.2 s\n",
      "process 13050 peaks takes 13.2 s\n",
      "process 13100 peaks takes 13.2 s\n",
      "process 13150 peaks takes 13.3 s\n",
      "process 13200 peaks takes 13.4 s\n",
      "process 13250 peaks takes 13.4 s\n",
      "process 13300 peaks takes 13.4 s\n",
      "process 13350 peaks takes 13.5 s\n",
      "process 13400 peaks takes 13.6 s\n",
      "process 13450 peaks takes 13.6 s\n",
      "process 13500 peaks takes 13.6 s\n",
      "process 13550 peaks takes 13.7 s\n",
      "process 13600 peaks takes 13.7 s\n",
      "process 13650 peaks takes 13.8 s\n",
      "process 13700 peaks takes 13.8 s\n",
      "process 13750 peaks takes 13.9 s\n",
      "process 13800 peaks takes 13.9 s\n",
      "process 13850 peaks takes 13.9 s\n",
      "process 13900 peaks takes 14.0 s\n",
      "process 13950 peaks takes 14.0 s\n",
      "process 14000 peaks takes 14.1 s\n",
      "process 14050 peaks takes 14.1 s\n",
      "process 14100 peaks takes 14.2 s\n",
      "process 14150 peaks takes 14.2 s\n",
      "process 14200 peaks takes 14.2 s\n",
      "process 14250 peaks takes 14.3 s\n",
      "process 14300 peaks takes 14.3 s\n",
      "process 14350 peaks takes 14.4 s\n",
      "process 14400 peaks takes 14.4 s\n",
      "process 14450 peaks takes 14.5 s\n",
      "process 14500 peaks takes 14.5 s\n",
      "process 14550 peaks takes 14.6 s\n",
      "process 14600 peaks takes 14.6 s\n",
      "process 14650 peaks takes 14.7 s\n",
      "process 14700 peaks takes 14.7 s\n",
      "process 14750 peaks takes 14.8 s\n",
      "process 14800 peaks takes 14.8 s\n",
      "process 14850 peaks takes 14.9 s\n",
      "process 14900 peaks takes 14.9 s\n",
      "process 14950 peaks takes 15.0 s\n",
      "process 15000 peaks takes 15.0 s\n",
      "process 15050 peaks takes 15.1 s\n",
      "process 15100 peaks takes 15.1 s\n",
      "process 15150 peaks takes 15.2 s\n",
      "process 15200 peaks takes 15.2 s\n",
      "process 15250 peaks takes 15.3 s\n",
      "process 15300 peaks takes 15.4 s\n",
      "process 15350 peaks takes 15.4 s\n",
      "process 15400 peaks takes 15.5 s\n",
      "process 15450 peaks takes 15.5 s\n",
      "process 15500 peaks takes 15.6 s\n",
      "process 15550 peaks takes 15.6 s\n",
      "process 15600 peaks takes 15.6 s\n",
      "process 15650 peaks takes 15.7 s\n",
      "process 15700 peaks takes 15.8 s\n",
      "process 15750 peaks takes 15.8 s\n",
      "process 15800 peaks takes 15.8 s\n",
      "process 15850 peaks takes 15.9 s\n",
      "process 15900 peaks takes 15.9 s\n",
      "process 15950 peaks takes 16.0 s\n",
      "process 16000 peaks takes 16.0 s\n",
      "process 16050 peaks takes 16.1 s\n",
      "process 16100 peaks takes 16.1 s\n",
      "process 16150 peaks takes 16.2 s\n",
      "process 16200 peaks takes 16.2 s\n",
      "process 16250 peaks takes 16.3 s\n",
      "process 16300 peaks takes 16.3 s\n",
      "process 16350 peaks takes 16.4 s\n",
      "process 16400 peaks takes 16.4 s\n",
      "process 16450 peaks takes 16.5 s\n",
      "process 16500 peaks takes 16.5 s\n",
      "process 16550 peaks takes 16.6 s\n",
      "process 16600 peaks takes 16.6 s\n",
      "process 16650 peaks takes 16.7 s\n",
      "process 16700 peaks takes 16.7 s\n",
      "process 16750 peaks takes 16.8 s\n",
      "process 16800 peaks takes 16.8 s\n",
      "process 16850 peaks takes 16.9 s\n",
      "process 16900 peaks takes 16.9 s\n",
      "process 16950 peaks takes 17.0 s\n",
      "process 17000 peaks takes 17.0 s\n",
      "process 17050 peaks takes 17.1 s\n",
      "process 17100 peaks takes 17.1 s\n",
      "process 17150 peaks takes 17.1 s\n",
      "process 17200 peaks takes 17.2 s\n",
      "process 17250 peaks takes 17.2 s\n",
      "process 17300 peaks takes 17.3 s\n",
      "process 17350 peaks takes 17.3 s\n",
      "process 17400 peaks takes 17.4 s\n",
      "process 17450 peaks takes 17.4 s\n",
      "process 17500 peaks takes 17.5 s\n",
      "process 17550 peaks takes 17.5 s\n",
      "process 17600 peaks takes 17.5 s\n",
      "process 17650 peaks takes 17.6 s\n",
      "process 17700 peaks takes 17.6 s\n",
      "process 17750 peaks takes 17.7 s\n",
      "process 17800 peaks takes 17.7 s\n",
      "process 17850 peaks takes 17.8 s\n",
      "process 17900 peaks takes 17.8 s\n",
      "process 17950 peaks takes 17.9 s\n",
      "process 18000 peaks takes 17.9 s\n",
      "process 18050 peaks takes 17.9 s\n",
      "process 18100 peaks takes 18.0 s\n",
      "process 18150 peaks takes 18.0 s\n",
      "process 18200 peaks takes 18.1 s\n",
      "process 18250 peaks takes 18.1 s\n",
      "process 18300 peaks takes 18.2 s\n",
      "process 18350 peaks takes 18.2 s\n",
      "process 18400 peaks takes 18.3 s\n",
      "process 18450 peaks takes 18.3 s\n",
      "process 18500 peaks takes 18.4 s\n",
      "process 18550 peaks takes 18.4 s\n",
      "process 18600 peaks takes 18.4 s\n",
      "process 18650 peaks takes 18.5 s\n",
      "process 18700 peaks takes 18.5 s\n",
      "process 18750 peaks takes 18.6 s\n",
      "process 18800 peaks takes 18.6 s\n",
      "process 18850 peaks takes 18.7 s\n",
      "process 18900 peaks takes 18.7 s\n",
      "process 18950 peaks takes 18.8 s\n",
      "process 19000 peaks takes 18.8 s\n",
      "process 19050 peaks takes 18.9 s\n",
      "process 19100 peaks takes 18.9 s\n",
      "process 19150 peaks takes 18.9 s\n",
      "process 19200 peaks takes 19.0 s\n",
      "process 19250 peaks takes 19.1 s\n",
      "process 19300 peaks takes 19.1 s\n",
      "process 19350 peaks takes 19.1 s\n",
      "process 19400 peaks takes 19.2 s\n",
      "process 19450 peaks takes 19.2 s\n",
      "process 19500 peaks takes 19.3 s\n",
      "process 19550 peaks takes 19.4 s\n",
      "process 19600 peaks takes 19.4 s\n",
      "process 19650 peaks takes 19.5 s\n",
      "process 19700 peaks takes 19.5 s\n",
      "process 19750 peaks takes 19.6 s\n",
      "process 19800 peaks takes 19.6 s\n",
      "process 19850 peaks takes 19.6 s\n",
      "process 19900 peaks takes 19.7 s\n",
      "process 19950 peaks takes 19.7 s\n",
      "process 20000 peaks takes 19.8 s\n",
      "process 20050 peaks takes 19.9 s\n",
      "process 20100 peaks takes 19.9 s\n",
      "process 20150 peaks takes 19.9 s\n",
      "process 20200 peaks takes 20.0 s\n",
      "process 20250 peaks takes 20.0 s\n",
      "process 20300 peaks takes 20.1 s\n",
      "process 20350 peaks takes 20.1 s\n",
      "process 20400 peaks takes 20.2 s\n",
      "process 20450 peaks takes 20.2 s\n",
      "process 20500 peaks takes 20.3 s\n",
      "process 20550 peaks takes 20.3 s\n",
      "process 20600 peaks takes 20.4 s\n",
      "process 20650 peaks takes 20.4 s\n",
      "process 20700 peaks takes 20.5 s\n",
      "process 20750 peaks takes 20.5 s\n",
      "process 20800 peaks takes 20.6 s\n",
      "process 20850 peaks takes 20.6 s\n",
      "process 20900 peaks takes 20.7 s\n",
      "process 20950 peaks takes 20.7 s\n",
      "process 21000 peaks takes 20.8 s\n",
      "process 21050 peaks takes 20.9 s\n",
      "process 21100 peaks takes 20.9 s\n",
      "process 21150 peaks takes 21.0 s\n",
      "process 21200 peaks takes 21.0 s\n",
      "process 21250 peaks takes 21.1 s\n",
      "process 21300 peaks takes 21.1 s\n",
      "process 21350 peaks takes 21.2 s\n",
      "process 21400 peaks takes 21.2 s\n",
      "process 21450 peaks takes 21.3 s\n",
      "process 21500 peaks takes 21.3 s\n",
      "process 21550 peaks takes 21.4 s\n",
      "process 21600 peaks takes 21.4 s\n",
      "process 21650 peaks takes 21.5 s\n",
      "process 21700 peaks takes 21.5 s\n",
      "process 21750 peaks takes 21.6 s\n",
      "process 21800 peaks takes 21.6 s\n",
      "process 21850 peaks takes 21.7 s\n",
      "process 21900 peaks takes 21.7 s\n",
      "process 21950 peaks takes 21.8 s\n",
      "process 22000 peaks takes 21.8 s\n",
      "process 22050 peaks takes 21.9 s\n",
      "process 22100 peaks takes 21.9 s\n",
      "process 22150 peaks takes 22.0 s\n",
      "process 22200 peaks takes 22.0 s\n",
      "process 22250 peaks takes 22.1 s\n",
      "process 22300 peaks takes 22.1 s\n",
      "process 22350 peaks takes 22.2 s\n",
      "process 22400 peaks takes 22.2 s\n",
      "process 22450 peaks takes 22.3 s\n",
      "process 22500 peaks takes 22.3 s\n",
      "process 22550 peaks takes 22.4 s\n",
      "process 22600 peaks takes 22.4 s\n",
      "process 22650 peaks takes 22.5 s\n",
      "process 22700 peaks takes 22.5 s\n",
      "process 22750 peaks takes 22.6 s\n",
      "process 22800 peaks takes 22.7 s\n",
      "process 22850 peaks takes 22.7 s\n",
      "process 22900 peaks takes 22.7 s\n",
      "process 22950 peaks takes 22.8 s\n",
      "process 23000 peaks takes 22.8 s\n",
      "process 23050 peaks takes 22.9 s\n",
      "process 23100 peaks takes 23.0 s\n",
      "process 23150 peaks takes 23.0 s\n",
      "process 23200 peaks takes 23.1 s\n",
      "process 23250 peaks takes 23.1 s\n",
      "process 23300 peaks takes 23.2 s\n",
      "process 23350 peaks takes 23.2 s\n",
      "process 23400 peaks takes 23.3 s\n",
      "process 23450 peaks takes 23.3 s\n",
      "process 23500 peaks takes 23.4 s\n",
      "process 23550 peaks takes 23.4 s\n",
      "process 23600 peaks takes 23.4 s\n",
      "process 23650 peaks takes 23.5 s\n",
      "process 23700 peaks takes 23.5 s\n",
      "process 23750 peaks takes 23.5 s\n",
      "process 23800 peaks takes 23.6 s\n",
      "process 23850 peaks takes 23.6 s\n",
      "process 23900 peaks takes 23.7 s\n",
      "process 23950 peaks takes 23.7 s\n",
      "process 24000 peaks takes 23.7 s\n",
      "process 24050 peaks takes 23.8 s\n",
      "process 24100 peaks takes 23.8 s\n",
      "process 24150 peaks takes 23.9 s\n",
      "process 24200 peaks takes 23.9 s\n",
      "process 24250 peaks takes 24.0 s\n",
      "process 24300 peaks takes 24.0 s\n",
      "process 24350 peaks takes 24.0 s\n",
      "process 24400 peaks takes 24.1 s\n",
      "process 24450 peaks takes 24.1 s\n",
      "process 24500 peaks takes 24.2 s\n",
      "process 24550 peaks takes 24.2 s\n",
      "process 24600 peaks takes 24.3 s\n",
      "process 24650 peaks takes 24.3 s\n",
      "process 24700 peaks takes 24.4 s\n",
      "process 24750 peaks takes 24.4 s\n",
      "process 24800 peaks takes 24.5 s\n",
      "process 24850 peaks takes 24.5 s\n",
      "process 24900 peaks takes 24.6 s\n",
      "process 24950 peaks takes 24.6 s\n",
      "process 25000 peaks takes 24.7 s\n",
      "process 25050 peaks takes 24.7 s\n",
      "process 25100 peaks takes 24.8 s\n",
      "process 25150 peaks takes 24.8 s\n",
      "process 25200 peaks takes 24.9 s\n",
      "process 25250 peaks takes 24.9 s\n",
      "process 25300 peaks takes 25.0 s\n",
      "process 25350 peaks takes 25.0 s\n",
      "process 25400 peaks takes 25.1 s\n",
      "process 25450 peaks takes 25.1 s\n",
      "process 25500 peaks takes 25.2 s\n",
      "process 25550 peaks takes 25.3 s\n",
      "process 25600 peaks takes 25.3 s\n",
      "process 25650 peaks takes 25.3 s\n",
      "process 25700 peaks takes 25.4 s\n",
      "process 25750 peaks takes 25.4 s\n",
      "process 25800 peaks takes 25.5 s\n",
      "process 25850 peaks takes 25.5 s\n",
      "process 25900 peaks takes 25.6 s\n",
      "process 25950 peaks takes 25.6 s\n",
      "process 26000 peaks takes 25.6 s\n",
      "process 26050 peaks takes 25.7 s\n",
      "process 26100 peaks takes 25.7 s\n",
      "process 26150 peaks takes 25.8 s\n",
      "process 26200 peaks takes 25.8 s\n",
      "process 26250 peaks takes 25.9 s\n",
      "process 26300 peaks takes 25.9 s\n",
      "process 26350 peaks takes 26.0 s\n",
      "process 26400 peaks takes 26.0 s\n",
      "process 26450 peaks takes 26.1 s\n",
      "process 26500 peaks takes 26.1 s\n",
      "process 26550 peaks takes 26.1 s\n",
      "process 26600 peaks takes 26.2 s\n",
      "process 26650 peaks takes 26.3 s\n",
      "process 26700 peaks takes 26.3 s\n",
      "process 26750 peaks takes 26.3 s\n",
      "process 26800 peaks takes 26.4 s\n",
      "process 26850 peaks takes 26.4 s\n",
      "process 26900 peaks takes 26.5 s\n",
      "process 26950 peaks takes 26.5 s\n",
      "\n",
      "test\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "\n",
      "val\n",
      "1499 29\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.7 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.5 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.6 s\n",
      "process 1350 peaks takes 1.7 s\n",
      "process 1400 peaks takes 1.7 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs10000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:07:39.878511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:07:39.984894: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:07:39.988224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:39.988253: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:07:40.487768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:40.487857: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:40.487883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.8GB.\n",
      "2024-05-13 07:07:43.158678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:07:43.158795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.158858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.158916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.158944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.158986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.159039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.159066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.159113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:07:43.159120: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:07:43.159448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 10000)     330000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 10000)    0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10000)        0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,849,810\n",
      "Trainable params: 4,843,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "211/211 [==============================] - 362s 2s/step - loss: 0.2191 - auc: 0.7112 - auc_1: 0.1438 - val_loss: 0.1964 - val_auc: 0.7657 - val_auc_1: 0.2677\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs10000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs10000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "(10000, 30000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000 --batch 50\n",
      "2024-05-13 07:13:51.105630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:13:51.206864: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:13:51.209882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:13:51.209916: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:13:51.686968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:13:51.687066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:13:51.687074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[27001, 1500, 1499]\n",
      "30000 600\n",
      "process 0 peaks takes 0.5 s\n",
      "process 50 peaks takes 0.5 s\n",
      "process 100 peaks takes 0.6 s\n",
      "process 150 peaks takes 0.6 s\n",
      "process 200 peaks takes 0.7 s\n",
      "process 250 peaks takes 0.7 s\n",
      "process 300 peaks takes 0.8 s\n",
      "process 350 peaks takes 0.8 s\n",
      "process 400 peaks takes 0.8 s\n",
      "process 450 peaks takes 0.9 s\n",
      "process 500 peaks takes 1.0 s\n",
      "process 550 peaks takes 1.0 s\n",
      "process 600 peaks takes 1.1 s\n",
      "process 650 peaks takes 1.1 s\n",
      "process 700 peaks takes 1.1 s\n",
      "process 750 peaks takes 1.2 s\n",
      "process 800 peaks takes 1.3 s\n",
      "process 850 peaks takes 1.3 s\n",
      "process 900 peaks takes 1.3 s\n",
      "process 950 peaks takes 1.4 s\n",
      "process 1000 peaks takes 1.4 s\n",
      "process 1050 peaks takes 1.5 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.6 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.7 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.8 s\n",
      "process 1500 peaks takes 1.9 s\n",
      "process 1550 peaks takes 1.9 s\n",
      "process 1600 peaks takes 2.0 s\n",
      "process 1650 peaks takes 2.0 s\n",
      "process 1700 peaks takes 2.1 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.2 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.3 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.4 s\n",
      "process 2100 peaks takes 2.5 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.6 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.7 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.8 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 2.9 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "process 2700 peaks takes 3.0 s\n",
      "process 2750 peaks takes 3.1 s\n",
      "process 2800 peaks takes 3.1 s\n",
      "process 2850 peaks takes 3.2 s\n",
      "process 2900 peaks takes 3.2 s\n",
      "process 2950 peaks takes 3.3 s\n",
      "process 3000 peaks takes 3.3 s\n",
      "process 3050 peaks takes 3.4 s\n",
      "process 3100 peaks takes 3.4 s\n",
      "process 3150 peaks takes 3.5 s\n",
      "process 3200 peaks takes 3.5 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.6 s\n",
      "process 3350 peaks takes 3.7 s\n",
      "process 3400 peaks takes 3.7 s\n",
      "process 3450 peaks takes 3.7 s\n",
      "process 3500 peaks takes 3.8 s\n",
      "process 3550 peaks takes 3.8 s\n",
      "process 3600 peaks takes 3.9 s\n",
      "process 3650 peaks takes 3.9 s\n",
      "process 3700 peaks takes 4.0 s\n",
      "process 3750 peaks takes 4.0 s\n",
      "process 3800 peaks takes 4.1 s\n",
      "process 3850 peaks takes 4.1 s\n",
      "process 3900 peaks takes 4.2 s\n",
      "process 3950 peaks takes 4.2 s\n",
      "process 4000 peaks takes 4.3 s\n",
      "process 4050 peaks takes 4.3 s\n",
      "process 4100 peaks takes 4.3 s\n",
      "process 4150 peaks takes 4.4 s\n",
      "process 4200 peaks takes 4.4 s\n",
      "process 4250 peaks takes 4.5 s\n",
      "process 4300 peaks takes 4.5 s\n",
      "process 4350 peaks takes 4.6 s\n",
      "process 4400 peaks takes 4.6 s\n",
      "process 4450 peaks takes 4.7 s\n",
      "process 4500 peaks takes 4.7 s\n",
      "process 4550 peaks takes 4.8 s\n",
      "process 4600 peaks takes 4.8 s\n",
      "process 4650 peaks takes 4.9 s\n",
      "process 4700 peaks takes 4.9 s\n",
      "process 4750 peaks takes 5.0 s\n",
      "process 4800 peaks takes 5.0 s\n",
      "process 4850 peaks takes 5.1 s\n",
      "process 4900 peaks takes 5.1 s\n",
      "process 4950 peaks takes 5.2 s\n",
      "process 5000 peaks takes 5.2 s\n",
      "process 5050 peaks takes 5.3 s\n",
      "process 5100 peaks takes 5.3 s\n",
      "process 5150 peaks takes 5.4 s\n",
      "process 5200 peaks takes 5.4 s\n",
      "process 5250 peaks takes 5.4 s\n",
      "process 5300 peaks takes 5.5 s\n",
      "process 5350 peaks takes 5.5 s\n",
      "process 5400 peaks takes 5.6 s\n",
      "process 5450 peaks takes 5.6 s\n",
      "process 5500 peaks takes 5.7 s\n",
      "process 5550 peaks takes 5.7 s\n",
      "process 5600 peaks takes 5.8 s\n",
      "process 5650 peaks takes 5.8 s\n",
      "process 5700 peaks takes 5.9 s\n",
      "process 5750 peaks takes 5.9 s\n",
      "process 5800 peaks takes 6.0 s\n",
      "process 5850 peaks takes 6.0 s\n",
      "process 5900 peaks takes 6.1 s\n",
      "process 5950 peaks takes 6.1 s\n",
      "process 6000 peaks takes 6.2 s\n",
      "process 6050 peaks takes 6.2 s\n",
      "process 6100 peaks takes 6.3 s\n",
      "process 6150 peaks takes 6.3 s\n",
      "process 6200 peaks takes 6.3 s\n",
      "process 6250 peaks takes 6.4 s\n",
      "process 6300 peaks takes 6.5 s\n",
      "process 6350 peaks takes 6.5 s\n",
      "process 6400 peaks takes 6.5 s\n",
      "process 6450 peaks takes 6.6 s\n",
      "process 6500 peaks takes 6.6 s\n",
      "process 6550 peaks takes 6.7 s\n",
      "process 6600 peaks takes 6.7 s\n",
      "process 6650 peaks takes 6.8 s\n",
      "process 6700 peaks takes 6.8 s\n",
      "process 6750 peaks takes 6.9 s\n",
      "process 6800 peaks takes 6.9 s\n",
      "process 6850 peaks takes 7.0 s\n",
      "process 6900 peaks takes 7.0 s\n",
      "process 6950 peaks takes 7.1 s\n",
      "process 7000 peaks takes 7.1 s\n",
      "process 7050 peaks takes 7.2 s\n",
      "process 7100 peaks takes 7.2 s\n",
      "process 7150 peaks takes 7.3 s\n",
      "process 7200 peaks takes 7.3 s\n",
      "process 7250 peaks takes 7.3 s\n",
      "process 7300 peaks takes 7.4 s\n",
      "process 7350 peaks takes 7.5 s\n",
      "process 7400 peaks takes 7.5 s\n",
      "process 7450 peaks takes 7.5 s\n",
      "process 7500 peaks takes 7.6 s\n",
      "process 7550 peaks takes 7.6 s\n",
      "process 7600 peaks takes 7.7 s\n",
      "process 7650 peaks takes 7.7 s\n",
      "process 7700 peaks takes 7.8 s\n",
      "process 7750 peaks takes 7.8 s\n",
      "process 7800 peaks takes 7.8 s\n",
      "process 7850 peaks takes 7.9 s\n",
      "process 7900 peaks takes 8.0 s\n",
      "process 7950 peaks takes 8.0 s\n",
      "process 8000 peaks takes 8.1 s\n",
      "process 8050 peaks takes 8.1 s\n",
      "process 8100 peaks takes 8.2 s\n",
      "process 8150 peaks takes 8.2 s\n",
      "process 8200 peaks takes 8.2 s\n",
      "process 8250 peaks takes 8.3 s\n",
      "process 8300 peaks takes 8.4 s\n",
      "process 8350 peaks takes 8.4 s\n",
      "process 8400 peaks takes 8.5 s\n",
      "process 8450 peaks takes 8.5 s\n",
      "process 8500 peaks takes 8.5 s\n",
      "process 8550 peaks takes 8.6 s\n",
      "process 8600 peaks takes 8.6 s\n",
      "process 8650 peaks takes 8.7 s\n",
      "process 8700 peaks takes 8.7 s\n",
      "process 8750 peaks takes 8.8 s\n",
      "process 8800 peaks takes 8.8 s\n",
      "process 8850 peaks takes 8.9 s\n",
      "process 8900 peaks takes 8.9 s\n",
      "process 8950 peaks takes 9.0 s\n",
      "process 9000 peaks takes 9.0 s\n",
      "process 9050 peaks takes 9.1 s\n",
      "process 9100 peaks takes 9.1 s\n",
      "process 9150 peaks takes 9.2 s\n",
      "process 9200 peaks takes 9.2 s\n",
      "process 9250 peaks takes 9.2 s\n",
      "process 9300 peaks takes 9.3 s\n",
      "process 9350 peaks takes 9.3 s\n",
      "process 9400 peaks takes 9.4 s\n",
      "process 9450 peaks takes 9.4 s\n",
      "process 9500 peaks takes 9.5 s\n",
      "process 9550 peaks takes 9.5 s\n",
      "process 9600 peaks takes 9.6 s\n",
      "process 9650 peaks takes 9.6 s\n",
      "process 9700 peaks takes 9.7 s\n",
      "process 9750 peaks takes 9.7 s\n",
      "process 9800 peaks takes 9.7 s\n",
      "process 9850 peaks takes 9.8 s\n",
      "process 9900 peaks takes 9.8 s\n",
      "process 9950 peaks takes 9.9 s\n",
      "process 10000 peaks takes 9.9 s\n",
      "process 10050 peaks takes 10.0 s\n",
      "process 10100 peaks takes 10.0 s\n",
      "process 10150 peaks takes 10.1 s\n",
      "process 10200 peaks takes 10.1 s\n",
      "process 10250 peaks takes 10.2 s\n",
      "process 10300 peaks takes 10.2 s\n",
      "process 10350 peaks takes 10.3 s\n",
      "process 10400 peaks takes 10.3 s\n",
      "process 10450 peaks takes 10.4 s\n",
      "process 10500 peaks takes 10.4 s\n",
      "process 10550 peaks takes 10.5 s\n",
      "process 10600 peaks takes 10.5 s\n",
      "process 10650 peaks takes 10.6 s\n",
      "process 10700 peaks takes 10.6 s\n",
      "process 10750 peaks takes 10.7 s\n",
      "process 10800 peaks takes 10.7 s\n",
      "process 10850 peaks takes 10.8 s\n",
      "process 10900 peaks takes 10.8 s\n",
      "process 10950 peaks takes 10.9 s\n",
      "process 11000 peaks takes 10.9 s\n",
      "process 11050 peaks takes 11.0 s\n",
      "process 11100 peaks takes 11.0 s\n",
      "process 11150 peaks takes 11.1 s\n",
      "process 11200 peaks takes 11.1 s\n",
      "process 11250 peaks takes 11.2 s\n",
      "process 11300 peaks takes 11.2 s\n",
      "process 11350 peaks takes 11.2 s\n",
      "process 11400 peaks takes 11.3 s\n",
      "process 11450 peaks takes 11.4 s\n",
      "process 11500 peaks takes 11.4 s\n",
      "process 11550 peaks takes 11.4 s\n",
      "process 11600 peaks takes 11.5 s\n",
      "process 11650 peaks takes 11.5 s\n",
      "process 11700 peaks takes 11.6 s\n",
      "process 11750 peaks takes 11.6 s\n",
      "process 11800 peaks takes 11.7 s\n",
      "process 11850 peaks takes 11.7 s\n",
      "process 11900 peaks takes 11.8 s\n",
      "process 11950 peaks takes 11.8 s\n",
      "process 12000 peaks takes 11.9 s\n",
      "process 12050 peaks takes 11.9 s\n",
      "process 12100 peaks takes 12.0 s\n",
      "process 12150 peaks takes 12.0 s\n",
      "process 12200 peaks takes 12.1 s\n",
      "process 12250 peaks takes 12.1 s\n",
      "process 12300 peaks takes 12.2 s\n",
      "process 12350 peaks takes 12.2 s\n",
      "process 12400 peaks takes 12.3 s\n",
      "process 12450 peaks takes 12.3 s\n",
      "process 12500 peaks takes 12.3 s\n",
      "process 12550 peaks takes 12.4 s\n",
      "process 12600 peaks takes 12.4 s\n",
      "process 12650 peaks takes 12.5 s\n",
      "process 12700 peaks takes 12.5 s\n",
      "process 12750 peaks takes 12.6 s\n",
      "process 12800 peaks takes 12.6 s\n",
      "process 12850 peaks takes 12.7 s\n",
      "process 12900 peaks takes 12.7 s\n",
      "process 12950 peaks takes 12.8 s\n",
      "process 13000 peaks takes 12.8 s\n",
      "process 13050 peaks takes 12.9 s\n",
      "process 13100 peaks takes 12.9 s\n",
      "process 13150 peaks takes 12.9 s\n",
      "process 13200 peaks takes 13.0 s\n",
      "process 13250 peaks takes 13.0 s\n",
      "process 13300 peaks takes 13.1 s\n",
      "process 13350 peaks takes 13.2 s\n",
      "process 13400 peaks takes 13.2 s\n",
      "process 13450 peaks takes 13.2 s\n",
      "process 13500 peaks takes 13.3 s\n",
      "process 13550 peaks takes 13.3 s\n",
      "process 13600 peaks takes 13.4 s\n",
      "process 13650 peaks takes 13.4 s\n",
      "process 13700 peaks takes 13.5 s\n",
      "process 13750 peaks takes 13.5 s\n",
      "process 13800 peaks takes 13.6 s\n",
      "process 13850 peaks takes 13.6 s\n",
      "process 13900 peaks takes 13.7 s\n",
      "process 13950 peaks takes 13.7 s\n",
      "process 14000 peaks takes 13.8 s\n",
      "process 14050 peaks takes 13.8 s\n",
      "process 14100 peaks takes 13.9 s\n",
      "process 14150 peaks takes 13.9 s\n",
      "process 14200 peaks takes 14.0 s\n",
      "process 14250 peaks takes 14.0 s\n",
      "process 14300 peaks takes 14.1 s\n",
      "process 14350 peaks takes 14.1 s\n",
      "process 14400 peaks takes 14.2 s\n",
      "process 14450 peaks takes 14.2 s\n",
      "process 14500 peaks takes 14.3 s\n",
      "process 14550 peaks takes 14.3 s\n",
      "process 14600 peaks takes 14.3 s\n",
      "process 14650 peaks takes 14.4 s\n",
      "process 14700 peaks takes 14.4 s\n",
      "process 14750 peaks takes 14.5 s\n",
      "process 14800 peaks takes 14.5 s\n",
      "process 14850 peaks takes 14.6 s\n",
      "process 14900 peaks takes 14.6 s\n",
      "process 14950 peaks takes 14.7 s\n",
      "process 15000 peaks takes 14.7 s\n",
      "process 15050 peaks takes 14.8 s\n",
      "process 15100 peaks takes 14.8 s\n",
      "process 15150 peaks takes 14.9 s\n",
      "process 15200 peaks takes 14.9 s\n",
      "process 15250 peaks takes 14.9 s\n",
      "process 15300 peaks takes 15.0 s\n",
      "process 15350 peaks takes 15.1 s\n",
      "process 15400 peaks takes 15.1 s\n",
      "process 15450 peaks takes 15.2 s\n",
      "process 15500 peaks takes 15.2 s\n",
      "process 15550 peaks takes 15.2 s\n",
      "process 15600 peaks takes 15.3 s\n",
      "process 15650 peaks takes 15.3 s\n",
      "process 15700 peaks takes 15.4 s\n",
      "process 15750 peaks takes 15.4 s\n",
      "process 15800 peaks takes 15.5 s\n",
      "process 15850 peaks takes 15.5 s\n",
      "process 15900 peaks takes 15.6 s\n",
      "process 15950 peaks takes 15.6 s\n",
      "process 16000 peaks takes 15.7 s\n",
      "process 16050 peaks takes 15.7 s\n",
      "process 16100 peaks takes 15.8 s\n",
      "process 16150 peaks takes 15.8 s\n",
      "process 16200 peaks takes 15.9 s\n",
      "process 16250 peaks takes 15.9 s\n",
      "process 16300 peaks takes 16.0 s\n",
      "process 16350 peaks takes 16.0 s\n",
      "process 16400 peaks takes 16.1 s\n",
      "process 16450 peaks takes 16.1 s\n",
      "process 16500 peaks takes 16.2 s\n",
      "process 16550 peaks takes 16.3 s\n",
      "process 16600 peaks takes 16.3 s\n",
      "process 16650 peaks takes 16.4 s\n",
      "process 16700 peaks takes 16.4 s\n",
      "process 16750 peaks takes 16.5 s\n",
      "process 16800 peaks takes 16.5 s\n",
      "process 16850 peaks takes 16.6 s\n",
      "process 16900 peaks takes 16.6 s\n",
      "process 16950 peaks takes 16.7 s\n",
      "process 17000 peaks takes 16.7 s\n",
      "process 17050 peaks takes 16.8 s\n",
      "process 17100 peaks takes 16.8 s\n",
      "process 17150 peaks takes 16.9 s\n",
      "process 17200 peaks takes 16.9 s\n",
      "process 17250 peaks takes 17.0 s\n",
      "process 17300 peaks takes 17.0 s\n",
      "process 17350 peaks takes 17.1 s\n",
      "process 17400 peaks takes 17.1 s\n",
      "process 17450 peaks takes 17.2 s\n",
      "process 17500 peaks takes 17.2 s\n",
      "process 17550 peaks takes 17.2 s\n",
      "process 17600 peaks takes 17.3 s\n",
      "process 17650 peaks takes 17.3 s\n",
      "process 17700 peaks takes 17.4 s\n",
      "process 17750 peaks takes 17.4 s\n",
      "process 17800 peaks takes 17.5 s\n",
      "process 17850 peaks takes 17.5 s\n",
      "process 17900 peaks takes 17.6 s\n",
      "process 17950 peaks takes 17.6 s\n",
      "process 18000 peaks takes 17.7 s\n",
      "process 18050 peaks takes 17.7 s\n",
      "process 18100 peaks takes 17.7 s\n",
      "process 18150 peaks takes 17.8 s\n",
      "process 18200 peaks takes 17.8 s\n",
      "process 18250 peaks takes 17.9 s\n",
      "process 18300 peaks takes 17.9 s\n",
      "process 18350 peaks takes 18.0 s\n",
      "process 18400 peaks takes 18.0 s\n",
      "process 18450 peaks takes 18.1 s\n",
      "process 18500 peaks takes 18.1 s\n",
      "process 18550 peaks takes 18.1 s\n",
      "process 18600 peaks takes 18.2 s\n",
      "process 18650 peaks takes 18.3 s\n",
      "process 18700 peaks takes 18.3 s\n",
      "process 18750 peaks takes 18.3 s\n",
      "process 18800 peaks takes 18.4 s\n",
      "process 18850 peaks takes 18.4 s\n",
      "process 18900 peaks takes 18.5 s\n",
      "process 18950 peaks takes 18.5 s\n",
      "process 19000 peaks takes 18.6 s\n",
      "process 19050 peaks takes 18.6 s\n",
      "process 19100 peaks takes 18.7 s\n",
      "process 19150 peaks takes 18.7 s\n",
      "process 19200 peaks takes 18.8 s\n",
      "process 19250 peaks takes 18.8 s\n",
      "process 19300 peaks takes 18.8 s\n",
      "process 19350 peaks takes 18.9 s\n",
      "process 19400 peaks takes 18.9 s\n",
      "process 19450 peaks takes 19.0 s\n",
      "process 19500 peaks takes 19.0 s\n",
      "process 19550 peaks takes 19.1 s\n",
      "process 19600 peaks takes 19.1 s\n",
      "process 19650 peaks takes 19.2 s\n",
      "process 19700 peaks takes 19.2 s\n",
      "process 19750 peaks takes 19.2 s\n",
      "process 19800 peaks takes 19.3 s\n",
      "process 19850 peaks takes 19.3 s\n",
      "process 19900 peaks takes 19.4 s\n",
      "process 19950 peaks takes 19.4 s\n",
      "process 20000 peaks takes 19.5 s\n",
      "process 20050 peaks takes 19.5 s\n",
      "process 20100 peaks takes 19.5 s\n",
      "process 20150 peaks takes 19.6 s\n",
      "process 20200 peaks takes 19.6 s\n",
      "process 20250 peaks takes 19.7 s\n",
      "process 20300 peaks takes 19.7 s\n",
      "process 20350 peaks takes 19.8 s\n",
      "process 20400 peaks takes 19.8 s\n",
      "process 20450 peaks takes 19.9 s\n",
      "process 20500 peaks takes 19.9 s\n",
      "process 20550 peaks takes 19.9 s\n",
      "process 20600 peaks takes 20.0 s\n",
      "process 20650 peaks takes 20.0 s\n",
      "process 20700 peaks takes 20.1 s\n",
      "process 20750 peaks takes 20.1 s\n",
      "process 20800 peaks takes 20.2 s\n",
      "process 20850 peaks takes 20.2 s\n",
      "process 20900 peaks takes 20.2 s\n",
      "process 20950 peaks takes 20.3 s\n",
      "process 21000 peaks takes 20.3 s\n",
      "process 21050 peaks takes 20.4 s\n",
      "process 21100 peaks takes 20.4 s\n",
      "process 21150 peaks takes 20.5 s\n",
      "process 21200 peaks takes 20.5 s\n",
      "process 21250 peaks takes 20.6 s\n",
      "process 21300 peaks takes 20.6 s\n",
      "process 21350 peaks takes 20.6 s\n",
      "process 21400 peaks takes 20.7 s\n",
      "process 21450 peaks takes 20.7 s\n",
      "process 21500 peaks takes 20.8 s\n",
      "process 21550 peaks takes 20.8 s\n",
      "process 21600 peaks takes 20.9 s\n",
      "process 21650 peaks takes 20.9 s\n",
      "process 21700 peaks takes 21.0 s\n",
      "process 21750 peaks takes 21.0 s\n",
      "process 21800 peaks takes 21.1 s\n",
      "process 21850 peaks takes 21.1 s\n",
      "process 21900 peaks takes 21.2 s\n",
      "process 21950 peaks takes 21.2 s\n",
      "process 22000 peaks takes 21.2 s\n",
      "process 22050 peaks takes 21.3 s\n",
      "process 22100 peaks takes 21.3 s\n",
      "process 22150 peaks takes 21.4 s\n",
      "process 22200 peaks takes 21.4 s\n",
      "process 22250 peaks takes 21.5 s\n",
      "process 22300 peaks takes 21.5 s\n",
      "process 22350 peaks takes 21.6 s\n",
      "process 22400 peaks takes 21.6 s\n",
      "process 22450 peaks takes 21.7 s\n",
      "process 22500 peaks takes 21.7 s\n",
      "process 22550 peaks takes 21.8 s\n",
      "process 22600 peaks takes 21.8 s\n",
      "process 22650 peaks takes 21.8 s\n",
      "process 22700 peaks takes 21.9 s\n",
      "process 22750 peaks takes 21.9 s\n",
      "process 22800 peaks takes 22.0 s\n",
      "process 22850 peaks takes 22.0 s\n",
      "process 22900 peaks takes 22.1 s\n",
      "process 22950 peaks takes 22.1 s\n",
      "process 23000 peaks takes 22.2 s\n",
      "process 23050 peaks takes 22.2 s\n",
      "process 23100 peaks takes 22.3 s\n",
      "process 23150 peaks takes 22.3 s\n",
      "process 23200 peaks takes 22.4 s\n",
      "process 23250 peaks takes 22.4 s\n",
      "process 23300 peaks takes 22.4 s\n",
      "process 23350 peaks takes 22.5 s\n",
      "process 23400 peaks takes 22.6 s\n",
      "process 23450 peaks takes 22.6 s\n",
      "process 23500 peaks takes 22.6 s\n",
      "process 23550 peaks takes 22.7 s\n",
      "process 23600 peaks takes 22.7 s\n",
      "process 23650 peaks takes 22.8 s\n",
      "process 23700 peaks takes 22.8 s\n",
      "process 23750 peaks takes 22.9 s\n",
      "process 23800 peaks takes 22.9 s\n",
      "process 23850 peaks takes 23.0 s\n",
      "process 23900 peaks takes 23.0 s\n",
      "process 23950 peaks takes 23.1 s\n",
      "process 24000 peaks takes 23.1 s\n",
      "process 24050 peaks takes 23.2 s\n",
      "process 24100 peaks takes 23.2 s\n",
      "process 24150 peaks takes 23.3 s\n",
      "process 24200 peaks takes 23.3 s\n",
      "process 24250 peaks takes 23.4 s\n",
      "process 24300 peaks takes 23.4 s\n",
      "process 24350 peaks takes 23.4 s\n",
      "process 24400 peaks takes 23.5 s\n",
      "process 24450 peaks takes 23.6 s\n",
      "process 24500 peaks takes 23.6 s\n",
      "process 24550 peaks takes 23.7 s\n",
      "process 24600 peaks takes 23.7 s\n",
      "process 24650 peaks takes 23.8 s\n",
      "process 24700 peaks takes 23.8 s\n",
      "process 24750 peaks takes 23.8 s\n",
      "process 24800 peaks takes 23.9 s\n",
      "process 24850 peaks takes 23.9 s\n",
      "process 24900 peaks takes 24.0 s\n",
      "process 24950 peaks takes 24.0 s\n",
      "process 25000 peaks takes 24.1 s\n",
      "process 25050 peaks takes 24.1 s\n",
      "process 25100 peaks takes 24.2 s\n",
      "process 25150 peaks takes 24.2 s\n",
      "process 25200 peaks takes 24.3 s\n",
      "process 25250 peaks takes 24.3 s\n",
      "process 25300 peaks takes 24.4 s\n",
      "process 25350 peaks takes 24.4 s\n",
      "process 25400 peaks takes 24.4 s\n",
      "process 25450 peaks takes 24.5 s\n",
      "process 25500 peaks takes 24.5 s\n",
      "process 25550 peaks takes 24.6 s\n",
      "process 25600 peaks takes 24.6 s\n",
      "process 25650 peaks takes 24.6 s\n",
      "process 25700 peaks takes 24.7 s\n",
      "process 25750 peaks takes 24.7 s\n",
      "process 25800 peaks takes 24.8 s\n",
      "process 25850 peaks takes 24.8 s\n",
      "process 25900 peaks takes 24.9 s\n",
      "process 25950 peaks takes 24.9 s\n",
      "process 26000 peaks takes 25.0 s\n",
      "process 26050 peaks takes 25.0 s\n",
      "process 26100 peaks takes 25.1 s\n",
      "process 26150 peaks takes 25.1 s\n",
      "process 26200 peaks takes 25.2 s\n",
      "process 26250 peaks takes 25.2 s\n",
      "process 26300 peaks takes 25.2 s\n",
      "process 26350 peaks takes 25.3 s\n",
      "process 26400 peaks takes 25.3 s\n",
      "process 26450 peaks takes 25.4 s\n",
      "process 26500 peaks takes 25.4 s\n",
      "process 26550 peaks takes 25.5 s\n",
      "process 26600 peaks takes 25.5 s\n",
      "process 26650 peaks takes 25.5 s\n",
      "process 26700 peaks takes 25.6 s\n",
      "process 26750 peaks takes 25.6 s\n",
      "process 26800 peaks takes 25.7 s\n",
      "process 26850 peaks takes 25.7 s\n",
      "process 26900 peaks takes 25.7 s\n",
      "process 26950 peaks takes 25.8 s\n",
      "process 27000 peaks takes 25.8 s\n",
      "process 27050 peaks takes 25.9 s\n",
      "process 27100 peaks takes 25.9 s\n",
      "process 27150 peaks takes 26.0 s\n",
      "process 27200 peaks takes 26.0 s\n",
      "process 27250 peaks takes 26.1 s\n",
      "process 27300 peaks takes 26.1 s\n",
      "process 27350 peaks takes 26.1 s\n",
      "process 27400 peaks takes 26.2 s\n",
      "process 27450 peaks takes 26.2 s\n",
      "process 27500 peaks takes 26.3 s\n",
      "process 27550 peaks takes 26.3 s\n",
      "process 27600 peaks takes 26.4 s\n",
      "process 27650 peaks takes 26.4 s\n",
      "process 27700 peaks takes 26.4 s\n",
      "process 27750 peaks takes 26.5 s\n",
      "process 27800 peaks takes 26.5 s\n",
      "process 27850 peaks takes 26.6 s\n",
      "process 27900 peaks takes 26.6 s\n",
      "process 27950 peaks takes 26.7 s\n",
      "process 28000 peaks takes 26.7 s\n",
      "process 28050 peaks takes 26.8 s\n",
      "process 28100 peaks takes 26.8 s\n",
      "process 28150 peaks takes 26.9 s\n",
      "process 28200 peaks takes 26.9 s\n",
      "process 28250 peaks takes 27.0 s\n",
      "process 28300 peaks takes 27.0 s\n",
      "process 28350 peaks takes 27.0 s\n",
      "process 28400 peaks takes 27.1 s\n",
      "process 28450 peaks takes 27.1 s\n",
      "process 28500 peaks takes 27.2 s\n",
      "process 28550 peaks takes 27.2 s\n",
      "process 28600 peaks takes 27.3 s\n",
      "process 28650 peaks takes 27.3 s\n",
      "process 28700 peaks takes 27.4 s\n",
      "process 28750 peaks takes 27.4 s\n",
      "process 28800 peaks takes 27.4 s\n",
      "process 28850 peaks takes 27.5 s\n",
      "process 28900 peaks takes 27.5 s\n",
      "process 28950 peaks takes 27.6 s\n",
      "process 29000 peaks takes 27.6 s\n",
      "process 29050 peaks takes 27.7 s\n",
      "process 29100 peaks takes 27.7 s\n",
      "process 29150 peaks takes 27.7 s\n",
      "process 29200 peaks takes 27.8 s\n",
      "process 29250 peaks takes 27.8 s\n",
      "process 29300 peaks takes 27.9 s\n",
      "process 29350 peaks takes 27.9 s\n",
      "process 29400 peaks takes 28.0 s\n",
      "process 29450 peaks takes 28.0 s\n",
      "process 29500 peaks takes 28.1 s\n",
      "process 29550 peaks takes 28.1 s\n",
      "process 29600 peaks takes 28.2 s\n",
      "process 29650 peaks takes 28.2 s\n",
      "process 29700 peaks takes 28.3 s\n",
      "process 29750 peaks takes 28.3 s\n",
      "process 29800 peaks takes 28.4 s\n",
      "process 29850 peaks takes 28.4 s\n",
      "process 29900 peaks takes 28.5 s\n",
      "process 29950 peaks takes 28.5 s\n",
      "\n",
      "train\n",
      "27001 540\n",
      "process 0 peaks takes 0.5 s\n",
      "process 50 peaks takes 0.6 s\n",
      "process 100 peaks takes 0.6 s\n",
      "process 150 peaks takes 0.7 s\n",
      "process 200 peaks takes 0.7 s\n",
      "process 250 peaks takes 0.7 s\n",
      "process 300 peaks takes 0.8 s\n",
      "process 350 peaks takes 0.8 s\n",
      "process 400 peaks takes 0.9 s\n",
      "process 450 peaks takes 0.9 s\n",
      "process 500 peaks takes 1.0 s\n",
      "process 550 peaks takes 1.0 s\n",
      "process 600 peaks takes 1.0 s\n",
      "process 650 peaks takes 1.1 s\n",
      "process 700 peaks takes 1.1 s\n",
      "process 750 peaks takes 1.2 s\n",
      "process 800 peaks takes 1.2 s\n",
      "process 850 peaks takes 1.3 s\n",
      "process 900 peaks takes 1.3 s\n",
      "process 950 peaks takes 1.4 s\n",
      "process 1000 peaks takes 1.4 s\n",
      "process 1050 peaks takes 1.5 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.6 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.7 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "process 1450 peaks takes 1.8 s\n",
      "process 1500 peaks takes 1.9 s\n",
      "process 1550 peaks takes 1.9 s\n",
      "process 1600 peaks takes 1.9 s\n",
      "process 1650 peaks takes 2.0 s\n",
      "process 1700 peaks takes 2.0 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.1 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.2 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.3 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.4 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.5 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.6 s\n",
      "process 2400 peaks takes 2.7 s\n",
      "process 2450 peaks takes 2.7 s\n",
      "process 2500 peaks takes 2.8 s\n",
      "process 2550 peaks takes 2.8 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 2.9 s\n",
      "process 2750 peaks takes 3.0 s\n",
      "process 2800 peaks takes 3.0 s\n",
      "process 2850 peaks takes 3.0 s\n",
      "process 2900 peaks takes 3.1 s\n",
      "process 2950 peaks takes 3.1 s\n",
      "process 3000 peaks takes 3.2 s\n",
      "process 3050 peaks takes 3.2 s\n",
      "process 3100 peaks takes 3.3 s\n",
      "process 3150 peaks takes 3.3 s\n",
      "process 3200 peaks takes 3.4 s\n",
      "process 3250 peaks takes 3.4 s\n",
      "process 3300 peaks takes 3.5 s\n",
      "process 3350 peaks takes 3.5 s\n",
      "process 3400 peaks takes 3.5 s\n",
      "process 3450 peaks takes 3.6 s\n",
      "process 3500 peaks takes 3.6 s\n",
      "process 3550 peaks takes 3.7 s\n",
      "process 3600 peaks takes 3.7 s\n",
      "process 3650 peaks takes 3.8 s\n",
      "process 3700 peaks takes 3.8 s\n",
      "process 3750 peaks takes 3.9 s\n",
      "process 3800 peaks takes 3.9 s\n",
      "process 3850 peaks takes 3.9 s\n",
      "process 3900 peaks takes 4.0 s\n",
      "process 3950 peaks takes 4.0 s\n",
      "process 4000 peaks takes 4.1 s\n",
      "process 4050 peaks takes 4.1 s\n",
      "process 4100 peaks takes 4.2 s\n",
      "process 4150 peaks takes 4.2 s\n",
      "process 4200 peaks takes 4.3 s\n",
      "process 4250 peaks takes 4.3 s\n",
      "process 4300 peaks takes 4.4 s\n",
      "process 4350 peaks takes 4.4 s\n",
      "process 4400 peaks takes 4.5 s\n",
      "process 4450 peaks takes 4.5 s\n",
      "process 4500 peaks takes 4.5 s\n",
      "process 4550 peaks takes 4.6 s\n",
      "process 4600 peaks takes 4.6 s\n",
      "process 4650 peaks takes 4.7 s\n",
      "process 4700 peaks takes 4.7 s\n",
      "process 4750 peaks takes 4.8 s\n",
      "process 4800 peaks takes 4.8 s\n",
      "process 4850 peaks takes 4.9 s\n",
      "process 4900 peaks takes 4.9 s\n",
      "process 4950 peaks takes 4.9 s\n",
      "process 5000 peaks takes 5.0 s\n",
      "process 5050 peaks takes 5.0 s\n",
      "process 5100 peaks takes 5.1 s\n",
      "process 5150 peaks takes 5.1 s\n",
      "process 5200 peaks takes 5.2 s\n",
      "process 5250 peaks takes 5.2 s\n",
      "process 5300 peaks takes 5.3 s\n",
      "process 5350 peaks takes 5.3 s\n",
      "process 5400 peaks takes 5.3 s\n",
      "process 5450 peaks takes 5.4 s\n",
      "process 5500 peaks takes 5.4 s\n",
      "process 5550 peaks takes 5.5 s\n",
      "process 5600 peaks takes 5.5 s\n",
      "process 5650 peaks takes 5.6 s\n",
      "process 5700 peaks takes 5.6 s\n",
      "process 5750 peaks takes 5.7 s\n",
      "process 5800 peaks takes 5.7 s\n",
      "process 5850 peaks takes 5.7 s\n",
      "process 5900 peaks takes 5.8 s\n",
      "process 5950 peaks takes 5.8 s\n",
      "process 6000 peaks takes 5.9 s\n",
      "process 6050 peaks takes 5.9 s\n",
      "process 6100 peaks takes 6.0 s\n",
      "process 6150 peaks takes 6.0 s\n",
      "process 6200 peaks takes 6.1 s\n",
      "process 6250 peaks takes 6.1 s\n",
      "process 6300 peaks takes 6.1 s\n",
      "process 6350 peaks takes 6.2 s\n",
      "process 6400 peaks takes 6.2 s\n",
      "process 6450 peaks takes 6.3 s\n",
      "process 6500 peaks takes 6.3 s\n",
      "process 6550 peaks takes 6.4 s\n",
      "process 6600 peaks takes 6.4 s\n",
      "process 6650 peaks takes 6.5 s\n",
      "process 6700 peaks takes 6.5 s\n",
      "process 6750 peaks takes 6.5 s\n",
      "process 6800 peaks takes 6.6 s\n",
      "process 6850 peaks takes 6.6 s\n",
      "process 6900 peaks takes 6.7 s\n",
      "process 6950 peaks takes 6.7 s\n",
      "process 7000 peaks takes 6.8 s\n",
      "process 7050 peaks takes 6.8 s\n",
      "process 7100 peaks takes 6.8 s\n",
      "process 7150 peaks takes 6.9 s\n",
      "process 7200 peaks takes 6.9 s\n",
      "process 7250 peaks takes 7.0 s\n",
      "process 7300 peaks takes 7.0 s\n",
      "process 7350 peaks takes 7.1 s\n",
      "process 7400 peaks takes 7.1 s\n",
      "process 7450 peaks takes 7.1 s\n",
      "process 7500 peaks takes 7.2 s\n",
      "process 7550 peaks takes 7.2 s\n",
      "process 7600 peaks takes 7.3 s\n",
      "process 7650 peaks takes 7.3 s\n",
      "process 7700 peaks takes 7.4 s\n",
      "process 7750 peaks takes 7.4 s\n",
      "process 7800 peaks takes 7.5 s\n",
      "process 7850 peaks takes 7.5 s\n",
      "process 7900 peaks takes 7.6 s\n",
      "process 7950 peaks takes 7.6 s\n",
      "process 8000 peaks takes 7.6 s\n",
      "process 8050 peaks takes 7.7 s\n",
      "process 8100 peaks takes 7.7 s\n",
      "process 8150 peaks takes 7.8 s\n",
      "process 8200 peaks takes 7.8 s\n",
      "process 8250 peaks takes 7.8 s\n",
      "process 8300 peaks takes 7.9 s\n",
      "process 8350 peaks takes 7.9 s\n",
      "process 8400 peaks takes 8.0 s\n",
      "process 8450 peaks takes 8.0 s\n",
      "process 8500 peaks takes 8.1 s\n",
      "process 8550 peaks takes 8.1 s\n",
      "process 8600 peaks takes 8.1 s\n",
      "process 8650 peaks takes 8.2 s\n",
      "process 8700 peaks takes 8.2 s\n",
      "process 8750 peaks takes 8.3 s\n",
      "process 8800 peaks takes 8.3 s\n",
      "process 8850 peaks takes 8.4 s\n",
      "process 8900 peaks takes 8.4 s\n",
      "process 8950 peaks takes 8.5 s\n",
      "process 9000 peaks takes 8.5 s\n",
      "process 9050 peaks takes 8.5 s\n",
      "process 9100 peaks takes 8.6 s\n",
      "process 9150 peaks takes 8.6 s\n",
      "process 9200 peaks takes 8.7 s\n",
      "process 9250 peaks takes 8.7 s\n",
      "process 9300 peaks takes 8.8 s\n",
      "process 9350 peaks takes 8.8 s\n",
      "process 9400 peaks takes 8.8 s\n",
      "process 9450 peaks takes 8.9 s\n",
      "process 9500 peaks takes 8.9 s\n",
      "process 9550 peaks takes 9.0 s\n",
      "process 9600 peaks takes 9.0 s\n",
      "process 9650 peaks takes 9.1 s\n",
      "process 9700 peaks takes 9.1 s\n",
      "process 9750 peaks takes 9.2 s\n",
      "process 9800 peaks takes 9.2 s\n",
      "process 9850 peaks takes 9.3 s\n",
      "process 9900 peaks takes 9.3 s\n",
      "process 9950 peaks takes 9.3 s\n",
      "process 10000 peaks takes 9.4 s\n",
      "process 10050 peaks takes 9.4 s\n",
      "process 10100 peaks takes 9.5 s\n",
      "process 10150 peaks takes 9.5 s\n",
      "process 10200 peaks takes 9.6 s\n",
      "process 10250 peaks takes 9.6 s\n",
      "process 10300 peaks takes 9.7 s\n",
      "process 10350 peaks takes 9.7 s\n",
      "process 10400 peaks takes 9.8 s\n",
      "process 10450 peaks takes 9.8 s\n",
      "process 10500 peaks takes 9.8 s\n",
      "process 10550 peaks takes 9.9 s\n",
      "process 10600 peaks takes 9.9 s\n",
      "process 10650 peaks takes 10.0 s\n",
      "process 10700 peaks takes 10.0 s\n",
      "process 10750 peaks takes 10.1 s\n",
      "process 10800 peaks takes 10.1 s\n",
      "process 10850 peaks takes 10.1 s\n",
      "process 10900 peaks takes 10.2 s\n",
      "process 10950 peaks takes 10.2 s\n",
      "process 11000 peaks takes 10.3 s\n",
      "process 11050 peaks takes 10.3 s\n",
      "process 11100 peaks takes 10.4 s\n",
      "process 11150 peaks takes 10.4 s\n",
      "process 11200 peaks takes 10.5 s\n",
      "process 11250 peaks takes 10.5 s\n",
      "process 11300 peaks takes 10.6 s\n",
      "process 11350 peaks takes 10.6 s\n",
      "process 11400 peaks takes 10.6 s\n",
      "process 11450 peaks takes 10.7 s\n",
      "process 11500 peaks takes 10.7 s\n",
      "process 11550 peaks takes 10.8 s\n",
      "process 11600 peaks takes 10.8 s\n",
      "process 11650 peaks takes 10.8 s\n",
      "process 11700 peaks takes 10.9 s\n",
      "process 11750 peaks takes 10.9 s\n",
      "process 11800 peaks takes 11.0 s\n",
      "process 11850 peaks takes 11.0 s\n",
      "process 11900 peaks takes 11.1 s\n",
      "process 11950 peaks takes 11.1 s\n",
      "process 12000 peaks takes 11.2 s\n",
      "process 12050 peaks takes 11.2 s\n",
      "process 12100 peaks takes 11.3 s\n",
      "process 12150 peaks takes 11.3 s\n",
      "process 12200 peaks takes 11.4 s\n",
      "process 12250 peaks takes 11.4 s\n",
      "process 12300 peaks takes 11.5 s\n",
      "process 12350 peaks takes 11.5 s\n",
      "process 12400 peaks takes 11.6 s\n",
      "process 12450 peaks takes 11.6 s\n",
      "process 12500 peaks takes 11.6 s\n",
      "process 12550 peaks takes 11.7 s\n",
      "process 12600 peaks takes 11.7 s\n",
      "process 12650 peaks takes 11.8 s\n",
      "process 12700 peaks takes 11.8 s\n",
      "process 12750 peaks takes 11.9 s\n",
      "process 12800 peaks takes 11.9 s\n",
      "process 12850 peaks takes 11.9 s\n",
      "process 12900 peaks takes 12.0 s\n",
      "process 12950 peaks takes 12.0 s\n",
      "process 13000 peaks takes 12.1 s\n",
      "process 13050 peaks takes 12.1 s\n",
      "process 13100 peaks takes 12.1 s\n",
      "process 13150 peaks takes 12.2 s\n",
      "process 13200 peaks takes 12.2 s\n",
      "process 13250 peaks takes 12.3 s\n",
      "process 13300 peaks takes 12.3 s\n",
      "process 13350 peaks takes 12.4 s\n",
      "process 13400 peaks takes 12.4 s\n",
      "process 13450 peaks takes 12.5 s\n",
      "process 13500 peaks takes 12.5 s\n",
      "process 13550 peaks takes 12.5 s\n",
      "process 13600 peaks takes 12.6 s\n",
      "process 13650 peaks takes 12.6 s\n",
      "process 13700 peaks takes 12.7 s\n",
      "process 13750 peaks takes 12.7 s\n",
      "process 13800 peaks takes 12.7 s\n",
      "process 13850 peaks takes 12.8 s\n",
      "process 13900 peaks takes 12.8 s\n",
      "process 13950 peaks takes 12.9 s\n",
      "process 14000 peaks takes 12.9 s\n",
      "process 14050 peaks takes 13.0 s\n",
      "process 14100 peaks takes 13.0 s\n",
      "process 14150 peaks takes 13.0 s\n",
      "process 14200 peaks takes 13.1 s\n",
      "process 14250 peaks takes 13.1 s\n",
      "process 14300 peaks takes 13.2 s\n",
      "process 14350 peaks takes 13.2 s\n",
      "process 14400 peaks takes 13.3 s\n",
      "process 14450 peaks takes 13.3 s\n",
      "process 14500 peaks takes 13.3 s\n",
      "process 14550 peaks takes 13.4 s\n",
      "process 14600 peaks takes 13.4 s\n",
      "process 14650 peaks takes 13.5 s\n",
      "process 14700 peaks takes 13.5 s\n",
      "process 14750 peaks takes 13.6 s\n",
      "process 14800 peaks takes 13.6 s\n",
      "process 14850 peaks takes 13.6 s\n",
      "process 14900 peaks takes 13.7 s\n",
      "process 14950 peaks takes 13.7 s\n",
      "process 15000 peaks takes 13.8 s\n",
      "process 15050 peaks takes 13.8 s\n",
      "process 15100 peaks takes 13.9 s\n",
      "process 15150 peaks takes 13.9 s\n",
      "process 15200 peaks takes 13.9 s\n",
      "process 15250 peaks takes 14.0 s\n",
      "process 15300 peaks takes 14.0 s\n",
      "process 15350 peaks takes 14.1 s\n",
      "process 15400 peaks takes 14.1 s\n",
      "process 15450 peaks takes 14.1 s\n",
      "process 15500 peaks takes 14.2 s\n",
      "process 15550 peaks takes 14.2 s\n",
      "process 15600 peaks takes 14.3 s\n",
      "process 15650 peaks takes 14.3 s\n",
      "process 15700 peaks takes 14.4 s\n",
      "process 15750 peaks takes 14.4 s\n",
      "process 15800 peaks takes 14.5 s\n",
      "process 15850 peaks takes 14.5 s\n",
      "process 15900 peaks takes 14.6 s\n",
      "process 15950 peaks takes 14.6 s\n",
      "process 16000 peaks takes 14.6 s\n",
      "process 16050 peaks takes 14.7 s\n",
      "process 16100 peaks takes 14.7 s\n",
      "process 16150 peaks takes 14.8 s\n",
      "process 16200 peaks takes 14.8 s\n",
      "process 16250 peaks takes 14.8 s\n",
      "process 16300 peaks takes 14.9 s\n",
      "process 16350 peaks takes 14.9 s\n",
      "process 16400 peaks takes 15.0 s\n",
      "process 16450 peaks takes 15.0 s\n",
      "process 16500 peaks takes 15.1 s\n",
      "process 16550 peaks takes 15.1 s\n",
      "process 16600 peaks takes 15.1 s\n",
      "process 16650 peaks takes 15.2 s\n",
      "process 16700 peaks takes 15.2 s\n",
      "process 16750 peaks takes 15.3 s\n",
      "process 16800 peaks takes 15.3 s\n",
      "process 16850 peaks takes 15.4 s\n",
      "process 16900 peaks takes 15.4 s\n",
      "process 16950 peaks takes 15.5 s\n",
      "process 17000 peaks takes 15.5 s\n",
      "process 17050 peaks takes 15.5 s\n",
      "process 17100 peaks takes 15.6 s\n",
      "process 17150 peaks takes 15.6 s\n",
      "process 17200 peaks takes 15.7 s\n",
      "process 17250 peaks takes 15.7 s\n",
      "process 17300 peaks takes 15.8 s\n",
      "process 17350 peaks takes 15.8 s\n",
      "process 17400 peaks takes 15.8 s\n",
      "process 17450 peaks takes 15.9 s\n",
      "process 17500 peaks takes 15.9 s\n",
      "process 17550 peaks takes 16.0 s\n",
      "process 17600 peaks takes 16.0 s\n",
      "process 17650 peaks takes 16.1 s\n",
      "process 17700 peaks takes 16.1 s\n",
      "process 17750 peaks takes 16.2 s\n",
      "process 17800 peaks takes 16.2 s\n",
      "process 17850 peaks takes 16.2 s\n",
      "process 17900 peaks takes 16.3 s\n",
      "process 17950 peaks takes 16.3 s\n",
      "process 18000 peaks takes 16.4 s\n",
      "process 18050 peaks takes 16.4 s\n",
      "process 18100 peaks takes 16.5 s\n",
      "process 18150 peaks takes 16.5 s\n",
      "process 18200 peaks takes 16.6 s\n",
      "process 18250 peaks takes 16.6 s\n",
      "process 18300 peaks takes 16.7 s\n",
      "process 18350 peaks takes 16.7 s\n",
      "process 18400 peaks takes 16.7 s\n",
      "process 18450 peaks takes 16.8 s\n",
      "process 18500 peaks takes 16.8 s\n",
      "process 18550 peaks takes 16.9 s\n",
      "process 18600 peaks takes 16.9 s\n",
      "process 18650 peaks takes 16.9 s\n",
      "process 18700 peaks takes 17.0 s\n",
      "process 18750 peaks takes 17.0 s\n",
      "process 18800 peaks takes 17.1 s\n",
      "process 18850 peaks takes 17.1 s\n",
      "process 18900 peaks takes 17.2 s\n",
      "process 18950 peaks takes 17.2 s\n",
      "process 19000 peaks takes 17.2 s\n",
      "process 19050 peaks takes 17.3 s\n",
      "process 19100 peaks takes 17.3 s\n",
      "process 19150 peaks takes 17.4 s\n",
      "process 19200 peaks takes 17.4 s\n",
      "process 19250 peaks takes 17.5 s\n",
      "process 19300 peaks takes 17.5 s\n",
      "process 19350 peaks takes 17.6 s\n",
      "process 19400 peaks takes 17.6 s\n",
      "process 19450 peaks takes 17.6 s\n",
      "process 19500 peaks takes 17.7 s\n",
      "process 19550 peaks takes 17.7 s\n",
      "process 19600 peaks takes 17.8 s\n",
      "process 19650 peaks takes 17.8 s\n",
      "process 19700 peaks takes 17.8 s\n",
      "process 19750 peaks takes 17.9 s\n",
      "process 19800 peaks takes 17.9 s\n",
      "process 19850 peaks takes 18.0 s\n",
      "process 19900 peaks takes 18.0 s\n",
      "process 19950 peaks takes 18.1 s\n",
      "process 20000 peaks takes 18.1 s\n",
      "process 20050 peaks takes 18.2 s\n",
      "process 20100 peaks takes 18.2 s\n",
      "process 20150 peaks takes 18.2 s\n",
      "process 20200 peaks takes 18.3 s\n",
      "process 20250 peaks takes 18.3 s\n",
      "process 20300 peaks takes 18.4 s\n",
      "process 20350 peaks takes 18.4 s\n",
      "process 20400 peaks takes 18.4 s\n",
      "process 20450 peaks takes 18.5 s\n",
      "process 20500 peaks takes 18.6 s\n",
      "process 20550 peaks takes 18.6 s\n",
      "process 20600 peaks takes 18.6 s\n",
      "process 20650 peaks takes 18.7 s\n",
      "process 20700 peaks takes 18.7 s\n",
      "process 20750 peaks takes 18.8 s\n",
      "process 20800 peaks takes 18.8 s\n",
      "process 20850 peaks takes 18.9 s\n",
      "process 20900 peaks takes 18.9 s\n",
      "process 20950 peaks takes 18.9 s\n",
      "process 21000 peaks takes 19.0 s\n",
      "process 21050 peaks takes 19.0 s\n",
      "process 21100 peaks takes 19.1 s\n",
      "process 21150 peaks takes 19.1 s\n",
      "process 21200 peaks takes 19.2 s\n",
      "process 21250 peaks takes 19.2 s\n",
      "process 21300 peaks takes 19.2 s\n",
      "process 21350 peaks takes 19.3 s\n",
      "process 21400 peaks takes 19.3 s\n",
      "process 21450 peaks takes 19.4 s\n",
      "process 21500 peaks takes 19.4 s\n",
      "process 21550 peaks takes 19.5 s\n",
      "process 21600 peaks takes 19.5 s\n",
      "process 21650 peaks takes 19.6 s\n",
      "process 21700 peaks takes 19.6 s\n",
      "process 21750 peaks takes 19.7 s\n",
      "process 21800 peaks takes 19.7 s\n",
      "process 21850 peaks takes 19.7 s\n",
      "process 21900 peaks takes 19.8 s\n",
      "process 21950 peaks takes 19.8 s\n",
      "process 22000 peaks takes 19.9 s\n",
      "process 22050 peaks takes 19.9 s\n",
      "process 22100 peaks takes 20.0 s\n",
      "process 22150 peaks takes 20.0 s\n",
      "process 22200 peaks takes 20.1 s\n",
      "process 22250 peaks takes 20.1 s\n",
      "process 22300 peaks takes 20.1 s\n",
      "process 22350 peaks takes 20.2 s\n",
      "process 22400 peaks takes 20.2 s\n",
      "process 22450 peaks takes 20.3 s\n",
      "process 22500 peaks takes 20.3 s\n",
      "process 22550 peaks takes 20.3 s\n",
      "process 22600 peaks takes 20.4 s\n",
      "process 22650 peaks takes 20.4 s\n",
      "process 22700 peaks takes 20.5 s\n",
      "process 22750 peaks takes 20.6 s\n",
      "process 22800 peaks takes 20.6 s\n",
      "process 22850 peaks takes 20.7 s\n",
      "process 22900 peaks takes 20.7 s\n",
      "process 22950 peaks takes 20.7 s\n",
      "process 23000 peaks takes 20.8 s\n",
      "process 23050 peaks takes 20.8 s\n",
      "process 23100 peaks takes 20.9 s\n",
      "process 23150 peaks takes 20.9 s\n",
      "process 23200 peaks takes 20.9 s\n",
      "process 23250 peaks takes 21.0 s\n",
      "process 23300 peaks takes 21.0 s\n",
      "process 23350 peaks takes 21.1 s\n",
      "process 23400 peaks takes 21.1 s\n",
      "process 23450 peaks takes 21.2 s\n",
      "process 23500 peaks takes 21.2 s\n",
      "process 23550 peaks takes 21.2 s\n",
      "process 23600 peaks takes 21.3 s\n",
      "process 23650 peaks takes 21.3 s\n",
      "process 23700 peaks takes 21.4 s\n",
      "process 23750 peaks takes 21.4 s\n",
      "process 23800 peaks takes 21.4 s\n",
      "process 23850 peaks takes 21.5 s\n",
      "process 23900 peaks takes 21.5 s\n",
      "process 23950 peaks takes 21.6 s\n",
      "process 24000 peaks takes 21.6 s\n",
      "process 24050 peaks takes 21.7 s\n",
      "process 24100 peaks takes 21.7 s\n",
      "process 24150 peaks takes 21.7 s\n",
      "process 24200 peaks takes 21.8 s\n",
      "process 24250 peaks takes 21.8 s\n",
      "process 24300 peaks takes 21.9 s\n",
      "process 24350 peaks takes 21.9 s\n",
      "process 24400 peaks takes 22.0 s\n",
      "process 24450 peaks takes 22.0 s\n",
      "process 24500 peaks takes 22.1 s\n",
      "process 24550 peaks takes 22.1 s\n",
      "process 24600 peaks takes 22.1 s\n",
      "process 24650 peaks takes 22.2 s\n",
      "process 24700 peaks takes 22.2 s\n",
      "process 24750 peaks takes 22.3 s\n",
      "process 24800 peaks takes 22.3 s\n",
      "process 24850 peaks takes 22.4 s\n",
      "process 24900 peaks takes 22.4 s\n",
      "process 24950 peaks takes 22.5 s\n",
      "process 25000 peaks takes 22.5 s\n",
      "process 25050 peaks takes 22.6 s\n",
      "process 25100 peaks takes 22.6 s\n",
      "process 25150 peaks takes 22.7 s\n",
      "process 25200 peaks takes 22.7 s\n",
      "process 25250 peaks takes 22.8 s\n",
      "process 25300 peaks takes 22.8 s\n",
      "process 25350 peaks takes 22.8 s\n",
      "process 25400 peaks takes 22.9 s\n",
      "process 25450 peaks takes 22.9 s\n",
      "process 25500 peaks takes 23.0 s\n",
      "process 25550 peaks takes 23.0 s\n",
      "process 25600 peaks takes 23.1 s\n",
      "process 25650 peaks takes 23.1 s\n",
      "process 25700 peaks takes 23.1 s\n",
      "process 25750 peaks takes 23.2 s\n",
      "process 25800 peaks takes 23.2 s\n",
      "process 25850 peaks takes 23.3 s\n",
      "process 25900 peaks takes 23.3 s\n",
      "process 25950 peaks takes 23.4 s\n",
      "process 26000 peaks takes 23.4 s\n",
      "process 26050 peaks takes 23.5 s\n",
      "process 26100 peaks takes 23.5 s\n",
      "process 26150 peaks takes 23.5 s\n",
      "process 26200 peaks takes 23.6 s\n",
      "process 26250 peaks takes 23.6 s\n",
      "process 26300 peaks takes 23.7 s\n",
      "process 26350 peaks takes 23.7 s\n",
      "process 26400 peaks takes 23.7 s\n",
      "process 26450 peaks takes 23.8 s\n",
      "process 26500 peaks takes 23.8 s\n",
      "process 26550 peaks takes 23.9 s\n",
      "process 26600 peaks takes 23.9 s\n",
      "process 26650 peaks takes 24.0 s\n",
      "process 26700 peaks takes 24.0 s\n",
      "process 26750 peaks takes 24.1 s\n",
      "process 26800 peaks takes 24.1 s\n",
      "process 26850 peaks takes 24.2 s\n",
      "process 26900 peaks takes 24.2 s\n",
      "process 26950 peaks takes 24.2 s\n",
      "\n",
      "test\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "\n",
      "val\n",
      "1499 29\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.5 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.6 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.7 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.9 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.2 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.3 s\n",
      "process 1000 peaks takes 1.3 s\n",
      "process 1050 peaks takes 1.4 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.6 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.7 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs10000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs10000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:14:51.434416: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:14:51.532358: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:14:51.535234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:51.535262: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:14:52.059907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:52.059979: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:52.059985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.8GB.\n",
      "2024-05-13 07:14:54.791390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:14:54.791502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791793: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:14:54.791852: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:14:54.792175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 10000)     330000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 10000)    0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10000)        0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,849,810\n",
      "Trainable params: 4,843,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "211/211 [==============================] - 367s 2s/step - loss: 0.2307 - auc: 0.6989 - auc_1: 0.1309 - val_loss: 0.1889 - val_auc: 0.7668 - val_auc_1: 0.2589\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs10000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs1000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "(1000, 3000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000 --batch 50\n",
      "2024-05-13 07:21:05.061144: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:21:05.161401: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:21:05.164328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:05.164359: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:21:05.634017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:05.634096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:05.634113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[2701, 150, 149]\n",
      "3000 60\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 2.0 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.1 s\n",
      "process 1900 peaks takes 2.2 s\n",
      "process 1950 peaks takes 2.2 s\n",
      "process 2000 peaks takes 2.3 s\n",
      "process 2050 peaks takes 2.3 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.6 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.7 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.9 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 3.0 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "process 2700 peaks takes 3.1 s\n",
      "process 2750 peaks takes 3.1 s\n",
      "process 2800 peaks takes 3.2 s\n",
      "process 2850 peaks takes 3.2 s\n",
      "process 2900 peaks takes 3.3 s\n",
      "process 2950 peaks takes 3.4 s\n",
      "\n",
      "train\n",
      "2701 54\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.3 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.4 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.5 s\n",
      "process 2400 peaks takes 2.5 s\n",
      "process 2450 peaks takes 2.6 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.7 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.8 s\n",
      "\n",
      "test\n",
      "150 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "149 2\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs1000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:21:14.364723: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:21:14.518183: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:21:14.522431: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:14.522493: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:21:15.265774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:15.265902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:15.265912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:21:17.556656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:21:17.556782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.556856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.556899: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.556946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.556990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.557047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.557090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.557132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:21:17.557150: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:21:17.557506: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "22/22 [==============================] - 49s 2s/step - loss: 0.3513 - auc: 0.6121 - auc_1: 0.0783 - val_loss: 0.4098 - val_auc: 0.5016 - val_auc_1: 0.0629\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs1000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000\n",
      "out True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs1000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000/train_seqs.h5\n",
      "skip prepare (already done...)\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs1000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs1000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:22:08.475052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:22:08.585691: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:22:08.588558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:08.588586: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:22:09.090738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:09.090842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:09.090858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:22:10.702564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:22:10.702735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.702816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.702862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.702906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.702953: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.702998: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.703042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.703086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:22:10.703105: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:22:10.703454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "22/22 [==============================] - 48s 2s/step - loss: 0.4689 - auc: 0.6080 - auc_1: 0.0777 - val_loss: 0.3073 - val_auc: 0.7182 - val_auc_1: 0.1182\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs1000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "pancreatic_endocrinogenesis episcanpy /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs500_e1/poisson\n",
      "mm10\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "(500, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500 --batch 50\n",
      "2024-05-13 07:23:01.821979: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:23:01.916354: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:23:01.919409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:01.919440: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:23:02.404647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:02.404718: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:02.404725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "\n",
      "train\n",
      "1351 27\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "\n",
      "test\n",
      "75 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "val\n",
      "74 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs500_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:23:07.438148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:23:07.546082: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:23:07.549611: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:07.549646: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:23:08.038605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:08.038670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:08.038690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 07:23:09.589025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:23:09.589877: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590369: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:09.590589: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:23:09.590946: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.3841 - auc: 0.2658 - auc_1: 0.0014 - val_loss: 0.1941 - val_auc: 0.0221 - val_auc_1: 6.9483e-04\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs500_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs500_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "(500, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500 --batch 50\n",
      "2024-05-13 07:23:44.478274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:23:44.577911: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:23:44.580652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:44.580677: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:23:45.075675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:45.075750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:45.075756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "\n",
      "train\n",
      "1351 27\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "\n",
      "test\n",
      "75 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "val\n",
      "74 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs500 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs500_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:23:50.039188: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:23:50.138263: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:23:50.141622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:50.141666: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:23:50.634726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:50.634796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:50.634819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 07:23:52.127604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:23:52.127732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.127800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.127851: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.127893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.127937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.127998: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.128041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.128090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:23:52.128108: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:23:52.128482: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.6104 - auc: 0.2745 - auc_1: 0.0015 - val_loss: 2.0139 - val_auc: 0.0235 - val_auc_1: 8.0521e-04\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs500_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "pancreatic_endocrinogenesis episcanpy /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs2000_e1/poisson\n",
      "mm10\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 07:24:27.240226: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:24:27.351871: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:24:27.355311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:27.355353: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:24:27.837533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:27.837622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:27.837629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.1 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.2 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.3 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.4 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.5 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.6 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.7 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.8 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.9 s\n",
      "process 2850 peaks takes 3.0 s\n",
      "process 2900 peaks takes 3.0 s\n",
      "process 2950 peaks takes 3.0 s\n",
      "process 3000 peaks takes 3.1 s\n",
      "process 3050 peaks takes 3.1 s\n",
      "process 3100 peaks takes 3.2 s\n",
      "process 3150 peaks takes 3.2 s\n",
      "process 3200 peaks takes 3.3 s\n",
      "process 3250 peaks takes 3.3 s\n",
      "process 3300 peaks takes 3.4 s\n",
      "process 3350 peaks takes 3.4 s\n",
      "process 3400 peaks takes 3.5 s\n",
      "process 3450 peaks takes 3.6 s\n",
      "process 3500 peaks takes 3.6 s\n",
      "process 3550 peaks takes 3.7 s\n",
      "process 3600 peaks takes 3.7 s\n",
      "process 3650 peaks takes 3.8 s\n",
      "process 3700 peaks takes 3.8 s\n",
      "process 3750 peaks takes 3.9 s\n",
      "process 3800 peaks takes 3.9 s\n",
      "process 3850 peaks takes 4.0 s\n",
      "process 3900 peaks takes 4.1 s\n",
      "process 3950 peaks takes 4.1 s\n",
      "process 4000 peaks takes 4.2 s\n",
      "process 4050 peaks takes 4.2 s\n",
      "process 4100 peaks takes 4.3 s\n",
      "process 4150 peaks takes 4.3 s\n",
      "process 4200 peaks takes 4.4 s\n",
      "process 4250 peaks takes 4.4 s\n",
      "process 4300 peaks takes 4.5 s\n",
      "process 4350 peaks takes 4.5 s\n",
      "process 4400 peaks takes 4.6 s\n",
      "process 4450 peaks takes 4.6 s\n",
      "process 4500 peaks takes 4.7 s\n",
      "process 4550 peaks takes 4.7 s\n",
      "process 4600 peaks takes 4.8 s\n",
      "process 4650 peaks takes 4.9 s\n",
      "process 4700 peaks takes 4.9 s\n",
      "process 4750 peaks takes 4.9 s\n",
      "process 4800 peaks takes 5.0 s\n",
      "process 4850 peaks takes 5.1 s\n",
      "process 4900 peaks takes 5.1 s\n",
      "process 4950 peaks takes 5.2 s\n",
      "process 5000 peaks takes 5.2 s\n",
      "process 5050 peaks takes 5.2 s\n",
      "process 5100 peaks takes 5.3 s\n",
      "process 5150 peaks takes 5.4 s\n",
      "process 5200 peaks takes 5.4 s\n",
      "process 5250 peaks takes 5.4 s\n",
      "process 5300 peaks takes 5.5 s\n",
      "process 5350 peaks takes 5.5 s\n",
      "process 5400 peaks takes 5.6 s\n",
      "process 5450 peaks takes 5.6 s\n",
      "process 5500 peaks takes 5.7 s\n",
      "process 5550 peaks takes 5.7 s\n",
      "process 5600 peaks takes 5.8 s\n",
      "process 5650 peaks takes 5.8 s\n",
      "process 5700 peaks takes 5.9 s\n",
      "process 5750 peaks takes 5.9 s\n",
      "process 5800 peaks takes 6.0 s\n",
      "process 5850 peaks takes 6.0 s\n",
      "process 5900 peaks takes 6.1 s\n",
      "process 5950 peaks takes 6.2 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.3 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.4 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.5 s\n",
      "process 3600 peaks takes 3.5 s\n",
      "process 3650 peaks takes 3.6 s\n",
      "process 3700 peaks takes 3.6 s\n",
      "process 3750 peaks takes 3.7 s\n",
      "process 3800 peaks takes 3.7 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.8 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.9 s\n",
      "process 4050 peaks takes 3.9 s\n",
      "process 4100 peaks takes 4.0 s\n",
      "process 4150 peaks takes 4.0 s\n",
      "process 4200 peaks takes 4.1 s\n",
      "process 4250 peaks takes 4.1 s\n",
      "process 4300 peaks takes 4.2 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.2 s\n",
      "process 4450 peaks takes 4.3 s\n",
      "process 4500 peaks takes 4.3 s\n",
      "process 4550 peaks takes 4.4 s\n",
      "process 4600 peaks takes 4.4 s\n",
      "process 4650 peaks takes 4.5 s\n",
      "process 4700 peaks takes 4.5 s\n",
      "process 4750 peaks takes 4.6 s\n",
      "process 4800 peaks takes 4.6 s\n",
      "process 4850 peaks takes 4.7 s\n",
      "process 4900 peaks takes 4.8 s\n",
      "process 4950 peaks takes 4.8 s\n",
      "process 5000 peaks takes 4.8 s\n",
      "process 5050 peaks takes 4.9 s\n",
      "process 5100 peaks takes 4.9 s\n",
      "process 5150 peaks takes 5.0 s\n",
      "process 5200 peaks takes 5.0 s\n",
      "process 5250 peaks takes 5.1 s\n",
      "process 5300 peaks takes 5.1 s\n",
      "process 5350 peaks takes 5.1 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs2000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:24:41.695003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:24:41.805579: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:24:41.808549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:41.808578: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:24:42.282359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:42.282424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:42.282430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:24:43.800455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:24:43.800574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800642: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800773: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:24:43.800920: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:24:43.801260: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "43/43 [==============================] - 80s 2s/step - loss: 0.1602 - auc: 0.5007 - auc_1: 0.0052 - val_loss: 0.0347 - val_auc: 0.3378 - val_auc_1: 0.0059\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs2000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs2000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 07:26:07.353142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:26:07.449408: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:26:07.452436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:07.452469: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:26:07.916404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:07.916493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:07.916499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.3 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.4 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.4 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.6 s\n",
      "process 2400 peaks takes 2.6 s\n",
      "process 2450 peaks takes 2.7 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.8 s\n",
      "process 2600 peaks takes 2.9 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 3.0 s\n",
      "process 2750 peaks takes 3.0 s\n",
      "process 2800 peaks takes 3.0 s\n",
      "process 2850 peaks takes 3.1 s\n",
      "process 2900 peaks takes 3.1 s\n",
      "process 2950 peaks takes 3.2 s\n",
      "process 3000 peaks takes 3.3 s\n",
      "process 3050 peaks takes 3.3 s\n",
      "process 3100 peaks takes 3.3 s\n",
      "process 3150 peaks takes 3.4 s\n",
      "process 3200 peaks takes 3.4 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.6 s\n",
      "process 3350 peaks takes 3.6 s\n",
      "process 3400 peaks takes 3.6 s\n",
      "process 3450 peaks takes 3.7 s\n",
      "process 3500 peaks takes 3.8 s\n",
      "process 3550 peaks takes 3.8 s\n",
      "process 3600 peaks takes 3.9 s\n",
      "process 3650 peaks takes 3.9 s\n",
      "process 3700 peaks takes 3.9 s\n",
      "process 3750 peaks takes 4.0 s\n",
      "process 3800 peaks takes 4.1 s\n",
      "process 3850 peaks takes 4.1 s\n",
      "process 3900 peaks takes 4.2 s\n",
      "process 3950 peaks takes 4.2 s\n",
      "process 4000 peaks takes 4.3 s\n",
      "process 4050 peaks takes 4.3 s\n",
      "process 4100 peaks takes 4.4 s\n",
      "process 4150 peaks takes 4.4 s\n",
      "process 4200 peaks takes 4.5 s\n",
      "process 4250 peaks takes 4.5 s\n",
      "process 4300 peaks takes 4.6 s\n",
      "process 4350 peaks takes 4.6 s\n",
      "process 4400 peaks takes 4.7 s\n",
      "process 4450 peaks takes 4.7 s\n",
      "process 4500 peaks takes 4.8 s\n",
      "process 4550 peaks takes 4.8 s\n",
      "process 4600 peaks takes 4.9 s\n",
      "process 4650 peaks takes 5.0 s\n",
      "process 4700 peaks takes 5.0 s\n",
      "process 4750 peaks takes 5.1 s\n",
      "process 4800 peaks takes 5.1 s\n",
      "process 4850 peaks takes 5.2 s\n",
      "process 4900 peaks takes 5.2 s\n",
      "process 4950 peaks takes 5.3 s\n",
      "process 5000 peaks takes 5.3 s\n",
      "process 5050 peaks takes 5.4 s\n",
      "process 5100 peaks takes 5.5 s\n",
      "process 5150 peaks takes 5.5 s\n",
      "process 5200 peaks takes 5.6 s\n",
      "process 5250 peaks takes 5.6 s\n",
      "process 5300 peaks takes 5.7 s\n",
      "process 5350 peaks takes 5.7 s\n",
      "process 5400 peaks takes 5.8 s\n",
      "process 5450 peaks takes 5.8 s\n",
      "process 5500 peaks takes 6.0 s\n",
      "process 5550 peaks takes 6.0 s\n",
      "process 5600 peaks takes 6.1 s\n",
      "process 5650 peaks takes 6.1 s\n",
      "process 5700 peaks takes 6.2 s\n",
      "process 5750 peaks takes 6.2 s\n",
      "process 5800 peaks takes 6.3 s\n",
      "process 5850 peaks takes 6.3 s\n",
      "process 5900 peaks takes 6.4 s\n",
      "process 5950 peaks takes 6.4 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.9 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 3.0 s\n",
      "process 3000 peaks takes 3.0 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.2 s\n",
      "process 3250 peaks takes 3.3 s\n",
      "process 3300 peaks takes 3.3 s\n",
      "process 3350 peaks takes 3.3 s\n",
      "process 3400 peaks takes 3.4 s\n",
      "process 3450 peaks takes 3.5 s\n",
      "process 3500 peaks takes 3.5 s\n",
      "process 3550 peaks takes 3.6 s\n",
      "process 3600 peaks takes 3.6 s\n",
      "process 3650 peaks takes 3.7 s\n",
      "process 3700 peaks takes 3.7 s\n",
      "process 3750 peaks takes 3.8 s\n",
      "process 3800 peaks takes 3.8 s\n",
      "process 3850 peaks takes 3.9 s\n",
      "process 3900 peaks takes 3.9 s\n",
      "process 3950 peaks takes 4.0 s\n",
      "process 4000 peaks takes 4.1 s\n",
      "process 4050 peaks takes 4.1 s\n",
      "process 4100 peaks takes 4.1 s\n",
      "process 4150 peaks takes 4.2 s\n",
      "process 4200 peaks takes 4.2 s\n",
      "process 4250 peaks takes 4.3 s\n",
      "process 4300 peaks takes 4.3 s\n",
      "process 4350 peaks takes 4.4 s\n",
      "process 4400 peaks takes 4.4 s\n",
      "process 4450 peaks takes 4.5 s\n",
      "process 4500 peaks takes 4.5 s\n",
      "process 4550 peaks takes 4.6 s\n",
      "process 4600 peaks takes 4.6 s\n",
      "process 4650 peaks takes 4.7 s\n",
      "process 4700 peaks takes 4.7 s\n",
      "process 4750 peaks takes 4.8 s\n",
      "process 4800 peaks takes 4.8 s\n",
      "process 4850 peaks takes 4.9 s\n",
      "process 4900 peaks takes 4.9 s\n",
      "process 4950 peaks takes 5.0 s\n",
      "process 5000 peaks takes 5.1 s\n",
      "process 5050 peaks takes 5.1 s\n",
      "process 5100 peaks takes 5.1 s\n",
      "process 5150 peaks takes 5.2 s\n",
      "process 5200 peaks takes 5.2 s\n",
      "process 5250 peaks takes 5.3 s\n",
      "process 5300 peaks takes 5.3 s\n",
      "process 5350 peaks takes 5.4 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs2000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs2000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:26:22.251838: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:26:22.355062: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:26:22.357882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:22.357908: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:26:22.843732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:22.843820: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:22.843827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:26:24.412287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:26:24.412420: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412553: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412739: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:26:24.412784: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:26:24.413140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "43/43 [==============================] - 82s 2s/step - loss: 0.2529 - auc: 0.5001 - auc_1: 0.0053 - val_loss: 0.0436 - val_auc: 0.3398 - val_auc_1: 0.0089\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs2000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "pancreatic_endocrinogenesis episcanpy /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs5000_e1/poisson\n",
      "mm10\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 07:27:49.982894: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:27:50.089089: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:27:50.092250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:27:50.092286: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:27:50.572091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:27:50.572196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:27:50.572204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.6 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.2 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.4 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.9 s\n",
      "process 2900 peaks takes 3.0 s\n",
      "process 2950 peaks takes 3.0 s\n",
      "process 3000 peaks takes 3.1 s\n",
      "process 3050 peaks takes 3.1 s\n",
      "process 3100 peaks takes 3.2 s\n",
      "process 3150 peaks takes 3.2 s\n",
      "process 3200 peaks takes 3.3 s\n",
      "process 3250 peaks takes 3.3 s\n",
      "process 3300 peaks takes 3.4 s\n",
      "process 3350 peaks takes 3.4 s\n",
      "process 3400 peaks takes 3.5 s\n",
      "process 3450 peaks takes 3.6 s\n",
      "process 3500 peaks takes 3.6 s\n",
      "process 3550 peaks takes 3.7 s\n",
      "process 3600 peaks takes 3.7 s\n",
      "process 3650 peaks takes 3.8 s\n",
      "process 3700 peaks takes 3.8 s\n",
      "process 3750 peaks takes 3.9 s\n",
      "process 3800 peaks takes 3.9 s\n",
      "process 3850 peaks takes 4.0 s\n",
      "process 3900 peaks takes 4.0 s\n",
      "process 3950 peaks takes 4.1 s\n",
      "process 4000 peaks takes 4.2 s\n",
      "process 4050 peaks takes 4.2 s\n",
      "process 4100 peaks takes 4.3 s\n",
      "process 4150 peaks takes 4.3 s\n",
      "process 4200 peaks takes 4.4 s\n",
      "process 4250 peaks takes 4.4 s\n",
      "process 4300 peaks takes 4.5 s\n",
      "process 4350 peaks takes 4.5 s\n",
      "process 4400 peaks takes 4.6 s\n",
      "process 4450 peaks takes 4.6 s\n",
      "process 4500 peaks takes 4.6 s\n",
      "process 4550 peaks takes 4.7 s\n",
      "process 4600 peaks takes 4.8 s\n",
      "process 4650 peaks takes 4.8 s\n",
      "process 4700 peaks takes 4.9 s\n",
      "process 4750 peaks takes 4.9 s\n",
      "process 4800 peaks takes 4.9 s\n",
      "process 4850 peaks takes 5.0 s\n",
      "process 4900 peaks takes 5.1 s\n",
      "process 4950 peaks takes 5.1 s\n",
      "process 5000 peaks takes 5.2 s\n",
      "process 5050 peaks takes 5.2 s\n",
      "process 5100 peaks takes 5.3 s\n",
      "process 5150 peaks takes 5.3 s\n",
      "process 5200 peaks takes 5.4 s\n",
      "process 5250 peaks takes 5.4 s\n",
      "process 5300 peaks takes 5.4 s\n",
      "process 5350 peaks takes 5.5 s\n",
      "process 5400 peaks takes 5.6 s\n",
      "process 5450 peaks takes 5.6 s\n",
      "process 5500 peaks takes 5.7 s\n",
      "process 5550 peaks takes 5.7 s\n",
      "process 5600 peaks takes 5.8 s\n",
      "process 5650 peaks takes 5.8 s\n",
      "process 5700 peaks takes 5.9 s\n",
      "process 5750 peaks takes 5.9 s\n",
      "process 5800 peaks takes 5.9 s\n",
      "process 5850 peaks takes 6.0 s\n",
      "process 5900 peaks takes 6.1 s\n",
      "process 5950 peaks takes 6.1 s\n",
      "process 6000 peaks takes 6.1 s\n",
      "process 6050 peaks takes 6.2 s\n",
      "process 6100 peaks takes 6.2 s\n",
      "process 6150 peaks takes 6.3 s\n",
      "process 6200 peaks takes 6.3 s\n",
      "process 6250 peaks takes 6.4 s\n",
      "process 6300 peaks takes 6.4 s\n",
      "process 6350 peaks takes 6.5 s\n",
      "process 6400 peaks takes 6.5 s\n",
      "process 6450 peaks takes 6.6 s\n",
      "process 6500 peaks takes 6.6 s\n",
      "process 6550 peaks takes 6.6 s\n",
      "process 6600 peaks takes 6.7 s\n",
      "process 6650 peaks takes 6.7 s\n",
      "process 6700 peaks takes 6.8 s\n",
      "process 6750 peaks takes 6.8 s\n",
      "process 6800 peaks takes 6.9 s\n",
      "process 6850 peaks takes 6.9 s\n",
      "process 6900 peaks takes 7.0 s\n",
      "process 6950 peaks takes 7.0 s\n",
      "process 7000 peaks takes 7.1 s\n",
      "process 7050 peaks takes 7.1 s\n",
      "process 7100 peaks takes 7.2 s\n",
      "process 7150 peaks takes 7.2 s\n",
      "process 7200 peaks takes 7.2 s\n",
      "process 7250 peaks takes 7.3 s\n",
      "process 7300 peaks takes 7.3 s\n",
      "process 7350 peaks takes 7.4 s\n",
      "process 7400 peaks takes 7.4 s\n",
      "process 7450 peaks takes 7.5 s\n",
      "process 7500 peaks takes 7.5 s\n",
      "process 7550 peaks takes 7.6 s\n",
      "process 7600 peaks takes 7.6 s\n",
      "process 7650 peaks takes 7.7 s\n",
      "process 7700 peaks takes 7.7 s\n",
      "process 7750 peaks takes 7.8 s\n",
      "process 7800 peaks takes 7.8 s\n",
      "process 7850 peaks takes 7.9 s\n",
      "process 7900 peaks takes 7.9 s\n",
      "process 7950 peaks takes 8.0 s\n",
      "process 8000 peaks takes 8.0 s\n",
      "process 8050 peaks takes 8.1 s\n",
      "process 8100 peaks takes 8.1 s\n",
      "process 8150 peaks takes 8.2 s\n",
      "process 8200 peaks takes 8.2 s\n",
      "process 8250 peaks takes 8.3 s\n",
      "process 8300 peaks takes 8.3 s\n",
      "process 8350 peaks takes 8.4 s\n",
      "process 8400 peaks takes 8.4 s\n",
      "process 8450 peaks takes 8.5 s\n",
      "process 8500 peaks takes 8.5 s\n",
      "process 8550 peaks takes 8.6 s\n",
      "process 8600 peaks takes 8.6 s\n",
      "process 8650 peaks takes 8.7 s\n",
      "process 8700 peaks takes 8.7 s\n",
      "process 8750 peaks takes 8.7 s\n",
      "process 8800 peaks takes 8.8 s\n",
      "process 8850 peaks takes 8.8 s\n",
      "process 8900 peaks takes 8.9 s\n",
      "process 8950 peaks takes 8.9 s\n",
      "process 9000 peaks takes 9.0 s\n",
      "process 9050 peaks takes 9.0 s\n",
      "process 9100 peaks takes 9.1 s\n",
      "process 9150 peaks takes 9.1 s\n",
      "process 9200 peaks takes 9.2 s\n",
      "process 9250 peaks takes 9.2 s\n",
      "process 9300 peaks takes 9.3 s\n",
      "process 9350 peaks takes 9.3 s\n",
      "process 9400 peaks takes 9.4 s\n",
      "process 9450 peaks takes 9.4 s\n",
      "process 9500 peaks takes 9.5 s\n",
      "process 9550 peaks takes 9.5 s\n",
      "process 9600 peaks takes 9.5 s\n",
      "process 9650 peaks takes 9.6 s\n",
      "process 9700 peaks takes 9.6 s\n",
      "process 9750 peaks takes 9.7 s\n",
      "process 9800 peaks takes 9.7 s\n",
      "process 9850 peaks takes 9.8 s\n",
      "process 9900 peaks takes 9.8 s\n",
      "process 9950 peaks takes 9.9 s\n",
      "process 10000 peaks takes 9.9 s\n",
      "process 10050 peaks takes 10.0 s\n",
      "process 10100 peaks takes 10.0 s\n",
      "process 10150 peaks takes 10.0 s\n",
      "process 10200 peaks takes 10.1 s\n",
      "process 10250 peaks takes 10.1 s\n",
      "process 10300 peaks takes 10.2 s\n",
      "process 10350 peaks takes 10.2 s\n",
      "process 10400 peaks takes 10.3 s\n",
      "process 10450 peaks takes 10.3 s\n",
      "process 10500 peaks takes 10.4 s\n",
      "process 10550 peaks takes 10.4 s\n",
      "process 10600 peaks takes 10.5 s\n",
      "process 10650 peaks takes 10.5 s\n",
      "process 10700 peaks takes 10.6 s\n",
      "process 10750 peaks takes 10.6 s\n",
      "process 10800 peaks takes 10.7 s\n",
      "process 10850 peaks takes 10.7 s\n",
      "process 10900 peaks takes 10.8 s\n",
      "process 10950 peaks takes 10.8 s\n",
      "process 11000 peaks takes 10.8 s\n",
      "process 11050 peaks takes 10.9 s\n",
      "process 11100 peaks takes 10.9 s\n",
      "process 11150 peaks takes 11.0 s\n",
      "process 11200 peaks takes 11.0 s\n",
      "process 11250 peaks takes 11.1 s\n",
      "process 11300 peaks takes 11.1 s\n",
      "process 11350 peaks takes 11.2 s\n",
      "process 11400 peaks takes 11.2 s\n",
      "process 11450 peaks takes 11.3 s\n",
      "process 11500 peaks takes 11.3 s\n",
      "process 11550 peaks takes 11.4 s\n",
      "process 11600 peaks takes 11.4 s\n",
      "process 11650 peaks takes 11.5 s\n",
      "process 11700 peaks takes 11.5 s\n",
      "process 11750 peaks takes 11.6 s\n",
      "process 11800 peaks takes 11.6 s\n",
      "process 11850 peaks takes 11.7 s\n",
      "process 11900 peaks takes 11.7 s\n",
      "process 11950 peaks takes 11.8 s\n",
      "process 12000 peaks takes 11.8 s\n",
      "process 12050 peaks takes 11.9 s\n",
      "process 12100 peaks takes 11.9 s\n",
      "process 12150 peaks takes 12.0 s\n",
      "process 12200 peaks takes 12.0 s\n",
      "process 12250 peaks takes 12.0 s\n",
      "process 12300 peaks takes 12.1 s\n",
      "process 12350 peaks takes 12.1 s\n",
      "process 12400 peaks takes 12.2 s\n",
      "process 12450 peaks takes 12.2 s\n",
      "process 12500 peaks takes 12.3 s\n",
      "process 12550 peaks takes 12.4 s\n",
      "process 12600 peaks takes 12.4 s\n",
      "process 12650 peaks takes 12.4 s\n",
      "process 12700 peaks takes 12.5 s\n",
      "process 12750 peaks takes 12.6 s\n",
      "process 12800 peaks takes 12.6 s\n",
      "process 12850 peaks takes 12.6 s\n",
      "process 12900 peaks takes 12.7 s\n",
      "process 12950 peaks takes 12.7 s\n",
      "process 13000 peaks takes 12.8 s\n",
      "process 13050 peaks takes 12.8 s\n",
      "process 13100 peaks takes 12.9 s\n",
      "process 13150 peaks takes 12.9 s\n",
      "process 13200 peaks takes 13.0 s\n",
      "process 13250 peaks takes 13.0 s\n",
      "process 13300 peaks takes 13.0 s\n",
      "process 13350 peaks takes 13.1 s\n",
      "process 13400 peaks takes 13.2 s\n",
      "process 13450 peaks takes 13.2 s\n",
      "process 13500 peaks takes 13.3 s\n",
      "process 13550 peaks takes 13.3 s\n",
      "process 13600 peaks takes 13.4 s\n",
      "process 13650 peaks takes 13.4 s\n",
      "process 13700 peaks takes 13.5 s\n",
      "process 13750 peaks takes 13.5 s\n",
      "process 13800 peaks takes 13.5 s\n",
      "process 13850 peaks takes 13.6 s\n",
      "process 13900 peaks takes 13.6 s\n",
      "process 13950 peaks takes 13.7 s\n",
      "process 14000 peaks takes 13.7 s\n",
      "process 14050 peaks takes 13.8 s\n",
      "process 14100 peaks takes 13.8 s\n",
      "process 14150 peaks takes 13.9 s\n",
      "process 14200 peaks takes 13.9 s\n",
      "process 14250 peaks takes 14.0 s\n",
      "process 14300 peaks takes 14.0 s\n",
      "process 14350 peaks takes 14.1 s\n",
      "process 14400 peaks takes 14.1 s\n",
      "process 14450 peaks takes 14.2 s\n",
      "process 14500 peaks takes 14.2 s\n",
      "process 14550 peaks takes 14.3 s\n",
      "process 14600 peaks takes 14.3 s\n",
      "process 14650 peaks takes 14.4 s\n",
      "process 14700 peaks takes 14.4 s\n",
      "process 14750 peaks takes 14.5 s\n",
      "process 14800 peaks takes 14.5 s\n",
      "process 14850 peaks takes 14.6 s\n",
      "process 14900 peaks takes 14.6 s\n",
      "process 14950 peaks takes 14.7 s\n",
      "\n",
      "train\n",
      "13501 270\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 3.0 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.2 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.3 s\n",
      "process 3350 peaks takes 3.3 s\n",
      "process 3400 peaks takes 3.4 s\n",
      "process 3450 peaks takes 3.4 s\n",
      "process 3500 peaks takes 3.5 s\n",
      "process 3550 peaks takes 3.5 s\n",
      "process 3600 peaks takes 3.6 s\n",
      "process 3650 peaks takes 3.6 s\n",
      "process 3700 peaks takes 3.7 s\n",
      "process 3750 peaks takes 3.7 s\n",
      "process 3800 peaks takes 3.8 s\n",
      "process 3850 peaks takes 3.8 s\n",
      "process 3900 peaks takes 3.9 s\n",
      "process 3950 peaks takes 3.9 s\n",
      "process 4000 peaks takes 4.0 s\n",
      "process 4050 peaks takes 4.0 s\n",
      "process 4100 peaks takes 4.1 s\n",
      "process 4150 peaks takes 4.1 s\n",
      "process 4200 peaks takes 4.2 s\n",
      "process 4250 peaks takes 4.2 s\n",
      "process 4300 peaks takes 4.3 s\n",
      "process 4350 peaks takes 4.3 s\n",
      "process 4400 peaks takes 4.4 s\n",
      "process 4450 peaks takes 4.4 s\n",
      "process 4500 peaks takes 4.5 s\n",
      "process 4550 peaks takes 4.5 s\n",
      "process 4600 peaks takes 4.6 s\n",
      "process 4650 peaks takes 4.6 s\n",
      "process 4700 peaks takes 4.6 s\n",
      "process 4750 peaks takes 4.7 s\n",
      "process 4800 peaks takes 4.8 s\n",
      "process 4850 peaks takes 4.8 s\n",
      "process 4900 peaks takes 4.9 s\n",
      "process 4950 peaks takes 4.9 s\n",
      "process 5000 peaks takes 5.0 s\n",
      "process 5050 peaks takes 5.0 s\n",
      "process 5100 peaks takes 5.0 s\n",
      "process 5150 peaks takes 5.1 s\n",
      "process 5200 peaks takes 5.1 s\n",
      "process 5250 peaks takes 5.2 s\n",
      "process 5300 peaks takes 5.2 s\n",
      "process 5350 peaks takes 5.3 s\n",
      "process 5400 peaks takes 5.4 s\n",
      "process 5450 peaks takes 5.4 s\n",
      "process 5500 peaks takes 5.4 s\n",
      "process 5550 peaks takes 5.5 s\n",
      "process 5600 peaks takes 5.5 s\n",
      "process 5650 peaks takes 5.6 s\n",
      "process 5700 peaks takes 5.6 s\n",
      "process 5750 peaks takes 5.7 s\n",
      "process 5800 peaks takes 5.7 s\n",
      "process 5850 peaks takes 5.8 s\n",
      "process 5900 peaks takes 5.8 s\n",
      "process 5950 peaks takes 5.9 s\n",
      "process 6000 peaks takes 5.9 s\n",
      "process 6050 peaks takes 6.0 s\n",
      "process 6100 peaks takes 6.0 s\n",
      "process 6150 peaks takes 6.1 s\n",
      "process 6200 peaks takes 6.1 s\n",
      "process 6250 peaks takes 6.1 s\n",
      "process 6300 peaks takes 6.2 s\n",
      "process 6350 peaks takes 6.2 s\n",
      "process 6400 peaks takes 6.3 s\n",
      "process 6450 peaks takes 6.3 s\n",
      "process 6500 peaks takes 6.4 s\n",
      "process 6550 peaks takes 6.4 s\n",
      "process 6600 peaks takes 6.4 s\n",
      "process 6650 peaks takes 6.5 s\n",
      "process 6700 peaks takes 6.6 s\n",
      "process 6750 peaks takes 6.6 s\n",
      "process 6800 peaks takes 6.6 s\n",
      "process 6850 peaks takes 6.7 s\n",
      "process 6900 peaks takes 6.7 s\n",
      "process 6950 peaks takes 6.8 s\n",
      "process 7000 peaks takes 6.8 s\n",
      "process 7050 peaks takes 6.9 s\n",
      "process 7100 peaks takes 6.9 s\n",
      "process 7150 peaks takes 7.0 s\n",
      "process 7200 peaks takes 7.0 s\n",
      "process 7250 peaks takes 7.1 s\n",
      "process 7300 peaks takes 7.1 s\n",
      "process 7350 peaks takes 7.2 s\n",
      "process 7400 peaks takes 7.2 s\n",
      "process 7450 peaks takes 7.3 s\n",
      "process 7500 peaks takes 7.3 s\n",
      "process 7550 peaks takes 7.4 s\n",
      "process 7600 peaks takes 7.4 s\n",
      "process 7650 peaks takes 7.5 s\n",
      "process 7700 peaks takes 7.5 s\n",
      "process 7750 peaks takes 7.6 s\n",
      "process 7800 peaks takes 7.6 s\n",
      "process 7850 peaks takes 7.7 s\n",
      "process 7900 peaks takes 7.7 s\n",
      "process 7950 peaks takes 7.8 s\n",
      "process 8000 peaks takes 7.8 s\n",
      "process 8050 peaks takes 7.9 s\n",
      "process 8100 peaks takes 7.9 s\n",
      "process 8150 peaks takes 8.0 s\n",
      "process 8200 peaks takes 8.0 s\n",
      "process 8250 peaks takes 8.1 s\n",
      "process 8300 peaks takes 8.1 s\n",
      "process 8350 peaks takes 8.2 s\n",
      "process 8400 peaks takes 8.2 s\n",
      "process 8450 peaks takes 8.2 s\n",
      "process 8500 peaks takes 8.3 s\n",
      "process 8550 peaks takes 8.3 s\n",
      "process 8600 peaks takes 8.4 s\n",
      "process 8650 peaks takes 8.4 s\n",
      "process 8700 peaks takes 8.5 s\n",
      "process 8750 peaks takes 8.5 s\n",
      "process 8800 peaks takes 8.6 s\n",
      "process 8850 peaks takes 8.6 s\n",
      "process 8900 peaks takes 8.7 s\n",
      "process 8950 peaks takes 8.7 s\n",
      "process 9000 peaks takes 8.8 s\n",
      "process 9050 peaks takes 8.8 s\n",
      "process 9100 peaks takes 8.9 s\n",
      "process 9150 peaks takes 8.9 s\n",
      "process 9200 peaks takes 9.0 s\n",
      "process 9250 peaks takes 9.0 s\n",
      "process 9300 peaks takes 9.1 s\n",
      "process 9350 peaks takes 9.1 s\n",
      "process 9400 peaks takes 9.2 s\n",
      "process 9450 peaks takes 9.2 s\n",
      "process 9500 peaks takes 9.3 s\n",
      "process 9550 peaks takes 9.3 s\n",
      "process 9600 peaks takes 9.4 s\n",
      "process 9650 peaks takes 9.5 s\n",
      "process 9700 peaks takes 9.5 s\n",
      "process 9750 peaks takes 9.6 s\n",
      "process 9800 peaks takes 9.6 s\n",
      "process 9850 peaks takes 9.7 s\n",
      "process 9900 peaks takes 9.7 s\n",
      "process 9950 peaks takes 9.8 s\n",
      "process 10000 peaks takes 9.8 s\n",
      "process 10050 peaks takes 9.9 s\n",
      "process 10100 peaks takes 9.9 s\n",
      "process 10150 peaks takes 10.0 s\n",
      "process 10200 peaks takes 10.0 s\n",
      "process 10250 peaks takes 10.1 s\n",
      "process 10300 peaks takes 10.1 s\n",
      "process 10350 peaks takes 10.2 s\n",
      "process 10400 peaks takes 10.2 s\n",
      "process 10450 peaks takes 10.3 s\n",
      "process 10500 peaks takes 10.3 s\n",
      "process 10550 peaks takes 10.4 s\n",
      "process 10600 peaks takes 10.4 s\n",
      "process 10650 peaks takes 10.5 s\n",
      "process 10700 peaks takes 10.5 s\n",
      "process 10750 peaks takes 10.5 s\n",
      "process 10800 peaks takes 10.6 s\n",
      "process 10850 peaks takes 10.7 s\n",
      "process 10900 peaks takes 10.7 s\n",
      "process 10950 peaks takes 10.8 s\n",
      "process 11000 peaks takes 10.8 s\n",
      "process 11050 peaks takes 10.8 s\n",
      "process 11100 peaks takes 10.9 s\n",
      "process 11150 peaks takes 10.9 s\n",
      "process 11200 peaks takes 11.0 s\n",
      "process 11250 peaks takes 11.0 s\n",
      "process 11300 peaks takes 11.1 s\n",
      "process 11350 peaks takes 11.1 s\n",
      "process 11400 peaks takes 11.1 s\n",
      "process 11450 peaks takes 11.2 s\n",
      "process 11500 peaks takes 11.2 s\n",
      "process 11550 peaks takes 11.3 s\n",
      "process 11600 peaks takes 11.3 s\n",
      "process 11650 peaks takes 11.4 s\n",
      "process 11700 peaks takes 11.4 s\n",
      "process 11750 peaks takes 11.5 s\n",
      "process 11800 peaks takes 11.5 s\n",
      "process 11850 peaks takes 11.6 s\n",
      "process 11900 peaks takes 11.6 s\n",
      "process 11950 peaks takes 11.7 s\n",
      "process 12000 peaks takes 11.7 s\n",
      "process 12050 peaks takes 11.8 s\n",
      "process 12100 peaks takes 11.8 s\n",
      "process 12150 peaks takes 11.8 s\n",
      "process 12200 peaks takes 11.9 s\n",
      "process 12250 peaks takes 11.9 s\n",
      "process 12300 peaks takes 12.0 s\n",
      "process 12350 peaks takes 12.0 s\n",
      "process 12400 peaks takes 12.1 s\n",
      "process 12450 peaks takes 12.1 s\n",
      "process 12500 peaks takes 12.2 s\n",
      "process 12550 peaks takes 12.2 s\n",
      "process 12600 peaks takes 12.3 s\n",
      "process 12650 peaks takes 12.3 s\n",
      "process 12700 peaks takes 12.4 s\n",
      "process 12750 peaks takes 12.4 s\n",
      "process 12800 peaks takes 12.5 s\n",
      "process 12850 peaks takes 12.5 s\n",
      "process 12900 peaks takes 12.6 s\n",
      "process 12950 peaks takes 12.6 s\n",
      "process 13000 peaks takes 12.6 s\n",
      "process 13050 peaks takes 12.7 s\n",
      "process 13100 peaks takes 12.7 s\n",
      "process 13150 peaks takes 12.8 s\n",
      "process 13200 peaks takes 12.8 s\n",
      "process 13250 peaks takes 12.9 s\n",
      "process 13300 peaks takes 12.9 s\n",
      "process 13350 peaks takes 13.0 s\n",
      "process 13400 peaks takes 13.0 s\n",
      "process 13450 peaks takes 13.1 s\n",
      "\n",
      "test\n",
      "750 15\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "\n",
      "val\n",
      "749 14\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs5000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:28:22.232134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:28:22.331890: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:28:22.334952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:22.334983: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:28:22.811621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:22.811713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:22.811736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:28:24.420090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:28:24.420210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420416: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:28:24.420567: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:28:24.420896: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5000)      165000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,684,810\n",
      "Trainable params: 4,678,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "106/106 [==============================] - 182s 2s/step - loss: 0.0951 - auc: 0.4996 - auc_1: 0.0066 - val_loss: 0.0430 - val_auc: 0.4740 - val_auc_1: 0.0103\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs5000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs5000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 07:31:30.570886: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:31:30.688155: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:31:30.691364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:31:30.691398: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:31:31.197572: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:31:31.197690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:31:31.197697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.1 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.9 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 3.0 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.2 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.3 s\n",
      "process 3350 peaks takes 3.4 s\n",
      "process 3400 peaks takes 3.4 s\n",
      "process 3450 peaks takes 3.4 s\n",
      "process 3500 peaks takes 3.5 s\n",
      "process 3550 peaks takes 3.6 s\n",
      "process 3600 peaks takes 3.6 s\n",
      "process 3650 peaks takes 3.6 s\n",
      "process 3700 peaks takes 3.7 s\n",
      "process 3750 peaks takes 3.7 s\n",
      "process 3800 peaks takes 3.8 s\n",
      "process 3850 peaks takes 3.9 s\n",
      "process 3900 peaks takes 3.9 s\n",
      "process 3950 peaks takes 3.9 s\n",
      "process 4000 peaks takes 4.0 s\n",
      "process 4050 peaks takes 4.0 s\n",
      "process 4100 peaks takes 4.1 s\n",
      "process 4150 peaks takes 4.1 s\n",
      "process 4200 peaks takes 4.2 s\n",
      "process 4250 peaks takes 4.2 s\n",
      "process 4300 peaks takes 4.3 s\n",
      "process 4350 peaks takes 4.3 s\n",
      "process 4400 peaks takes 4.4 s\n",
      "process 4450 peaks takes 4.4 s\n",
      "process 4500 peaks takes 4.5 s\n",
      "process 4550 peaks takes 4.5 s\n",
      "process 4600 peaks takes 4.6 s\n",
      "process 4650 peaks takes 4.6 s\n",
      "process 4700 peaks takes 4.6 s\n",
      "process 4750 peaks takes 4.7 s\n",
      "process 4800 peaks takes 4.7 s\n",
      "process 4850 peaks takes 4.8 s\n",
      "process 4900 peaks takes 4.8 s\n",
      "process 4950 peaks takes 4.9 s\n",
      "process 5000 peaks takes 4.9 s\n",
      "process 5050 peaks takes 5.0 s\n",
      "process 5100 peaks takes 5.0 s\n",
      "process 5150 peaks takes 5.1 s\n",
      "process 5200 peaks takes 5.1 s\n",
      "process 5250 peaks takes 5.1 s\n",
      "process 5300 peaks takes 5.2 s\n",
      "process 5350 peaks takes 5.2 s\n",
      "process 5400 peaks takes 5.3 s\n",
      "process 5450 peaks takes 5.3 s\n",
      "process 5500 peaks takes 5.4 s\n",
      "process 5550 peaks takes 5.4 s\n",
      "process 5600 peaks takes 5.5 s\n",
      "process 5650 peaks takes 5.5 s\n",
      "process 5700 peaks takes 5.6 s\n",
      "process 5750 peaks takes 5.6 s\n",
      "process 5800 peaks takes 5.7 s\n",
      "process 5850 peaks takes 5.7 s\n",
      "process 5900 peaks takes 5.8 s\n",
      "process 5950 peaks takes 5.8 s\n",
      "process 6000 peaks takes 5.9 s\n",
      "process 6050 peaks takes 5.9 s\n",
      "process 6100 peaks takes 5.9 s\n",
      "process 6150 peaks takes 6.0 s\n",
      "process 6200 peaks takes 6.0 s\n",
      "process 6250 peaks takes 6.1 s\n",
      "process 6300 peaks takes 6.1 s\n",
      "process 6350 peaks takes 6.2 s\n",
      "process 6400 peaks takes 6.2 s\n",
      "process 6450 peaks takes 6.3 s\n",
      "process 6500 peaks takes 6.3 s\n",
      "process 6550 peaks takes 6.4 s\n",
      "process 6600 peaks takes 6.4 s\n",
      "process 6650 peaks takes 6.5 s\n",
      "process 6700 peaks takes 6.5 s\n",
      "process 6750 peaks takes 6.6 s\n",
      "process 6800 peaks takes 6.6 s\n",
      "process 6850 peaks takes 6.7 s\n",
      "process 6900 peaks takes 6.7 s\n",
      "process 6950 peaks takes 6.8 s\n",
      "process 7000 peaks takes 6.8 s\n",
      "process 7050 peaks takes 6.9 s\n",
      "process 7100 peaks takes 6.9 s\n",
      "process 7150 peaks takes 7.0 s\n",
      "process 7200 peaks takes 7.0 s\n",
      "process 7250 peaks takes 7.0 s\n",
      "process 7300 peaks takes 7.1 s\n",
      "process 7350 peaks takes 7.2 s\n",
      "process 7400 peaks takes 7.2 s\n",
      "process 7450 peaks takes 7.2 s\n",
      "process 7500 peaks takes 7.4 s\n",
      "process 7550 peaks takes 7.4 s\n",
      "process 7600 peaks takes 7.5 s\n",
      "process 7650 peaks takes 7.5 s\n",
      "process 7700 peaks takes 7.6 s\n",
      "process 7750 peaks takes 7.6 s\n",
      "process 7800 peaks takes 7.7 s\n",
      "process 7850 peaks takes 7.7 s\n",
      "process 7900 peaks takes 7.8 s\n",
      "process 7950 peaks takes 7.8 s\n",
      "process 8000 peaks takes 7.8 s\n",
      "process 8050 peaks takes 7.9 s\n",
      "process 8100 peaks takes 7.9 s\n",
      "process 8150 peaks takes 8.0 s\n",
      "process 8200 peaks takes 8.0 s\n",
      "process 8250 peaks takes 8.1 s\n",
      "process 8300 peaks takes 8.1 s\n",
      "process 8350 peaks takes 8.1 s\n",
      "process 8400 peaks takes 8.2 s\n",
      "process 8450 peaks takes 8.2 s\n",
      "process 8500 peaks takes 8.3 s\n",
      "process 8550 peaks takes 8.3 s\n",
      "process 8600 peaks takes 8.4 s\n",
      "process 8650 peaks takes 8.4 s\n",
      "process 8700 peaks takes 8.5 s\n",
      "process 8750 peaks takes 8.5 s\n",
      "process 8800 peaks takes 8.6 s\n",
      "process 8850 peaks takes 8.6 s\n",
      "process 8900 peaks takes 8.7 s\n",
      "process 8950 peaks takes 8.7 s\n",
      "process 9000 peaks takes 8.7 s\n",
      "process 9050 peaks takes 8.8 s\n",
      "process 9100 peaks takes 8.8 s\n",
      "process 9150 peaks takes 8.9 s\n",
      "process 9200 peaks takes 8.9 s\n",
      "process 9250 peaks takes 9.0 s\n",
      "process 9300 peaks takes 9.0 s\n",
      "process 9350 peaks takes 9.1 s\n",
      "process 9400 peaks takes 9.1 s\n",
      "process 9450 peaks takes 9.2 s\n",
      "process 9500 peaks takes 9.2 s\n",
      "process 9550 peaks takes 9.3 s\n",
      "process 9600 peaks takes 9.3 s\n",
      "process 9650 peaks takes 9.3 s\n",
      "process 9700 peaks takes 9.4 s\n",
      "process 9750 peaks takes 9.4 s\n",
      "process 9800 peaks takes 9.5 s\n",
      "process 9850 peaks takes 9.5 s\n",
      "process 9900 peaks takes 9.6 s\n",
      "process 9950 peaks takes 9.6 s\n",
      "process 10000 peaks takes 9.7 s\n",
      "process 10050 peaks takes 9.7 s\n",
      "process 10100 peaks takes 9.8 s\n",
      "process 10150 peaks takes 9.8 s\n",
      "process 10200 peaks takes 9.9 s\n",
      "process 10250 peaks takes 9.9 s\n",
      "process 10300 peaks takes 10.0 s\n",
      "process 10350 peaks takes 10.0 s\n",
      "process 10400 peaks takes 10.1 s\n",
      "process 10450 peaks takes 10.1 s\n",
      "process 10500 peaks takes 10.2 s\n",
      "process 10550 peaks takes 10.2 s\n",
      "process 10600 peaks takes 10.3 s\n",
      "process 10650 peaks takes 10.3 s\n",
      "process 10700 peaks takes 10.4 s\n",
      "process 10750 peaks takes 10.4 s\n",
      "process 10800 peaks takes 10.5 s\n",
      "process 10850 peaks takes 10.5 s\n",
      "process 10900 peaks takes 10.5 s\n",
      "process 10950 peaks takes 10.6 s\n",
      "process 11000 peaks takes 10.6 s\n",
      "process 11050 peaks takes 10.7 s\n",
      "process 11100 peaks takes 10.7 s\n",
      "process 11150 peaks takes 10.8 s\n",
      "process 11200 peaks takes 10.8 s\n",
      "process 11250 peaks takes 10.9 s\n",
      "process 11300 peaks takes 10.9 s\n",
      "process 11350 peaks takes 10.9 s\n",
      "process 11400 peaks takes 11.0 s\n",
      "process 11450 peaks takes 11.0 s\n",
      "process 11500 peaks takes 11.1 s\n",
      "process 11550 peaks takes 11.1 s\n",
      "process 11600 peaks takes 11.2 s\n",
      "process 11650 peaks takes 11.2 s\n",
      "process 11700 peaks takes 11.3 s\n",
      "process 11750 peaks takes 11.3 s\n",
      "process 11800 peaks takes 11.4 s\n",
      "process 11850 peaks takes 11.4 s\n",
      "process 11900 peaks takes 11.5 s\n",
      "process 11950 peaks takes 11.5 s\n",
      "process 12000 peaks takes 11.6 s\n",
      "process 12050 peaks takes 11.6 s\n",
      "process 12100 peaks takes 11.6 s\n",
      "process 12150 peaks takes 11.7 s\n",
      "process 12200 peaks takes 11.7 s\n",
      "process 12250 peaks takes 11.8 s\n",
      "process 12300 peaks takes 11.8 s\n",
      "process 12350 peaks takes 11.9 s\n",
      "process 12400 peaks takes 11.9 s\n",
      "process 12450 peaks takes 12.0 s\n",
      "process 12500 peaks takes 12.0 s\n",
      "process 12550 peaks takes 12.0 s\n",
      "process 12600 peaks takes 12.1 s\n",
      "process 12650 peaks takes 12.2 s\n",
      "process 12700 peaks takes 12.2 s\n",
      "process 12750 peaks takes 12.2 s\n",
      "process 12800 peaks takes 12.3 s\n",
      "process 12850 peaks takes 12.3 s\n",
      "process 12900 peaks takes 12.4 s\n",
      "process 12950 peaks takes 12.4 s\n",
      "process 13000 peaks takes 12.5 s\n",
      "process 13050 peaks takes 12.5 s\n",
      "process 13100 peaks takes 12.6 s\n",
      "process 13150 peaks takes 12.6 s\n",
      "process 13200 peaks takes 12.7 s\n",
      "process 13250 peaks takes 12.7 s\n",
      "process 13300 peaks takes 12.8 s\n",
      "process 13350 peaks takes 12.8 s\n",
      "process 13400 peaks takes 12.9 s\n",
      "process 13450 peaks takes 12.9 s\n",
      "process 13500 peaks takes 12.9 s\n",
      "process 13550 peaks takes 13.0 s\n",
      "process 13600 peaks takes 13.0 s\n",
      "process 13650 peaks takes 13.1 s\n",
      "process 13700 peaks takes 13.1 s\n",
      "process 13750 peaks takes 13.1 s\n",
      "process 13800 peaks takes 13.2 s\n",
      "process 13850 peaks takes 13.2 s\n",
      "process 13900 peaks takes 13.3 s\n",
      "process 13950 peaks takes 13.3 s\n",
      "process 14000 peaks takes 13.4 s\n",
      "process 14050 peaks takes 13.4 s\n",
      "process 14100 peaks takes 13.5 s\n",
      "process 14150 peaks takes 13.5 s\n",
      "process 14200 peaks takes 13.6 s\n",
      "process 14250 peaks takes 13.6 s\n",
      "process 14300 peaks takes 13.7 s\n",
      "process 14350 peaks takes 13.7 s\n",
      "process 14400 peaks takes 13.8 s\n",
      "process 14450 peaks takes 13.8 s\n",
      "process 14500 peaks takes 13.9 s\n",
      "process 14550 peaks takes 13.9 s\n",
      "process 14600 peaks takes 13.9 s\n",
      "process 14650 peaks takes 14.0 s\n",
      "process 14700 peaks takes 14.0 s\n",
      "process 14750 peaks takes 14.1 s\n",
      "process 14800 peaks takes 14.1 s\n",
      "process 14850 peaks takes 14.2 s\n",
      "process 14900 peaks takes 14.2 s\n",
      "process 14950 peaks takes 14.3 s\n",
      "\n",
      "train\n",
      "13501 270\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.6 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.7 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.0 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.5 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.6 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.7 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.0 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.1 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.2 s\n",
      "process 3450 peaks takes 3.3 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.4 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.5 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.6 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.7 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.9 s\n",
      "process 4100 peaks takes 3.9 s\n",
      "process 4150 peaks takes 4.0 s\n",
      "process 4200 peaks takes 4.0 s\n",
      "process 4250 peaks takes 4.0 s\n",
      "process 4300 peaks takes 4.1 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.2 s\n",
      "process 4450 peaks takes 4.2 s\n",
      "process 4500 peaks takes 4.3 s\n",
      "process 4550 peaks takes 4.3 s\n",
      "process 4600 peaks takes 4.4 s\n",
      "process 4650 peaks takes 4.4 s\n",
      "process 4700 peaks takes 4.5 s\n",
      "process 4750 peaks takes 4.5 s\n",
      "process 4800 peaks takes 4.6 s\n",
      "process 4850 peaks takes 4.6 s\n",
      "process 4900 peaks takes 4.6 s\n",
      "process 4950 peaks takes 4.7 s\n",
      "process 5000 peaks takes 4.8 s\n",
      "process 5050 peaks takes 4.8 s\n",
      "process 5100 peaks takes 4.8 s\n",
      "process 5150 peaks takes 4.9 s\n",
      "process 5200 peaks takes 4.9 s\n",
      "process 5250 peaks takes 5.0 s\n",
      "process 5300 peaks takes 5.0 s\n",
      "process 5350 peaks takes 5.1 s\n",
      "process 5400 peaks takes 5.1 s\n",
      "process 5450 peaks takes 5.2 s\n",
      "process 5500 peaks takes 5.2 s\n",
      "process 5550 peaks takes 5.3 s\n",
      "process 5600 peaks takes 5.3 s\n",
      "process 5650 peaks takes 5.3 s\n",
      "process 5700 peaks takes 5.4 s\n",
      "process 5750 peaks takes 5.4 s\n",
      "process 5800 peaks takes 5.5 s\n",
      "process 5850 peaks takes 5.5 s\n",
      "process 5900 peaks takes 5.6 s\n",
      "process 5950 peaks takes 5.6 s\n",
      "process 6000 peaks takes 5.6 s\n",
      "process 6050 peaks takes 5.7 s\n",
      "process 6100 peaks takes 5.7 s\n",
      "process 6150 peaks takes 5.8 s\n",
      "process 6200 peaks takes 5.8 s\n",
      "process 6250 peaks takes 5.9 s\n",
      "process 6300 peaks takes 5.9 s\n",
      "process 6350 peaks takes 6.0 s\n",
      "process 6400 peaks takes 6.0 s\n",
      "process 6450 peaks takes 6.1 s\n",
      "process 6500 peaks takes 6.2 s\n",
      "process 6550 peaks takes 6.2 s\n",
      "process 6600 peaks takes 6.3 s\n",
      "process 6650 peaks takes 6.3 s\n",
      "process 6700 peaks takes 6.4 s\n",
      "process 6750 peaks takes 6.5 s\n",
      "process 6800 peaks takes 6.5 s\n",
      "process 6850 peaks takes 6.6 s\n",
      "process 6900 peaks takes 6.6 s\n",
      "process 6950 peaks takes 6.7 s\n",
      "process 7000 peaks takes 6.7 s\n",
      "process 7050 peaks takes 6.8 s\n",
      "process 7100 peaks takes 6.8 s\n",
      "process 7150 peaks takes 6.9 s\n",
      "process 7200 peaks takes 7.0 s\n",
      "process 7250 peaks takes 7.0 s\n",
      "process 7300 peaks takes 7.1 s\n",
      "process 7350 peaks takes 7.1 s\n",
      "process 7400 peaks takes 7.2 s\n",
      "process 7450 peaks takes 7.3 s\n",
      "process 7500 peaks takes 7.3 s\n",
      "process 7550 peaks takes 7.4 s\n",
      "process 7600 peaks takes 7.4 s\n",
      "process 7650 peaks takes 7.5 s\n",
      "process 7700 peaks takes 7.5 s\n",
      "process 7750 peaks takes 7.6 s\n",
      "process 7800 peaks takes 7.6 s\n",
      "process 7850 peaks takes 7.7 s\n",
      "process 7900 peaks takes 7.8 s\n",
      "process 7950 peaks takes 7.8 s\n",
      "process 8000 peaks takes 7.9 s\n",
      "process 8050 peaks takes 7.9 s\n",
      "process 8100 peaks takes 8.0 s\n",
      "process 8150 peaks takes 8.0 s\n",
      "process 8200 peaks takes 8.1 s\n",
      "process 8250 peaks takes 8.1 s\n",
      "process 8300 peaks takes 8.2 s\n",
      "process 8350 peaks takes 8.2 s\n",
      "process 8400 peaks takes 8.3 s\n",
      "process 8450 peaks takes 8.3 s\n",
      "process 8500 peaks takes 8.4 s\n",
      "process 8550 peaks takes 8.4 s\n",
      "process 8600 peaks takes 8.5 s\n",
      "process 8650 peaks takes 8.5 s\n",
      "process 8700 peaks takes 8.6 s\n",
      "process 8750 peaks takes 8.6 s\n",
      "process 8800 peaks takes 8.7 s\n",
      "process 8850 peaks takes 8.7 s\n",
      "process 8900 peaks takes 8.8 s\n",
      "process 8950 peaks takes 8.8 s\n",
      "process 9000 peaks takes 8.9 s\n",
      "process 9050 peaks takes 8.9 s\n",
      "process 9100 peaks takes 9.0 s\n",
      "process 9150 peaks takes 9.0 s\n",
      "process 9200 peaks takes 9.1 s\n",
      "process 9250 peaks takes 9.1 s\n",
      "process 9300 peaks takes 9.2 s\n",
      "process 9350 peaks takes 9.2 s\n",
      "process 9400 peaks takes 9.3 s\n",
      "process 9450 peaks takes 9.3 s\n",
      "process 9500 peaks takes 9.4 s\n",
      "process 9550 peaks takes 9.4 s\n",
      "process 9600 peaks takes 9.5 s\n",
      "process 9650 peaks takes 9.5 s\n",
      "process 9700 peaks takes 9.6 s\n",
      "process 9750 peaks takes 9.6 s\n",
      "process 9800 peaks takes 9.7 s\n",
      "process 9850 peaks takes 9.8 s\n",
      "process 9900 peaks takes 9.8 s\n",
      "process 9950 peaks takes 9.9 s\n",
      "process 10000 peaks takes 9.9 s\n",
      "process 10050 peaks takes 10.0 s\n",
      "process 10100 peaks takes 10.0 s\n",
      "process 10150 peaks takes 10.1 s\n",
      "process 10200 peaks takes 10.1 s\n",
      "process 10250 peaks takes 10.2 s\n",
      "process 10300 peaks takes 10.2 s\n",
      "process 10350 peaks takes 10.3 s\n",
      "process 10400 peaks takes 10.3 s\n",
      "process 10450 peaks takes 10.4 s\n",
      "process 10500 peaks takes 10.4 s\n",
      "process 10550 peaks takes 10.5 s\n",
      "process 10600 peaks takes 10.5 s\n",
      "process 10650 peaks takes 10.6 s\n",
      "process 10700 peaks takes 10.6 s\n",
      "process 10750 peaks takes 10.6 s\n",
      "process 10800 peaks takes 10.7 s\n",
      "process 10850 peaks takes 10.8 s\n",
      "process 10900 peaks takes 10.8 s\n",
      "process 10950 peaks takes 10.9 s\n",
      "process 11000 peaks takes 10.9 s\n",
      "process 11050 peaks takes 11.0 s\n",
      "process 11100 peaks takes 11.0 s\n",
      "process 11150 peaks takes 11.1 s\n",
      "process 11200 peaks takes 11.1 s\n",
      "process 11250 peaks takes 11.2 s\n",
      "process 11300 peaks takes 11.2 s\n",
      "process 11350 peaks takes 11.3 s\n",
      "process 11400 peaks takes 11.3 s\n",
      "process 11450 peaks takes 11.4 s\n",
      "process 11500 peaks takes 11.4 s\n",
      "process 11550 peaks takes 11.5 s\n",
      "process 11600 peaks takes 11.5 s\n",
      "process 11650 peaks takes 11.6 s\n",
      "process 11700 peaks takes 11.6 s\n",
      "process 11750 peaks takes 11.7 s\n",
      "process 11800 peaks takes 11.7 s\n",
      "process 11850 peaks takes 11.8 s\n",
      "process 11900 peaks takes 11.8 s\n",
      "process 11950 peaks takes 11.9 s\n",
      "process 12000 peaks takes 11.9 s\n",
      "process 12050 peaks takes 11.9 s\n",
      "process 12100 peaks takes 12.0 s\n",
      "process 12150 peaks takes 12.0 s\n",
      "process 12200 peaks takes 12.1 s\n",
      "process 12250 peaks takes 12.1 s\n",
      "process 12300 peaks takes 12.2 s\n",
      "process 12350 peaks takes 12.2 s\n",
      "process 12400 peaks takes 12.3 s\n",
      "process 12450 peaks takes 12.3 s\n",
      "process 12500 peaks takes 12.4 s\n",
      "process 12550 peaks takes 12.4 s\n",
      "process 12600 peaks takes 12.5 s\n",
      "process 12650 peaks takes 12.6 s\n",
      "process 12700 peaks takes 12.6 s\n",
      "process 12750 peaks takes 12.6 s\n",
      "process 12800 peaks takes 12.7 s\n",
      "process 12850 peaks takes 12.7 s\n",
      "process 12900 peaks takes 12.8 s\n",
      "process 12950 peaks takes 12.8 s\n",
      "process 13000 peaks takes 12.9 s\n",
      "process 13050 peaks takes 12.9 s\n",
      "process 13100 peaks takes 13.0 s\n",
      "process 13150 peaks takes 13.1 s\n",
      "process 13200 peaks takes 13.1 s\n",
      "process 13250 peaks takes 13.2 s\n",
      "process 13300 peaks takes 13.2 s\n",
      "process 13350 peaks takes 13.3 s\n",
      "process 13400 peaks takes 13.3 s\n",
      "process 13450 peaks takes 13.4 s\n",
      "\n",
      "test\n",
      "750 15\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "\n",
      "val\n",
      "749 14\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs5000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs5000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:32:02.864231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:32:02.988506: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:32:02.992339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:02.992378: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:32:03.729993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:03.730104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:03.730139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:32:05.761511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:32:05.761638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.761723: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.761773: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.761826: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.761875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.761940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.761990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.762039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:32:05.762060: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:32:05.762445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 5000)      165000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 5000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,684,810\n",
      "Trainable params: 4,678,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "106/106 [==============================] - 186s 2s/step - loss: 0.1302 - auc: 0.5001 - auc_1: 0.0067 - val_loss: 0.0413 - val_auc: 0.4730 - val_auc_1: 0.0092\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs5000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "pancreatic_endocrinogenesis episcanpy /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs10000_e1/poisson\n",
      "mm10\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "(10000, 30000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000 --batch 50\n",
      "2024-05-13 07:35:16.237675: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:35:16.347660: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:35:16.351264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:35:16.351298: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:35:16.870249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:35:16.870347: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:35:16.870355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[27001, 1500, 1499]\n",
      "30000 600\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.3 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.8 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 1.9 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.0 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.1 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.2 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.3 s\n",
      "process 2450 peaks takes 2.4 s\n",
      "process 2500 peaks takes 2.4 s\n",
      "process 2550 peaks takes 2.4 s\n",
      "process 2600 peaks takes 2.5 s\n",
      "process 2650 peaks takes 2.5 s\n",
      "process 2700 peaks takes 2.6 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.7 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.8 s\n",
      "process 2950 peaks takes 2.8 s\n",
      "process 3000 peaks takes 2.9 s\n",
      "process 3050 peaks takes 2.9 s\n",
      "process 3100 peaks takes 3.0 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.1 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.2 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.3 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.4 s\n",
      "process 3600 peaks takes 3.5 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.6 s\n",
      "process 3750 peaks takes 3.6 s\n",
      "process 3800 peaks takes 3.7 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.8 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.8 s\n",
      "process 4050 peaks takes 3.9 s\n",
      "process 4100 peaks takes 3.9 s\n",
      "process 4150 peaks takes 4.0 s\n",
      "process 4200 peaks takes 4.0 s\n",
      "process 4250 peaks takes 4.1 s\n",
      "process 4300 peaks takes 4.1 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.2 s\n",
      "process 4450 peaks takes 4.3 s\n",
      "process 4500 peaks takes 4.3 s\n",
      "process 4550 peaks takes 4.4 s\n",
      "process 4600 peaks takes 4.4 s\n",
      "process 4650 peaks takes 4.5 s\n",
      "process 4700 peaks takes 4.5 s\n",
      "process 4750 peaks takes 4.6 s\n",
      "process 4800 peaks takes 4.6 s\n",
      "process 4850 peaks takes 4.7 s\n",
      "process 4900 peaks takes 4.7 s\n",
      "process 4950 peaks takes 4.8 s\n",
      "process 5000 peaks takes 4.8 s\n",
      "process 5050 peaks takes 4.8 s\n",
      "process 5100 peaks takes 4.9 s\n",
      "process 5150 peaks takes 4.9 s\n",
      "process 5200 peaks takes 5.0 s\n",
      "process 5250 peaks takes 5.0 s\n",
      "process 5300 peaks takes 5.1 s\n",
      "process 5350 peaks takes 5.1 s\n",
      "process 5400 peaks takes 5.2 s\n",
      "process 5450 peaks takes 5.2 s\n",
      "process 5500 peaks takes 5.3 s\n",
      "process 5550 peaks takes 5.3 s\n",
      "process 5600 peaks takes 5.3 s\n",
      "process 5650 peaks takes 5.4 s\n",
      "process 5700 peaks takes 5.4 s\n",
      "process 5750 peaks takes 5.5 s\n",
      "process 5800 peaks takes 5.5 s\n",
      "process 5850 peaks takes 5.6 s\n",
      "process 5900 peaks takes 5.6 s\n",
      "process 5950 peaks takes 5.6 s\n",
      "process 6000 peaks takes 5.7 s\n",
      "process 6050 peaks takes 5.8 s\n",
      "process 6100 peaks takes 5.8 s\n",
      "process 6150 peaks takes 5.8 s\n",
      "process 6200 peaks takes 5.9 s\n",
      "process 6250 peaks takes 5.9 s\n",
      "process 6300 peaks takes 6.0 s\n",
      "process 6350 peaks takes 6.0 s\n",
      "process 6400 peaks takes 6.1 s\n",
      "process 6450 peaks takes 6.1 s\n",
      "process 6500 peaks takes 6.2 s\n",
      "process 6550 peaks takes 6.2 s\n",
      "process 6600 peaks takes 6.2 s\n",
      "process 6650 peaks takes 6.3 s\n",
      "process 6700 peaks takes 6.3 s\n",
      "process 6750 peaks takes 6.4 s\n",
      "process 6800 peaks takes 6.4 s\n",
      "process 6850 peaks takes 6.5 s\n",
      "process 6900 peaks takes 6.5 s\n",
      "process 6950 peaks takes 6.6 s\n",
      "process 7000 peaks takes 6.6 s\n",
      "process 7050 peaks takes 6.7 s\n",
      "process 7100 peaks takes 6.7 s\n",
      "process 7150 peaks takes 6.7 s\n",
      "process 7200 peaks takes 6.8 s\n",
      "process 7250 peaks takes 6.8 s\n",
      "process 7300 peaks takes 6.9 s\n",
      "process 7350 peaks takes 6.9 s\n",
      "process 7400 peaks takes 7.0 s\n",
      "process 7450 peaks takes 7.0 s\n",
      "process 7500 peaks takes 7.1 s\n",
      "process 7550 peaks takes 7.1 s\n",
      "process 7600 peaks takes 7.1 s\n",
      "process 7650 peaks takes 7.2 s\n",
      "process 7700 peaks takes 7.2 s\n",
      "process 7750 peaks takes 7.3 s\n",
      "process 7800 peaks takes 7.3 s\n",
      "process 7850 peaks takes 7.4 s\n",
      "process 7900 peaks takes 7.4 s\n",
      "process 7950 peaks takes 7.4 s\n",
      "process 8000 peaks takes 7.5 s\n",
      "process 8050 peaks takes 7.5 s\n",
      "process 8100 peaks takes 7.6 s\n",
      "process 8150 peaks takes 7.6 s\n",
      "process 8200 peaks takes 7.7 s\n",
      "process 8250 peaks takes 7.7 s\n",
      "process 8300 peaks takes 7.8 s\n",
      "process 8350 peaks takes 7.8 s\n",
      "process 8400 peaks takes 7.8 s\n",
      "process 8450 peaks takes 7.9 s\n",
      "process 8500 peaks takes 7.9 s\n",
      "process 8550 peaks takes 8.0 s\n",
      "process 8600 peaks takes 8.0 s\n",
      "process 8650 peaks takes 8.1 s\n",
      "process 8700 peaks takes 8.1 s\n",
      "process 8750 peaks takes 8.2 s\n",
      "process 8800 peaks takes 8.2 s\n",
      "process 8850 peaks takes 8.3 s\n",
      "process 8900 peaks takes 8.3 s\n",
      "process 8950 peaks takes 8.4 s\n",
      "process 9000 peaks takes 8.4 s\n",
      "process 9050 peaks takes 8.5 s\n",
      "process 9100 peaks takes 8.5 s\n",
      "process 9150 peaks takes 8.6 s\n",
      "process 9200 peaks takes 8.6 s\n",
      "process 9250 peaks takes 8.7 s\n",
      "process 9300 peaks takes 8.7 s\n",
      "process 9350 peaks takes 8.7 s\n",
      "process 9400 peaks takes 8.8 s\n",
      "process 9450 peaks takes 8.8 s\n",
      "process 9500 peaks takes 8.9 s\n",
      "process 9550 peaks takes 8.9 s\n",
      "process 9600 peaks takes 9.0 s\n",
      "process 9650 peaks takes 9.0 s\n",
      "process 9700 peaks takes 9.0 s\n",
      "process 9750 peaks takes 9.1 s\n",
      "process 9800 peaks takes 9.1 s\n",
      "process 9850 peaks takes 9.2 s\n",
      "process 9900 peaks takes 9.2 s\n",
      "process 9950 peaks takes 9.3 s\n",
      "process 10000 peaks takes 9.3 s\n",
      "process 10050 peaks takes 9.4 s\n",
      "process 10100 peaks takes 9.4 s\n",
      "process 10150 peaks takes 9.4 s\n",
      "process 10200 peaks takes 9.5 s\n",
      "process 10250 peaks takes 9.5 s\n",
      "process 10300 peaks takes 9.6 s\n",
      "process 10350 peaks takes 9.6 s\n",
      "process 10400 peaks takes 9.7 s\n",
      "process 10450 peaks takes 9.7 s\n",
      "process 10500 peaks takes 9.8 s\n",
      "process 10550 peaks takes 9.8 s\n",
      "process 10600 peaks takes 9.8 s\n",
      "process 10650 peaks takes 9.9 s\n",
      "process 10700 peaks takes 9.9 s\n",
      "process 10750 peaks takes 10.0 s\n",
      "process 10800 peaks takes 10.0 s\n",
      "process 10850 peaks takes 10.1 s\n",
      "process 10900 peaks takes 10.1 s\n",
      "process 10950 peaks takes 10.2 s\n",
      "process 11000 peaks takes 10.2 s\n",
      "process 11050 peaks takes 10.3 s\n",
      "process 11100 peaks takes 10.3 s\n",
      "process 11150 peaks takes 10.3 s\n",
      "process 11200 peaks takes 10.4 s\n",
      "process 11250 peaks takes 10.4 s\n",
      "process 11300 peaks takes 10.5 s\n",
      "process 11350 peaks takes 10.5 s\n",
      "process 11400 peaks takes 10.6 s\n",
      "process 11450 peaks takes 10.6 s\n",
      "process 11500 peaks takes 10.7 s\n",
      "process 11550 peaks takes 10.7 s\n",
      "process 11600 peaks takes 10.8 s\n",
      "process 11650 peaks takes 10.8 s\n",
      "process 11700 peaks takes 10.8 s\n",
      "process 11750 peaks takes 10.9 s\n",
      "process 11800 peaks takes 10.9 s\n",
      "process 11850 peaks takes 11.0 s\n",
      "process 11900 peaks takes 11.0 s\n",
      "process 11950 peaks takes 11.1 s\n",
      "process 12000 peaks takes 11.1 s\n",
      "process 12050 peaks takes 11.2 s\n",
      "process 12100 peaks takes 11.2 s\n",
      "process 12150 peaks takes 11.3 s\n",
      "process 12200 peaks takes 11.3 s\n",
      "process 12250 peaks takes 11.4 s\n",
      "process 12300 peaks takes 11.4 s\n",
      "process 12350 peaks takes 11.4 s\n",
      "process 12400 peaks takes 11.5 s\n",
      "process 12450 peaks takes 11.5 s\n",
      "process 12500 peaks takes 11.6 s\n",
      "process 12550 peaks takes 11.6 s\n",
      "process 12600 peaks takes 11.7 s\n",
      "process 12650 peaks takes 11.8 s\n",
      "process 12700 peaks takes 11.8 s\n",
      "process 12750 peaks takes 11.8 s\n",
      "process 12800 peaks takes 11.9 s\n",
      "process 12850 peaks takes 11.9 s\n",
      "process 12900 peaks takes 12.0 s\n",
      "process 12950 peaks takes 12.0 s\n",
      "process 13000 peaks takes 12.1 s\n",
      "process 13050 peaks takes 12.1 s\n",
      "process 13100 peaks takes 12.2 s\n",
      "process 13150 peaks takes 12.2 s\n",
      "process 13200 peaks takes 12.3 s\n",
      "process 13250 peaks takes 12.3 s\n",
      "process 13300 peaks takes 12.4 s\n",
      "process 13350 peaks takes 12.4 s\n",
      "process 13400 peaks takes 12.5 s\n",
      "process 13450 peaks takes 12.5 s\n",
      "process 13500 peaks takes 12.6 s\n",
      "process 13550 peaks takes 12.6 s\n",
      "process 13600 peaks takes 12.6 s\n",
      "process 13650 peaks takes 12.7 s\n",
      "process 13700 peaks takes 12.8 s\n",
      "process 13750 peaks takes 12.8 s\n",
      "process 13800 peaks takes 12.8 s\n",
      "process 13850 peaks takes 12.9 s\n",
      "process 13900 peaks takes 12.9 s\n",
      "process 13950 peaks takes 13.0 s\n",
      "process 14000 peaks takes 13.0 s\n",
      "process 14050 peaks takes 13.1 s\n",
      "process 14100 peaks takes 13.1 s\n",
      "process 14150 peaks takes 13.1 s\n",
      "process 14200 peaks takes 13.2 s\n",
      "process 14250 peaks takes 13.2 s\n",
      "process 14300 peaks takes 13.3 s\n",
      "process 14350 peaks takes 13.3 s\n",
      "process 14400 peaks takes 13.4 s\n",
      "process 14450 peaks takes 13.4 s\n",
      "process 14500 peaks takes 13.5 s\n",
      "process 14550 peaks takes 13.5 s\n",
      "process 14600 peaks takes 13.5 s\n",
      "process 14650 peaks takes 13.6 s\n",
      "process 14700 peaks takes 13.6 s\n",
      "process 14750 peaks takes 13.7 s\n",
      "process 14800 peaks takes 13.7 s\n",
      "process 14850 peaks takes 13.8 s\n",
      "process 14900 peaks takes 13.8 s\n",
      "process 14950 peaks takes 13.9 s\n",
      "process 15000 peaks takes 13.9 s\n",
      "process 15050 peaks takes 14.0 s\n",
      "process 15100 peaks takes 14.0 s\n",
      "process 15150 peaks takes 14.0 s\n",
      "process 15200 peaks takes 14.1 s\n",
      "process 15250 peaks takes 14.1 s\n",
      "process 15300 peaks takes 14.2 s\n",
      "process 15350 peaks takes 14.2 s\n",
      "process 15400 peaks takes 14.3 s\n",
      "process 15450 peaks takes 14.3 s\n",
      "process 15500 peaks takes 14.4 s\n",
      "process 15550 peaks takes 14.4 s\n",
      "process 15600 peaks takes 14.5 s\n",
      "process 15650 peaks takes 14.5 s\n",
      "process 15700 peaks takes 14.5 s\n",
      "process 15750 peaks takes 14.6 s\n",
      "process 15800 peaks takes 14.6 s\n",
      "process 15850 peaks takes 14.7 s\n",
      "process 15900 peaks takes 14.7 s\n",
      "process 15950 peaks takes 14.8 s\n",
      "process 16000 peaks takes 14.8 s\n",
      "process 16050 peaks takes 14.9 s\n",
      "process 16100 peaks takes 14.9 s\n",
      "process 16150 peaks takes 15.0 s\n",
      "process 16200 peaks takes 15.0 s\n",
      "process 16250 peaks takes 15.1 s\n",
      "process 16300 peaks takes 15.1 s\n",
      "process 16350 peaks takes 15.1 s\n",
      "process 16400 peaks takes 15.2 s\n",
      "process 16450 peaks takes 15.2 s\n",
      "process 16500 peaks takes 15.3 s\n",
      "process 16550 peaks takes 15.3 s\n",
      "process 16600 peaks takes 15.4 s\n",
      "process 16650 peaks takes 15.4 s\n",
      "process 16700 peaks takes 15.5 s\n",
      "process 16750 peaks takes 15.5 s\n",
      "process 16800 peaks takes 15.6 s\n",
      "process 16850 peaks takes 15.6 s\n",
      "process 16900 peaks takes 15.7 s\n",
      "process 16950 peaks takes 15.7 s\n",
      "process 17000 peaks takes 15.8 s\n",
      "process 17050 peaks takes 15.8 s\n",
      "process 17100 peaks takes 15.9 s\n",
      "process 17150 peaks takes 15.9 s\n",
      "process 17200 peaks takes 16.0 s\n",
      "process 17250 peaks takes 16.0 s\n",
      "process 17300 peaks takes 16.0 s\n",
      "process 17350 peaks takes 16.1 s\n",
      "process 17400 peaks takes 16.1 s\n",
      "process 17450 peaks takes 16.2 s\n",
      "process 17500 peaks takes 16.2 s\n",
      "process 17550 peaks takes 16.3 s\n",
      "process 17600 peaks takes 16.3 s\n",
      "process 17650 peaks takes 16.4 s\n",
      "process 17700 peaks takes 16.4 s\n",
      "process 17750 peaks takes 16.5 s\n",
      "process 17800 peaks takes 16.5 s\n",
      "process 17850 peaks takes 16.5 s\n",
      "process 17900 peaks takes 16.6 s\n",
      "process 17950 peaks takes 16.6 s\n",
      "process 18000 peaks takes 16.7 s\n",
      "process 18050 peaks takes 16.7 s\n",
      "process 18100 peaks takes 16.8 s\n",
      "process 18150 peaks takes 16.8 s\n",
      "process 18200 peaks takes 16.9 s\n",
      "process 18250 peaks takes 16.9 s\n",
      "process 18300 peaks takes 17.0 s\n",
      "process 18350 peaks takes 17.0 s\n",
      "process 18400 peaks takes 17.0 s\n",
      "process 18450 peaks takes 17.1 s\n",
      "process 18500 peaks takes 17.2 s\n",
      "process 18550 peaks takes 17.2 s\n",
      "process 18600 peaks takes 17.2 s\n",
      "process 18650 peaks takes 17.3 s\n",
      "process 18700 peaks takes 17.3 s\n",
      "process 18750 peaks takes 17.4 s\n",
      "process 18800 peaks takes 17.4 s\n",
      "process 18850 peaks takes 17.5 s\n",
      "process 18900 peaks takes 17.5 s\n",
      "process 18950 peaks takes 17.5 s\n",
      "process 19000 peaks takes 17.6 s\n",
      "process 19050 peaks takes 17.6 s\n",
      "process 19100 peaks takes 17.7 s\n",
      "process 19150 peaks takes 17.8 s\n",
      "process 19200 peaks takes 17.8 s\n",
      "process 19250 peaks takes 17.9 s\n",
      "process 19300 peaks takes 17.9 s\n",
      "process 19350 peaks takes 18.0 s\n",
      "process 19400 peaks takes 18.0 s\n",
      "process 19450 peaks takes 18.1 s\n",
      "process 19500 peaks takes 18.1 s\n",
      "process 19550 peaks takes 18.1 s\n",
      "process 19600 peaks takes 18.2 s\n",
      "process 19650 peaks takes 18.2 s\n",
      "process 19700 peaks takes 18.3 s\n",
      "process 19750 peaks takes 18.3 s\n",
      "process 19800 peaks takes 18.4 s\n",
      "process 19850 peaks takes 18.4 s\n",
      "process 19900 peaks takes 18.4 s\n",
      "process 19950 peaks takes 18.5 s\n",
      "process 20000 peaks takes 18.5 s\n",
      "process 20050 peaks takes 18.6 s\n",
      "process 20100 peaks takes 18.6 s\n",
      "process 20150 peaks takes 18.7 s\n",
      "process 20200 peaks takes 18.7 s\n",
      "process 20250 peaks takes 18.8 s\n",
      "process 20300 peaks takes 18.8 s\n",
      "process 20350 peaks takes 18.9 s\n",
      "process 20400 peaks takes 18.9 s\n",
      "process 20450 peaks takes 19.0 s\n",
      "process 20500 peaks takes 19.0 s\n",
      "process 20550 peaks takes 19.1 s\n",
      "process 20600 peaks takes 19.1 s\n",
      "process 20650 peaks takes 19.2 s\n",
      "process 20700 peaks takes 19.2 s\n",
      "process 20750 peaks takes 19.2 s\n",
      "process 20800 peaks takes 19.3 s\n",
      "process 20850 peaks takes 19.4 s\n",
      "process 20900 peaks takes 19.4 s\n",
      "process 20950 peaks takes 19.5 s\n",
      "process 21000 peaks takes 19.5 s\n",
      "process 21050 peaks takes 19.6 s\n",
      "process 21100 peaks takes 19.6 s\n",
      "process 21150 peaks takes 19.6 s\n",
      "process 21200 peaks takes 19.7 s\n",
      "process 21250 peaks takes 19.7 s\n",
      "process 21300 peaks takes 19.8 s\n",
      "process 21350 peaks takes 19.8 s\n",
      "process 21400 peaks takes 19.9 s\n",
      "process 21450 peaks takes 19.9 s\n",
      "process 21500 peaks takes 19.9 s\n",
      "process 21550 peaks takes 20.0 s\n",
      "process 21600 peaks takes 20.0 s\n",
      "process 21650 peaks takes 20.1 s\n",
      "process 21700 peaks takes 20.1 s\n",
      "process 21750 peaks takes 20.2 s\n",
      "process 21800 peaks takes 20.2 s\n",
      "process 21850 peaks takes 20.2 s\n",
      "process 21900 peaks takes 20.3 s\n",
      "process 21950 peaks takes 20.3 s\n",
      "process 22000 peaks takes 20.4 s\n",
      "process 22050 peaks takes 20.4 s\n",
      "process 22100 peaks takes 20.5 s\n",
      "process 22150 peaks takes 20.5 s\n",
      "process 22200 peaks takes 20.6 s\n",
      "process 22250 peaks takes 20.6 s\n",
      "process 22300 peaks takes 20.7 s\n",
      "process 22350 peaks takes 20.7 s\n",
      "process 22400 peaks takes 20.8 s\n",
      "process 22450 peaks takes 20.8 s\n",
      "process 22500 peaks takes 20.9 s\n",
      "process 22550 peaks takes 20.9 s\n",
      "process 22600 peaks takes 20.9 s\n",
      "process 22650 peaks takes 21.0 s\n",
      "process 22700 peaks takes 21.0 s\n",
      "process 22750 peaks takes 21.1 s\n",
      "process 22800 peaks takes 21.1 s\n",
      "process 22850 peaks takes 21.2 s\n",
      "process 22900 peaks takes 21.2 s\n",
      "process 22950 peaks takes 21.3 s\n",
      "process 23000 peaks takes 21.3 s\n",
      "process 23050 peaks takes 21.4 s\n",
      "process 23100 peaks takes 21.4 s\n",
      "process 23150 peaks takes 21.5 s\n",
      "process 23200 peaks takes 21.5 s\n",
      "process 23250 peaks takes 21.5 s\n",
      "process 23300 peaks takes 21.6 s\n",
      "process 23350 peaks takes 21.7 s\n",
      "process 23400 peaks takes 21.7 s\n",
      "process 23450 peaks takes 21.7 s\n",
      "process 23500 peaks takes 21.8 s\n",
      "process 23550 peaks takes 21.8 s\n",
      "process 23600 peaks takes 21.9 s\n",
      "process 23650 peaks takes 21.9 s\n",
      "process 23700 peaks takes 22.0 s\n",
      "process 23750 peaks takes 22.0 s\n",
      "process 23800 peaks takes 22.1 s\n",
      "process 23850 peaks takes 22.1 s\n",
      "process 23900 peaks takes 22.2 s\n",
      "process 23950 peaks takes 22.2 s\n",
      "process 24000 peaks takes 22.3 s\n",
      "process 24050 peaks takes 22.3 s\n",
      "process 24100 peaks takes 22.4 s\n",
      "process 24150 peaks takes 22.4 s\n",
      "process 24200 peaks takes 22.5 s\n",
      "process 24250 peaks takes 22.5 s\n",
      "process 24300 peaks takes 22.6 s\n",
      "process 24350 peaks takes 22.6 s\n",
      "process 24400 peaks takes 22.7 s\n",
      "process 24450 peaks takes 22.7 s\n",
      "process 24500 peaks takes 22.8 s\n",
      "process 24550 peaks takes 22.8 s\n",
      "process 24600 peaks takes 22.8 s\n",
      "process 24650 peaks takes 22.9 s\n",
      "process 24700 peaks takes 22.9 s\n",
      "process 24750 peaks takes 23.0 s\n",
      "process 24800 peaks takes 23.0 s\n",
      "process 24850 peaks takes 23.1 s\n",
      "process 24900 peaks takes 23.1 s\n",
      "process 24950 peaks takes 23.2 s\n",
      "process 25000 peaks takes 23.2 s\n",
      "process 25050 peaks takes 23.3 s\n",
      "process 25100 peaks takes 23.3 s\n",
      "process 25150 peaks takes 23.3 s\n",
      "process 25200 peaks takes 23.4 s\n",
      "process 25250 peaks takes 23.4 s\n",
      "process 25300 peaks takes 23.5 s\n",
      "process 25350 peaks takes 23.5 s\n",
      "process 25400 peaks takes 23.6 s\n",
      "process 25450 peaks takes 23.6 s\n",
      "process 25500 peaks takes 23.6 s\n",
      "process 25550 peaks takes 23.7 s\n",
      "process 25600 peaks takes 23.7 s\n",
      "process 25650 peaks takes 23.8 s\n",
      "process 25700 peaks takes 23.8 s\n",
      "process 25750 peaks takes 23.9 s\n",
      "process 25800 peaks takes 23.9 s\n",
      "process 25850 peaks takes 24.0 s\n",
      "process 25900 peaks takes 24.1 s\n",
      "process 25950 peaks takes 24.1 s\n",
      "process 26000 peaks takes 24.1 s\n",
      "process 26050 peaks takes 24.2 s\n",
      "process 26100 peaks takes 24.2 s\n",
      "process 26150 peaks takes 24.3 s\n",
      "process 26200 peaks takes 24.3 s\n",
      "process 26250 peaks takes 24.4 s\n",
      "process 26300 peaks takes 24.5 s\n",
      "process 26350 peaks takes 24.5 s\n",
      "process 26400 peaks takes 24.5 s\n",
      "process 26450 peaks takes 24.6 s\n",
      "process 26500 peaks takes 24.6 s\n",
      "process 26550 peaks takes 24.7 s\n",
      "process 26600 peaks takes 24.7 s\n",
      "process 26650 peaks takes 24.8 s\n",
      "process 26700 peaks takes 24.8 s\n",
      "process 26750 peaks takes 24.9 s\n",
      "process 26800 peaks takes 24.9 s\n",
      "process 26850 peaks takes 25.0 s\n",
      "process 26900 peaks takes 25.0 s\n",
      "process 26950 peaks takes 25.1 s\n",
      "process 27000 peaks takes 25.1 s\n",
      "process 27050 peaks takes 25.2 s\n",
      "process 27100 peaks takes 25.2 s\n",
      "process 27150 peaks takes 25.3 s\n",
      "process 27200 peaks takes 25.3 s\n",
      "process 27250 peaks takes 25.4 s\n",
      "process 27300 peaks takes 25.4 s\n",
      "process 27350 peaks takes 25.5 s\n",
      "process 27400 peaks takes 25.5 s\n",
      "process 27450 peaks takes 25.6 s\n",
      "process 27500 peaks takes 25.6 s\n",
      "process 27550 peaks takes 25.7 s\n",
      "process 27600 peaks takes 25.7 s\n",
      "process 27650 peaks takes 25.8 s\n",
      "process 27700 peaks takes 25.8 s\n",
      "process 27750 peaks takes 25.9 s\n",
      "process 27800 peaks takes 25.9 s\n",
      "process 27850 peaks takes 26.0 s\n",
      "process 27900 peaks takes 26.0 s\n",
      "process 27950 peaks takes 26.1 s\n",
      "process 28000 peaks takes 26.1 s\n",
      "process 28050 peaks takes 26.2 s\n",
      "process 28100 peaks takes 26.2 s\n",
      "process 28150 peaks takes 26.3 s\n",
      "process 28200 peaks takes 26.3 s\n",
      "process 28250 peaks takes 26.4 s\n",
      "process 28300 peaks takes 26.4 s\n",
      "process 28350 peaks takes 26.5 s\n",
      "process 28400 peaks takes 26.5 s\n",
      "process 28450 peaks takes 26.6 s\n",
      "process 28500 peaks takes 26.7 s\n",
      "process 28550 peaks takes 26.7 s\n",
      "process 28600 peaks takes 26.8 s\n",
      "process 28650 peaks takes 26.8 s\n",
      "process 28700 peaks takes 26.9 s\n",
      "process 28750 peaks takes 26.9 s\n",
      "process 28800 peaks takes 27.0 s\n",
      "process 28850 peaks takes 27.0 s\n",
      "process 28900 peaks takes 27.1 s\n",
      "process 28950 peaks takes 27.1 s\n",
      "process 29000 peaks takes 27.2 s\n",
      "process 29050 peaks takes 27.2 s\n",
      "process 29100 peaks takes 27.3 s\n",
      "process 29150 peaks takes 27.3 s\n",
      "process 29200 peaks takes 27.4 s\n",
      "process 29250 peaks takes 27.4 s\n",
      "process 29300 peaks takes 27.5 s\n",
      "process 29350 peaks takes 27.5 s\n",
      "process 29400 peaks takes 27.6 s\n",
      "process 29450 peaks takes 27.6 s\n",
      "process 29500 peaks takes 27.7 s\n",
      "process 29550 peaks takes 27.8 s\n",
      "process 29600 peaks takes 27.8 s\n",
      "process 29650 peaks takes 27.9 s\n",
      "process 29700 peaks takes 27.9 s\n",
      "process 29750 peaks takes 28.0 s\n",
      "process 29800 peaks takes 28.1 s\n",
      "process 29850 peaks takes 28.1 s\n",
      "process 29900 peaks takes 28.2 s\n",
      "process 29950 peaks takes 28.2 s\n",
      "\n",
      "train\n",
      "27001 540\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.4 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.7 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.8 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 1.9 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.0 s\n",
      "process 2000 peaks takes 2.1 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.2 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.3 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.4 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.9 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 3.0 s\n",
      "process 3000 peaks takes 3.0 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.2 s\n",
      "process 3200 peaks takes 3.2 s\n",
      "process 3250 peaks takes 3.3 s\n",
      "process 3300 peaks takes 3.3 s\n",
      "process 3350 peaks takes 3.4 s\n",
      "process 3400 peaks takes 3.4 s\n",
      "process 3450 peaks takes 3.5 s\n",
      "process 3500 peaks takes 3.5 s\n",
      "process 3550 peaks takes 3.6 s\n",
      "process 3600 peaks takes 3.6 s\n",
      "process 3650 peaks takes 3.7 s\n",
      "process 3700 peaks takes 3.7 s\n",
      "process 3750 peaks takes 3.8 s\n",
      "process 3800 peaks takes 3.8 s\n",
      "process 3850 peaks takes 3.9 s\n",
      "process 3900 peaks takes 3.9 s\n",
      "process 3950 peaks takes 4.0 s\n",
      "process 4000 peaks takes 4.0 s\n",
      "process 4050 peaks takes 4.1 s\n",
      "process 4100 peaks takes 4.1 s\n",
      "process 4150 peaks takes 4.2 s\n",
      "process 4200 peaks takes 4.2 s\n",
      "process 4250 peaks takes 4.3 s\n",
      "process 4300 peaks takes 4.3 s\n",
      "process 4350 peaks takes 4.4 s\n",
      "process 4400 peaks takes 4.5 s\n",
      "process 4450 peaks takes 4.5 s\n",
      "process 4500 peaks takes 4.6 s\n",
      "process 4550 peaks takes 4.6 s\n",
      "process 4600 peaks takes 4.7 s\n",
      "process 4650 peaks takes 4.7 s\n",
      "process 4700 peaks takes 4.8 s\n",
      "process 4750 peaks takes 4.8 s\n",
      "process 4800 peaks takes 4.9 s\n",
      "process 4850 peaks takes 4.9 s\n",
      "process 4900 peaks takes 5.0 s\n",
      "process 4950 peaks takes 5.0 s\n",
      "process 5000 peaks takes 5.1 s\n",
      "process 5050 peaks takes 5.1 s\n",
      "process 5100 peaks takes 5.2 s\n",
      "process 5150 peaks takes 5.2 s\n",
      "process 5200 peaks takes 5.3 s\n",
      "process 5250 peaks takes 5.3 s\n",
      "process 5300 peaks takes 5.4 s\n",
      "process 5350 peaks takes 5.4 s\n",
      "process 5400 peaks takes 5.5 s\n",
      "process 5450 peaks takes 5.5 s\n",
      "process 5500 peaks takes 5.6 s\n",
      "process 5550 peaks takes 5.6 s\n",
      "process 5600 peaks takes 5.7 s\n",
      "process 5650 peaks takes 5.7 s\n",
      "process 5700 peaks takes 5.8 s\n",
      "process 5750 peaks takes 5.8 s\n",
      "process 5800 peaks takes 5.9 s\n",
      "process 5850 peaks takes 5.9 s\n",
      "process 5900 peaks takes 6.0 s\n",
      "process 5950 peaks takes 6.0 s\n",
      "process 6000 peaks takes 6.1 s\n",
      "process 6050 peaks takes 6.1 s\n",
      "process 6100 peaks takes 6.2 s\n",
      "process 6150 peaks takes 6.3 s\n",
      "process 6200 peaks takes 6.3 s\n",
      "process 6250 peaks takes 6.3 s\n",
      "process 6300 peaks takes 6.4 s\n",
      "process 6350 peaks takes 6.4 s\n",
      "process 6400 peaks takes 6.5 s\n",
      "process 6450 peaks takes 6.5 s\n",
      "process 6500 peaks takes 6.6 s\n",
      "process 6550 peaks takes 6.6 s\n",
      "process 6600 peaks takes 6.7 s\n",
      "process 6650 peaks takes 6.7 s\n",
      "process 6700 peaks takes 6.7 s\n",
      "process 6750 peaks takes 6.8 s\n",
      "process 6800 peaks takes 6.8 s\n",
      "process 6850 peaks takes 6.9 s\n",
      "process 6900 peaks takes 6.9 s\n",
      "process 6950 peaks takes 6.9 s\n",
      "process 7000 peaks takes 7.0 s\n",
      "process 7050 peaks takes 7.0 s\n",
      "process 7100 peaks takes 7.1 s\n",
      "process 7150 peaks takes 7.1 s\n",
      "process 7200 peaks takes 7.2 s\n",
      "process 7250 peaks takes 7.2 s\n",
      "process 7300 peaks takes 7.3 s\n",
      "process 7350 peaks takes 7.3 s\n",
      "process 7400 peaks takes 7.3 s\n",
      "process 7450 peaks takes 7.4 s\n",
      "process 7500 peaks takes 7.4 s\n",
      "process 7550 peaks takes 7.5 s\n",
      "process 7600 peaks takes 7.5 s\n",
      "process 7650 peaks takes 7.6 s\n",
      "process 7700 peaks takes 7.6 s\n",
      "process 7750 peaks takes 7.7 s\n",
      "process 7800 peaks takes 7.7 s\n",
      "process 7850 peaks takes 7.8 s\n",
      "process 7900 peaks takes 7.8 s\n",
      "process 7950 peaks takes 7.9 s\n",
      "process 8000 peaks takes 7.9 s\n",
      "process 8050 peaks takes 7.9 s\n",
      "process 8100 peaks takes 8.0 s\n",
      "process 8150 peaks takes 8.0 s\n",
      "process 8200 peaks takes 8.1 s\n",
      "process 8250 peaks takes 8.1 s\n",
      "process 8300 peaks takes 8.2 s\n",
      "process 8350 peaks takes 8.2 s\n",
      "process 8400 peaks takes 8.3 s\n",
      "process 8450 peaks takes 8.3 s\n",
      "process 8500 peaks takes 8.4 s\n",
      "process 8550 peaks takes 8.4 s\n",
      "process 8600 peaks takes 8.5 s\n",
      "process 8650 peaks takes 8.5 s\n",
      "process 8700 peaks takes 8.6 s\n",
      "process 8750 peaks takes 8.6 s\n",
      "process 8800 peaks takes 8.6 s\n",
      "process 8850 peaks takes 8.7 s\n",
      "process 8900 peaks takes 8.7 s\n",
      "process 8950 peaks takes 8.8 s\n",
      "process 9000 peaks takes 8.8 s\n",
      "process 9050 peaks takes 8.8 s\n",
      "process 9100 peaks takes 8.9 s\n",
      "process 9150 peaks takes 8.9 s\n",
      "process 9200 peaks takes 9.0 s\n",
      "process 9250 peaks takes 9.0 s\n",
      "process 9300 peaks takes 9.1 s\n",
      "process 9350 peaks takes 9.1 s\n",
      "process 9400 peaks takes 9.1 s\n",
      "process 9450 peaks takes 9.2 s\n",
      "process 9500 peaks takes 9.3 s\n",
      "process 9550 peaks takes 9.3 s\n",
      "process 9600 peaks takes 9.4 s\n",
      "process 9650 peaks takes 9.4 s\n",
      "process 9700 peaks takes 9.4 s\n",
      "process 9750 peaks takes 9.5 s\n",
      "process 9800 peaks takes 9.5 s\n",
      "process 9850 peaks takes 9.6 s\n",
      "process 9900 peaks takes 9.6 s\n",
      "process 9950 peaks takes 9.7 s\n",
      "process 10000 peaks takes 9.7 s\n",
      "process 10050 peaks takes 9.8 s\n",
      "process 10100 peaks takes 9.8 s\n",
      "process 10150 peaks takes 9.8 s\n",
      "process 10200 peaks takes 9.9 s\n",
      "process 10250 peaks takes 9.9 s\n",
      "process 10300 peaks takes 10.0 s\n",
      "process 10350 peaks takes 10.0 s\n",
      "process 10400 peaks takes 10.1 s\n",
      "process 10450 peaks takes 10.1 s\n",
      "process 10500 peaks takes 10.2 s\n",
      "process 10550 peaks takes 10.2 s\n",
      "process 10600 peaks takes 10.2 s\n",
      "process 10650 peaks takes 10.3 s\n",
      "process 10700 peaks takes 10.3 s\n",
      "process 10750 peaks takes 10.4 s\n",
      "process 10800 peaks takes 10.4 s\n",
      "process 10850 peaks takes 10.5 s\n",
      "process 10900 peaks takes 10.5 s\n",
      "process 10950 peaks takes 10.6 s\n",
      "process 11000 peaks takes 10.6 s\n",
      "process 11050 peaks takes 10.7 s\n",
      "process 11100 peaks takes 10.8 s\n",
      "process 11150 peaks takes 10.8 s\n",
      "process 11200 peaks takes 10.8 s\n",
      "process 11250 peaks takes 10.9 s\n",
      "process 11300 peaks takes 10.9 s\n",
      "process 11350 peaks takes 11.0 s\n",
      "process 11400 peaks takes 11.0 s\n",
      "process 11450 peaks takes 11.0 s\n",
      "process 11500 peaks takes 11.1 s\n",
      "process 11550 peaks takes 11.1 s\n",
      "process 11600 peaks takes 11.2 s\n",
      "process 11650 peaks takes 11.2 s\n",
      "process 11700 peaks takes 11.3 s\n",
      "process 11750 peaks takes 11.3 s\n",
      "process 11800 peaks takes 11.4 s\n",
      "process 11850 peaks takes 11.4 s\n",
      "process 11900 peaks takes 11.4 s\n",
      "process 11950 peaks takes 11.5 s\n",
      "process 12000 peaks takes 11.5 s\n",
      "process 12050 peaks takes 11.6 s\n",
      "process 12100 peaks takes 11.6 s\n",
      "process 12150 peaks takes 11.7 s\n",
      "process 12200 peaks takes 11.7 s\n",
      "process 12250 peaks takes 11.8 s\n",
      "process 12300 peaks takes 11.8 s\n",
      "process 12350 peaks takes 11.9 s\n",
      "process 12400 peaks takes 11.9 s\n",
      "process 12450 peaks takes 11.9 s\n",
      "process 12500 peaks takes 12.0 s\n",
      "process 12550 peaks takes 12.1 s\n",
      "process 12600 peaks takes 12.1 s\n",
      "process 12650 peaks takes 12.1 s\n",
      "process 12700 peaks takes 12.2 s\n",
      "process 12750 peaks takes 12.2 s\n",
      "process 12800 peaks takes 12.3 s\n",
      "process 12850 peaks takes 12.3 s\n",
      "process 12900 peaks takes 12.4 s\n",
      "process 12950 peaks takes 12.4 s\n",
      "process 13000 peaks takes 12.5 s\n",
      "process 13050 peaks takes 12.5 s\n",
      "process 13100 peaks takes 12.5 s\n",
      "process 13150 peaks takes 12.6 s\n",
      "process 13200 peaks takes 12.7 s\n",
      "process 13250 peaks takes 12.7 s\n",
      "process 13300 peaks takes 12.7 s\n",
      "process 13350 peaks takes 12.8 s\n",
      "process 13400 peaks takes 12.8 s\n",
      "process 13450 peaks takes 12.9 s\n",
      "process 13500 peaks takes 12.9 s\n",
      "process 13550 peaks takes 13.0 s\n",
      "process 13600 peaks takes 13.0 s\n",
      "process 13650 peaks takes 13.1 s\n",
      "process 13700 peaks takes 13.1 s\n",
      "process 13750 peaks takes 13.2 s\n",
      "process 13800 peaks takes 13.2 s\n",
      "process 13850 peaks takes 13.3 s\n",
      "process 13900 peaks takes 13.3 s\n",
      "process 13950 peaks takes 13.3 s\n",
      "process 14000 peaks takes 13.4 s\n",
      "process 14050 peaks takes 13.4 s\n",
      "process 14100 peaks takes 13.5 s\n",
      "process 14150 peaks takes 13.6 s\n",
      "process 14200 peaks takes 13.6 s\n",
      "process 14250 peaks takes 13.6 s\n",
      "process 14300 peaks takes 13.7 s\n",
      "process 14350 peaks takes 13.8 s\n",
      "process 14400 peaks takes 13.8 s\n",
      "process 14450 peaks takes 13.8 s\n",
      "process 14500 peaks takes 13.9 s\n",
      "process 14550 peaks takes 13.9 s\n",
      "process 14600 peaks takes 14.0 s\n",
      "process 14650 peaks takes 14.0 s\n",
      "process 14700 peaks takes 14.0 s\n",
      "process 14750 peaks takes 14.1 s\n",
      "process 14800 peaks takes 14.1 s\n",
      "process 14850 peaks takes 14.2 s\n",
      "process 14900 peaks takes 14.2 s\n",
      "process 14950 peaks takes 14.3 s\n",
      "process 15000 peaks takes 14.3 s\n",
      "process 15050 peaks takes 14.4 s\n",
      "process 15100 peaks takes 14.4 s\n",
      "process 15150 peaks takes 14.5 s\n",
      "process 15200 peaks takes 14.5 s\n",
      "process 15250 peaks takes 14.6 s\n",
      "process 15300 peaks takes 14.6 s\n",
      "process 15350 peaks takes 14.7 s\n",
      "process 15400 peaks takes 14.7 s\n",
      "process 15450 peaks takes 14.7 s\n",
      "process 15500 peaks takes 14.8 s\n",
      "process 15550 peaks takes 14.9 s\n",
      "process 15600 peaks takes 14.9 s\n",
      "process 15650 peaks takes 14.9 s\n",
      "process 15700 peaks takes 15.0 s\n",
      "process 15750 peaks takes 15.0 s\n",
      "process 15800 peaks takes 15.1 s\n",
      "process 15850 peaks takes 15.1 s\n",
      "process 15900 peaks takes 15.2 s\n",
      "process 15950 peaks takes 15.2 s\n",
      "process 16000 peaks takes 15.2 s\n",
      "process 16050 peaks takes 15.3 s\n",
      "process 16100 peaks takes 15.3 s\n",
      "process 16150 peaks takes 15.4 s\n",
      "process 16200 peaks takes 15.4 s\n",
      "process 16250 peaks takes 15.5 s\n",
      "process 16300 peaks takes 15.5 s\n",
      "process 16350 peaks takes 15.6 s\n",
      "process 16400 peaks takes 15.6 s\n",
      "process 16450 peaks takes 15.7 s\n",
      "process 16500 peaks takes 15.7 s\n",
      "process 16550 peaks takes 15.7 s\n",
      "process 16600 peaks takes 15.8 s\n",
      "process 16650 peaks takes 15.8 s\n",
      "process 16700 peaks takes 15.9 s\n",
      "process 16750 peaks takes 15.9 s\n",
      "process 16800 peaks takes 16.0 s\n",
      "process 16850 peaks takes 16.0 s\n",
      "process 16900 peaks takes 16.1 s\n",
      "process 16950 peaks takes 16.1 s\n",
      "process 17000 peaks takes 16.2 s\n",
      "process 17050 peaks takes 16.2 s\n",
      "process 17100 peaks takes 16.2 s\n",
      "process 17150 peaks takes 16.3 s\n",
      "process 17200 peaks takes 16.3 s\n",
      "process 17250 peaks takes 16.4 s\n",
      "process 17300 peaks takes 16.4 s\n",
      "process 17350 peaks takes 16.5 s\n",
      "process 17400 peaks takes 16.5 s\n",
      "process 17450 peaks takes 16.6 s\n",
      "process 17500 peaks takes 16.6 s\n",
      "process 17550 peaks takes 16.6 s\n",
      "process 17600 peaks takes 16.7 s\n",
      "process 17650 peaks takes 16.7 s\n",
      "process 17700 peaks takes 16.8 s\n",
      "process 17750 peaks takes 16.8 s\n",
      "process 17800 peaks takes 16.8 s\n",
      "process 17850 peaks takes 16.9 s\n",
      "process 17900 peaks takes 16.9 s\n",
      "process 17950 peaks takes 17.0 s\n",
      "process 18000 peaks takes 17.0 s\n",
      "process 18050 peaks takes 17.1 s\n",
      "process 18100 peaks takes 17.1 s\n",
      "process 18150 peaks takes 17.1 s\n",
      "process 18200 peaks takes 17.2 s\n",
      "process 18250 peaks takes 17.2 s\n",
      "process 18300 peaks takes 17.3 s\n",
      "process 18350 peaks takes 17.3 s\n",
      "process 18400 peaks takes 17.4 s\n",
      "process 18450 peaks takes 17.4 s\n",
      "process 18500 peaks takes 17.5 s\n",
      "process 18550 peaks takes 17.5 s\n",
      "process 18600 peaks takes 17.6 s\n",
      "process 18650 peaks takes 17.6 s\n",
      "process 18700 peaks takes 17.7 s\n",
      "process 18750 peaks takes 17.7 s\n",
      "process 18800 peaks takes 17.8 s\n",
      "process 18850 peaks takes 17.8 s\n",
      "process 18900 peaks takes 17.8 s\n",
      "process 18950 peaks takes 17.9 s\n",
      "process 19000 peaks takes 17.9 s\n",
      "process 19050 peaks takes 18.0 s\n",
      "process 19100 peaks takes 18.0 s\n",
      "process 19150 peaks takes 18.1 s\n",
      "process 19200 peaks takes 18.1 s\n",
      "process 19250 peaks takes 18.1 s\n",
      "process 19300 peaks takes 18.2 s\n",
      "process 19350 peaks takes 18.2 s\n",
      "process 19400 peaks takes 18.3 s\n",
      "process 19450 peaks takes 18.3 s\n",
      "process 19500 peaks takes 18.4 s\n",
      "process 19550 peaks takes 18.4 s\n",
      "process 19600 peaks takes 18.5 s\n",
      "process 19650 peaks takes 18.5 s\n",
      "process 19700 peaks takes 18.6 s\n",
      "process 19750 peaks takes 18.6 s\n",
      "process 19800 peaks takes 18.7 s\n",
      "process 19850 peaks takes 18.7 s\n",
      "process 19900 peaks takes 18.8 s\n",
      "process 19950 peaks takes 18.8 s\n",
      "process 20000 peaks takes 18.9 s\n",
      "process 20050 peaks takes 18.9 s\n",
      "process 20100 peaks takes 18.9 s\n",
      "process 20150 peaks takes 19.0 s\n",
      "process 20200 peaks takes 19.0 s\n",
      "process 20250 peaks takes 19.1 s\n",
      "process 20300 peaks takes 19.1 s\n",
      "process 20350 peaks takes 19.2 s\n",
      "process 20400 peaks takes 19.2 s\n",
      "process 20450 peaks takes 19.3 s\n",
      "process 20500 peaks takes 19.3 s\n",
      "process 20550 peaks takes 19.4 s\n",
      "process 20600 peaks takes 19.4 s\n",
      "process 20650 peaks takes 19.5 s\n",
      "process 20700 peaks takes 19.5 s\n",
      "process 20750 peaks takes 19.5 s\n",
      "process 20800 peaks takes 19.6 s\n",
      "process 20850 peaks takes 19.7 s\n",
      "process 20900 peaks takes 19.7 s\n",
      "process 20950 peaks takes 19.7 s\n",
      "process 21000 peaks takes 19.8 s\n",
      "process 21050 peaks takes 19.9 s\n",
      "process 21100 peaks takes 19.9 s\n",
      "process 21150 peaks takes 19.9 s\n",
      "process 21200 peaks takes 20.0 s\n",
      "process 21250 peaks takes 20.0 s\n",
      "process 21300 peaks takes 20.1 s\n",
      "process 21350 peaks takes 20.1 s\n",
      "process 21400 peaks takes 20.2 s\n",
      "process 21450 peaks takes 20.2 s\n",
      "process 21500 peaks takes 20.3 s\n",
      "process 21550 peaks takes 20.3 s\n",
      "process 21600 peaks takes 20.4 s\n",
      "process 21650 peaks takes 20.4 s\n",
      "process 21700 peaks takes 20.5 s\n",
      "process 21750 peaks takes 20.5 s\n",
      "process 21800 peaks takes 20.6 s\n",
      "process 21850 peaks takes 20.6 s\n",
      "process 21900 peaks takes 20.7 s\n",
      "process 21950 peaks takes 20.7 s\n",
      "process 22000 peaks takes 20.7 s\n",
      "process 22050 peaks takes 20.8 s\n",
      "process 22100 peaks takes 20.8 s\n",
      "process 22150 peaks takes 20.9 s\n",
      "process 22200 peaks takes 20.9 s\n",
      "process 22250 peaks takes 21.0 s\n",
      "process 22300 peaks takes 21.0 s\n",
      "process 22350 peaks takes 21.1 s\n",
      "process 22400 peaks takes 21.1 s\n",
      "process 22450 peaks takes 21.2 s\n",
      "process 22500 peaks takes 21.2 s\n",
      "process 22550 peaks takes 21.3 s\n",
      "process 22600 peaks takes 21.3 s\n",
      "process 22650 peaks takes 21.3 s\n",
      "process 22700 peaks takes 21.4 s\n",
      "process 22750 peaks takes 21.4 s\n",
      "process 22800 peaks takes 21.5 s\n",
      "process 22850 peaks takes 21.6 s\n",
      "process 22900 peaks takes 21.6 s\n",
      "process 22950 peaks takes 21.6 s\n",
      "process 23000 peaks takes 21.7 s\n",
      "process 23050 peaks takes 21.7 s\n",
      "process 23100 peaks takes 21.8 s\n",
      "process 23150 peaks takes 21.8 s\n",
      "process 23200 peaks takes 21.9 s\n",
      "process 23250 peaks takes 21.9 s\n",
      "process 23300 peaks takes 22.0 s\n",
      "process 23350 peaks takes 22.0 s\n",
      "process 23400 peaks takes 22.0 s\n",
      "process 23450 peaks takes 22.1 s\n",
      "process 23500 peaks takes 22.1 s\n",
      "process 23550 peaks takes 22.2 s\n",
      "process 23600 peaks takes 22.2 s\n",
      "process 23650 peaks takes 22.3 s\n",
      "process 23700 peaks takes 22.3 s\n",
      "process 23750 peaks takes 22.3 s\n",
      "process 23800 peaks takes 22.4 s\n",
      "process 23850 peaks takes 22.4 s\n",
      "process 23900 peaks takes 22.5 s\n",
      "process 23950 peaks takes 22.5 s\n",
      "process 24000 peaks takes 22.6 s\n",
      "process 24050 peaks takes 22.6 s\n",
      "process 24100 peaks takes 22.7 s\n",
      "process 24150 peaks takes 22.7 s\n",
      "process 24200 peaks takes 22.8 s\n",
      "process 24250 peaks takes 22.8 s\n",
      "process 24300 peaks takes 22.9 s\n",
      "process 24350 peaks takes 22.9 s\n",
      "process 24400 peaks takes 22.9 s\n",
      "process 24450 peaks takes 23.0 s\n",
      "process 24500 peaks takes 23.0 s\n",
      "process 24550 peaks takes 23.1 s\n",
      "process 24600 peaks takes 23.1 s\n",
      "process 24650 peaks takes 23.2 s\n",
      "process 24700 peaks takes 23.2 s\n",
      "process 24750 peaks takes 23.3 s\n",
      "process 24800 peaks takes 23.3 s\n",
      "process 24850 peaks takes 23.3 s\n",
      "process 24900 peaks takes 23.4 s\n",
      "process 24950 peaks takes 23.4 s\n",
      "process 25000 peaks takes 23.5 s\n",
      "process 25050 peaks takes 23.5 s\n",
      "process 25100 peaks takes 23.6 s\n",
      "process 25150 peaks takes 23.6 s\n",
      "process 25200 peaks takes 23.7 s\n",
      "process 25250 peaks takes 23.7 s\n",
      "process 25300 peaks takes 23.8 s\n",
      "process 25350 peaks takes 23.8 s\n",
      "process 25400 peaks takes 23.9 s\n",
      "process 25450 peaks takes 23.9 s\n",
      "process 25500 peaks takes 24.0 s\n",
      "process 25550 peaks takes 24.0 s\n",
      "process 25600 peaks takes 24.0 s\n",
      "process 25650 peaks takes 24.1 s\n",
      "process 25700 peaks takes 24.1 s\n",
      "process 25750 peaks takes 24.2 s\n",
      "process 25800 peaks takes 24.2 s\n",
      "process 25850 peaks takes 24.2 s\n",
      "process 25900 peaks takes 24.3 s\n",
      "process 25950 peaks takes 24.3 s\n",
      "process 26000 peaks takes 24.4 s\n",
      "process 26050 peaks takes 24.4 s\n",
      "process 26100 peaks takes 24.5 s\n",
      "process 26150 peaks takes 24.5 s\n",
      "process 26200 peaks takes 24.6 s\n",
      "process 26250 peaks takes 24.6 s\n",
      "process 26300 peaks takes 24.7 s\n",
      "process 26350 peaks takes 24.7 s\n",
      "process 26400 peaks takes 24.8 s\n",
      "process 26450 peaks takes 24.8 s\n",
      "process 26500 peaks takes 24.8 s\n",
      "process 26550 peaks takes 24.9 s\n",
      "process 26600 peaks takes 24.9 s\n",
      "process 26650 peaks takes 25.0 s\n",
      "process 26700 peaks takes 25.0 s\n",
      "process 26750 peaks takes 25.1 s\n",
      "process 26800 peaks takes 25.1 s\n",
      "process 26850 peaks takes 25.2 s\n",
      "process 26900 peaks takes 25.2 s\n",
      "process 26950 peaks takes 25.2 s\n",
      "\n",
      "test\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "\n",
      "val\n",
      "1499 29\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.7 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.8 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.9 s\n",
      "process 700 peaks takes 1.0 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.1 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.2 s\n",
      "process 950 peaks takes 1.3 s\n",
      "process 1000 peaks takes 1.4 s\n",
      "process 1050 peaks takes 1.4 s\n",
      "process 1100 peaks takes 1.5 s\n",
      "process 1150 peaks takes 1.5 s\n",
      "process 1200 peaks takes 1.6 s\n",
      "process 1250 peaks takes 1.7 s\n",
      "process 1300 peaks takes 1.7 s\n",
      "process 1350 peaks takes 1.8 s\n",
      "process 1400 peaks takes 1.8 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs10000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:36:16.341881: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:36:16.461850: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:36:16.465859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:16.465910: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:36:16.965335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:16.965410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:16.965416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:36:18.807405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:36:18.807536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:36:18.807901: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:36:18.808249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 10000)     330000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 10000)    0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10000)        0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,849,810\n",
      "Trainable params: 4,843,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "211/211 [==============================] - 358s 2s/step - loss: 0.0776 - auc: 0.4990 - auc_1: 0.0080 - val_loss: 0.0454 - val_auc: 0.4989 - val_auc_1: 0.0092\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs10000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs10000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad\n",
      "(10000, 30000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs10000_var30000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000 --batch 50\n",
      "2024-05-13 07:42:20.880496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:42:20.979279: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:42:20.982187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:42:20.982218: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:42:21.505732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:42:21.505843: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:42:21.505876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[27001, 1500, 1499]\n",
      "30000 600\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.3 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.4 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.5 s\n",
      "process 2400 peaks takes 2.6 s\n",
      "process 2450 peaks takes 2.6 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.7 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 2.9 s\n",
      "process 2750 peaks takes 2.9 s\n",
      "process 2800 peaks takes 3.0 s\n",
      "process 2850 peaks takes 3.0 s\n",
      "process 2900 peaks takes 3.1 s\n",
      "process 2950 peaks takes 3.1 s\n",
      "process 3000 peaks takes 3.2 s\n",
      "process 3050 peaks takes 3.2 s\n",
      "process 3100 peaks takes 3.2 s\n",
      "process 3150 peaks takes 3.3 s\n",
      "process 3200 peaks takes 3.3 s\n",
      "process 3250 peaks takes 3.4 s\n",
      "process 3300 peaks takes 3.4 s\n",
      "process 3350 peaks takes 3.5 s\n",
      "process 3400 peaks takes 3.5 s\n",
      "process 3450 peaks takes 3.6 s\n",
      "process 3500 peaks takes 3.6 s\n",
      "process 3550 peaks takes 3.7 s\n",
      "process 3600 peaks takes 3.7 s\n",
      "process 3650 peaks takes 3.8 s\n",
      "process 3700 peaks takes 3.8 s\n",
      "process 3750 peaks takes 3.9 s\n",
      "process 3800 peaks takes 3.9 s\n",
      "process 3850 peaks takes 4.0 s\n",
      "process 3900 peaks takes 4.0 s\n",
      "process 3950 peaks takes 4.1 s\n",
      "process 4000 peaks takes 4.1 s\n",
      "process 4050 peaks takes 4.2 s\n",
      "process 4100 peaks takes 4.2 s\n",
      "process 4150 peaks takes 4.3 s\n",
      "process 4200 peaks takes 4.3 s\n",
      "process 4250 peaks takes 4.4 s\n",
      "process 4300 peaks takes 4.4 s\n",
      "process 4350 peaks takes 4.5 s\n",
      "process 4400 peaks takes 4.5 s\n",
      "process 4450 peaks takes 4.6 s\n",
      "process 4500 peaks takes 4.6 s\n",
      "process 4550 peaks takes 4.7 s\n",
      "process 4600 peaks takes 4.7 s\n",
      "process 4650 peaks takes 4.8 s\n",
      "process 4700 peaks takes 4.8 s\n",
      "process 4750 peaks takes 4.9 s\n",
      "process 4800 peaks takes 4.9 s\n",
      "process 4850 peaks takes 4.9 s\n",
      "process 4900 peaks takes 5.0 s\n",
      "process 4950 peaks takes 5.0 s\n",
      "process 5000 peaks takes 5.1 s\n",
      "process 5050 peaks takes 5.1 s\n",
      "process 5100 peaks takes 5.2 s\n",
      "process 5150 peaks takes 5.2 s\n",
      "process 5200 peaks takes 5.3 s\n",
      "process 5250 peaks takes 5.3 s\n",
      "process 5300 peaks takes 5.4 s\n",
      "process 5350 peaks takes 5.4 s\n",
      "process 5400 peaks takes 5.5 s\n",
      "process 5450 peaks takes 5.5 s\n",
      "process 5500 peaks takes 5.6 s\n",
      "process 5550 peaks takes 5.6 s\n",
      "process 5600 peaks takes 5.7 s\n",
      "process 5650 peaks takes 5.7 s\n",
      "process 5700 peaks takes 5.8 s\n",
      "process 5750 peaks takes 5.8 s\n",
      "process 5800 peaks takes 5.9 s\n",
      "process 5850 peaks takes 5.9 s\n",
      "process 5900 peaks takes 6.0 s\n",
      "process 5950 peaks takes 6.0 s\n",
      "process 6000 peaks takes 6.1 s\n",
      "process 6050 peaks takes 6.1 s\n",
      "process 6100 peaks takes 6.2 s\n",
      "process 6150 peaks takes 6.2 s\n",
      "process 6200 peaks takes 6.3 s\n",
      "process 6250 peaks takes 6.3 s\n",
      "process 6300 peaks takes 6.4 s\n",
      "process 6350 peaks takes 6.4 s\n",
      "process 6400 peaks takes 6.5 s\n",
      "process 6450 peaks takes 6.5 s\n",
      "process 6500 peaks takes 6.6 s\n",
      "process 6550 peaks takes 6.6 s\n",
      "process 6600 peaks takes 6.7 s\n",
      "process 6650 peaks takes 6.8 s\n",
      "process 6700 peaks takes 6.8 s\n",
      "process 6750 peaks takes 6.9 s\n",
      "process 6800 peaks takes 6.9 s\n",
      "process 6850 peaks takes 6.9 s\n",
      "process 6900 peaks takes 7.0 s\n",
      "process 6950 peaks takes 7.0 s\n",
      "process 7000 peaks takes 7.1 s\n",
      "process 7050 peaks takes 7.1 s\n",
      "process 7100 peaks takes 7.2 s\n",
      "process 7150 peaks takes 7.2 s\n",
      "process 7200 peaks takes 7.2 s\n",
      "process 7250 peaks takes 7.3 s\n",
      "process 7300 peaks takes 7.3 s\n",
      "process 7350 peaks takes 7.4 s\n",
      "process 7400 peaks takes 7.4 s\n",
      "process 7450 peaks takes 7.5 s\n",
      "process 7500 peaks takes 7.5 s\n",
      "process 7550 peaks takes 7.6 s\n",
      "process 7600 peaks takes 7.6 s\n",
      "process 7650 peaks takes 7.6 s\n",
      "process 7700 peaks takes 7.7 s\n",
      "process 7750 peaks takes 7.7 s\n",
      "process 7800 peaks takes 7.8 s\n",
      "process 7850 peaks takes 7.8 s\n",
      "process 7900 peaks takes 7.9 s\n",
      "process 7950 peaks takes 7.9 s\n",
      "process 8000 peaks takes 8.0 s\n",
      "process 8050 peaks takes 8.0 s\n",
      "process 8100 peaks takes 8.1 s\n",
      "process 8150 peaks takes 8.1 s\n",
      "process 8200 peaks takes 8.1 s\n",
      "process 8250 peaks takes 8.2 s\n",
      "process 8300 peaks takes 8.2 s\n",
      "process 8350 peaks takes 8.3 s\n",
      "process 8400 peaks takes 8.3 s\n",
      "process 8450 peaks takes 8.4 s\n",
      "process 8500 peaks takes 8.4 s\n",
      "process 8550 peaks takes 8.5 s\n",
      "process 8600 peaks takes 8.5 s\n",
      "process 8650 peaks takes 8.6 s\n",
      "process 8700 peaks takes 8.6 s\n",
      "process 8750 peaks takes 8.6 s\n",
      "process 8800 peaks takes 8.7 s\n",
      "process 8850 peaks takes 8.7 s\n",
      "process 8900 peaks takes 8.8 s\n",
      "process 8950 peaks takes 8.8 s\n",
      "process 9000 peaks takes 8.9 s\n",
      "process 9050 peaks takes 8.9 s\n",
      "process 9100 peaks takes 9.0 s\n",
      "process 9150 peaks takes 9.0 s\n",
      "process 9200 peaks takes 9.0 s\n",
      "process 9250 peaks takes 9.1 s\n",
      "process 9300 peaks takes 9.1 s\n",
      "process 9350 peaks takes 9.2 s\n",
      "process 9400 peaks takes 9.2 s\n",
      "process 9450 peaks takes 9.3 s\n",
      "process 9500 peaks takes 9.3 s\n",
      "process 9550 peaks takes 9.3 s\n",
      "process 9600 peaks takes 9.4 s\n",
      "process 9650 peaks takes 9.4 s\n",
      "process 9700 peaks takes 9.5 s\n",
      "process 9750 peaks takes 9.5 s\n",
      "process 9800 peaks takes 9.6 s\n",
      "process 9850 peaks takes 9.6 s\n",
      "process 9900 peaks takes 9.7 s\n",
      "process 9950 peaks takes 9.7 s\n",
      "process 10000 peaks takes 9.7 s\n",
      "process 10050 peaks takes 9.8 s\n",
      "process 10100 peaks takes 9.8 s\n",
      "process 10150 peaks takes 9.9 s\n",
      "process 10200 peaks takes 9.9 s\n",
      "process 10250 peaks takes 10.0 s\n",
      "process 10300 peaks takes 10.0 s\n",
      "process 10350 peaks takes 10.1 s\n",
      "process 10400 peaks takes 10.1 s\n",
      "process 10450 peaks takes 10.1 s\n",
      "process 10500 peaks takes 10.2 s\n",
      "process 10550 peaks takes 10.2 s\n",
      "process 10600 peaks takes 10.3 s\n",
      "process 10650 peaks takes 10.3 s\n",
      "process 10700 peaks takes 10.4 s\n",
      "process 10750 peaks takes 10.4 s\n",
      "process 10800 peaks takes 10.5 s\n",
      "process 10850 peaks takes 10.5 s\n",
      "process 10900 peaks takes 10.6 s\n",
      "process 10950 peaks takes 10.6 s\n",
      "process 11000 peaks takes 10.7 s\n",
      "process 11050 peaks takes 10.7 s\n",
      "process 11100 peaks takes 10.8 s\n",
      "process 11150 peaks takes 10.8 s\n",
      "process 11200 peaks takes 10.9 s\n",
      "process 11250 peaks takes 10.9 s\n",
      "process 11300 peaks takes 10.9 s\n",
      "process 11350 peaks takes 11.0 s\n",
      "process 11400 peaks takes 11.0 s\n",
      "process 11450 peaks takes 11.1 s\n",
      "process 11500 peaks takes 11.1 s\n",
      "process 11550 peaks takes 11.2 s\n",
      "process 11600 peaks takes 11.2 s\n",
      "process 11650 peaks takes 11.3 s\n",
      "process 11700 peaks takes 11.3 s\n",
      "process 11750 peaks takes 11.4 s\n",
      "process 11800 peaks takes 11.4 s\n",
      "process 11850 peaks takes 11.5 s\n",
      "process 11900 peaks takes 11.5 s\n",
      "process 11950 peaks takes 11.5 s\n",
      "process 12000 peaks takes 11.6 s\n",
      "process 12050 peaks takes 11.6 s\n",
      "process 12100 peaks takes 11.7 s\n",
      "process 12150 peaks takes 11.7 s\n",
      "process 12200 peaks takes 11.8 s\n",
      "process 12250 peaks takes 11.8 s\n",
      "process 12300 peaks takes 11.9 s\n",
      "process 12350 peaks takes 11.9 s\n",
      "process 12400 peaks takes 11.9 s\n",
      "process 12450 peaks takes 12.0 s\n",
      "process 12500 peaks takes 12.0 s\n",
      "process 12550 peaks takes 12.1 s\n",
      "process 12600 peaks takes 12.1 s\n",
      "process 12650 peaks takes 12.2 s\n",
      "process 12700 peaks takes 12.2 s\n",
      "process 12750 peaks takes 12.3 s\n",
      "process 12800 peaks takes 12.3 s\n",
      "process 12850 peaks takes 12.4 s\n",
      "process 12900 peaks takes 12.4 s\n",
      "process 12950 peaks takes 12.5 s\n",
      "process 13000 peaks takes 12.5 s\n",
      "process 13050 peaks takes 12.5 s\n",
      "process 13100 peaks takes 12.6 s\n",
      "process 13150 peaks takes 12.6 s\n",
      "process 13200 peaks takes 12.7 s\n",
      "process 13250 peaks takes 12.7 s\n",
      "process 13300 peaks takes 12.8 s\n",
      "process 13350 peaks takes 12.8 s\n",
      "process 13400 peaks takes 12.9 s\n",
      "process 13450 peaks takes 12.9 s\n",
      "process 13500 peaks takes 13.0 s\n",
      "process 13550 peaks takes 13.0 s\n",
      "process 13600 peaks takes 13.0 s\n",
      "process 13650 peaks takes 13.1 s\n",
      "process 13700 peaks takes 13.1 s\n",
      "process 13750 peaks takes 13.2 s\n",
      "process 13800 peaks takes 13.2 s\n",
      "process 13850 peaks takes 13.3 s\n",
      "process 13900 peaks takes 13.3 s\n",
      "process 13950 peaks takes 13.4 s\n",
      "process 14000 peaks takes 13.4 s\n",
      "process 14050 peaks takes 13.4 s\n",
      "process 14100 peaks takes 13.5 s\n",
      "process 14150 peaks takes 13.5 s\n",
      "process 14200 peaks takes 13.6 s\n",
      "process 14250 peaks takes 13.6 s\n",
      "process 14300 peaks takes 13.7 s\n",
      "process 14350 peaks takes 13.7 s\n",
      "process 14400 peaks takes 13.8 s\n",
      "process 14450 peaks takes 13.8 s\n",
      "process 14500 peaks takes 13.9 s\n",
      "process 14550 peaks takes 13.9 s\n",
      "process 14600 peaks takes 14.0 s\n",
      "process 14650 peaks takes 14.1 s\n",
      "process 14700 peaks takes 14.1 s\n",
      "process 14750 peaks takes 14.1 s\n",
      "process 14800 peaks takes 14.2 s\n",
      "process 14850 peaks takes 14.2 s\n",
      "process 14900 peaks takes 14.3 s\n",
      "process 14950 peaks takes 14.3 s\n",
      "process 15000 peaks takes 14.4 s\n",
      "process 15050 peaks takes 14.4 s\n",
      "process 15100 peaks takes 14.4 s\n",
      "process 15150 peaks takes 14.5 s\n",
      "process 15200 peaks takes 14.5 s\n",
      "process 15250 peaks takes 14.6 s\n",
      "process 15300 peaks takes 14.6 s\n",
      "process 15350 peaks takes 14.7 s\n",
      "process 15400 peaks takes 14.7 s\n",
      "process 15450 peaks takes 14.8 s\n",
      "process 15500 peaks takes 14.8 s\n",
      "process 15550 peaks takes 14.8 s\n",
      "process 15600 peaks takes 14.9 s\n",
      "process 15650 peaks takes 15.0 s\n",
      "process 15700 peaks takes 15.0 s\n",
      "process 15750 peaks takes 15.0 s\n",
      "process 15800 peaks takes 15.1 s\n",
      "process 15850 peaks takes 15.1 s\n",
      "process 15900 peaks takes 15.2 s\n",
      "process 15950 peaks takes 15.2 s\n",
      "process 16000 peaks takes 15.2 s\n",
      "process 16050 peaks takes 15.3 s\n",
      "process 16100 peaks takes 15.3 s\n",
      "process 16150 peaks takes 15.4 s\n",
      "process 16200 peaks takes 15.4 s\n",
      "process 16250 peaks takes 15.5 s\n",
      "process 16300 peaks takes 15.5 s\n",
      "process 16350 peaks takes 15.5 s\n",
      "process 16400 peaks takes 15.6 s\n",
      "process 16450 peaks takes 15.6 s\n",
      "process 16500 peaks takes 15.7 s\n",
      "process 16550 peaks takes 15.7 s\n",
      "process 16600 peaks takes 15.8 s\n",
      "process 16650 peaks takes 15.8 s\n",
      "process 16700 peaks takes 15.9 s\n",
      "process 16750 peaks takes 15.9 s\n",
      "process 16800 peaks takes 15.9 s\n",
      "process 16850 peaks takes 16.0 s\n",
      "process 16900 peaks takes 16.0 s\n",
      "process 16950 peaks takes 16.1 s\n",
      "process 17000 peaks takes 16.1 s\n",
      "process 17050 peaks takes 16.2 s\n",
      "process 17100 peaks takes 16.2 s\n",
      "process 17150 peaks takes 16.2 s\n",
      "process 17200 peaks takes 16.3 s\n",
      "process 17250 peaks takes 16.3 s\n",
      "process 17300 peaks takes 16.4 s\n",
      "process 17350 peaks takes 16.4 s\n",
      "process 17400 peaks takes 16.5 s\n",
      "process 17450 peaks takes 16.5 s\n",
      "process 17500 peaks takes 16.5 s\n",
      "process 17550 peaks takes 16.6 s\n",
      "process 17600 peaks takes 16.6 s\n",
      "process 17650 peaks takes 16.7 s\n",
      "process 17700 peaks takes 16.7 s\n",
      "process 17750 peaks takes 16.8 s\n",
      "process 17800 peaks takes 16.8 s\n",
      "process 17850 peaks takes 16.9 s\n",
      "process 17900 peaks takes 16.9 s\n",
      "process 17950 peaks takes 17.0 s\n",
      "process 18000 peaks takes 17.0 s\n",
      "process 18050 peaks takes 17.1 s\n",
      "process 18100 peaks takes 17.1 s\n",
      "process 18150 peaks takes 17.1 s\n",
      "process 18200 peaks takes 17.2 s\n",
      "process 18250 peaks takes 17.3 s\n",
      "process 18300 peaks takes 17.3 s\n",
      "process 18350 peaks takes 17.4 s\n",
      "process 18400 peaks takes 17.4 s\n",
      "process 18450 peaks takes 17.5 s\n",
      "process 18500 peaks takes 17.5 s\n",
      "process 18550 peaks takes 17.6 s\n",
      "process 18600 peaks takes 17.6 s\n",
      "process 18650 peaks takes 17.7 s\n",
      "process 18700 peaks takes 17.7 s\n",
      "process 18750 peaks takes 17.8 s\n",
      "process 18800 peaks takes 17.8 s\n",
      "process 18850 peaks takes 17.9 s\n",
      "process 18900 peaks takes 17.9 s\n",
      "process 18950 peaks takes 18.0 s\n",
      "process 19000 peaks takes 18.0 s\n",
      "process 19050 peaks takes 18.1 s\n",
      "process 19100 peaks takes 18.1 s\n",
      "process 19150 peaks takes 18.2 s\n",
      "process 19200 peaks takes 18.2 s\n",
      "process 19250 peaks takes 18.3 s\n",
      "process 19300 peaks takes 18.3 s\n",
      "process 19350 peaks takes 18.4 s\n",
      "process 19400 peaks takes 18.5 s\n",
      "process 19450 peaks takes 18.5 s\n",
      "process 19500 peaks takes 18.6 s\n",
      "process 19550 peaks takes 18.6 s\n",
      "process 19600 peaks takes 18.6 s\n",
      "process 19650 peaks takes 18.7 s\n",
      "process 19700 peaks takes 18.8 s\n",
      "process 19750 peaks takes 18.8 s\n",
      "process 19800 peaks takes 18.9 s\n",
      "process 19850 peaks takes 18.9 s\n",
      "process 19900 peaks takes 19.0 s\n",
      "process 19950 peaks takes 19.0 s\n",
      "process 20000 peaks takes 19.1 s\n",
      "process 20050 peaks takes 19.1 s\n",
      "process 20100 peaks takes 19.2 s\n",
      "process 20150 peaks takes 19.2 s\n",
      "process 20200 peaks takes 19.3 s\n",
      "process 20250 peaks takes 19.3 s\n",
      "process 20300 peaks takes 19.4 s\n",
      "process 20350 peaks takes 19.5 s\n",
      "process 20400 peaks takes 19.5 s\n",
      "process 20450 peaks takes 19.5 s\n",
      "process 20500 peaks takes 19.6 s\n",
      "process 20550 peaks takes 19.6 s\n",
      "process 20600 peaks takes 19.7 s\n",
      "process 20650 peaks takes 19.7 s\n",
      "process 20700 peaks takes 19.8 s\n",
      "process 20750 peaks takes 19.8 s\n",
      "process 20800 peaks takes 19.9 s\n",
      "process 20850 peaks takes 19.9 s\n",
      "process 20900 peaks takes 19.9 s\n",
      "process 20950 peaks takes 20.0 s\n",
      "process 21000 peaks takes 20.0 s\n",
      "process 21050 peaks takes 20.1 s\n",
      "process 21100 peaks takes 20.1 s\n",
      "process 21150 peaks takes 20.2 s\n",
      "process 21200 peaks takes 20.2 s\n",
      "process 21250 peaks takes 20.3 s\n",
      "process 21300 peaks takes 20.3 s\n",
      "process 21350 peaks takes 20.4 s\n",
      "process 21400 peaks takes 20.4 s\n",
      "process 21450 peaks takes 20.4 s\n",
      "process 21500 peaks takes 20.5 s\n",
      "process 21550 peaks takes 20.5 s\n",
      "process 21600 peaks takes 20.6 s\n",
      "process 21650 peaks takes 20.7 s\n",
      "process 21700 peaks takes 20.7 s\n",
      "process 21750 peaks takes 20.7 s\n",
      "process 21800 peaks takes 20.8 s\n",
      "process 21850 peaks takes 20.8 s\n",
      "process 21900 peaks takes 20.9 s\n",
      "process 21950 peaks takes 20.9 s\n",
      "process 22000 peaks takes 21.0 s\n",
      "process 22050 peaks takes 21.0 s\n",
      "process 22100 peaks takes 21.1 s\n",
      "process 22150 peaks takes 21.1 s\n",
      "process 22200 peaks takes 21.2 s\n",
      "process 22250 peaks takes 21.2 s\n",
      "process 22300 peaks takes 21.3 s\n",
      "process 22350 peaks takes 21.3 s\n",
      "process 22400 peaks takes 21.4 s\n",
      "process 22450 peaks takes 21.4 s\n",
      "process 22500 peaks takes 21.5 s\n",
      "process 22550 peaks takes 21.5 s\n",
      "process 22600 peaks takes 21.6 s\n",
      "process 22650 peaks takes 21.6 s\n",
      "process 22700 peaks takes 21.6 s\n",
      "process 22750 peaks takes 21.7 s\n",
      "process 22800 peaks takes 21.7 s\n",
      "process 22850 peaks takes 21.8 s\n",
      "process 22900 peaks takes 21.8 s\n",
      "process 22950 peaks takes 21.9 s\n",
      "process 23000 peaks takes 21.9 s\n",
      "process 23050 peaks takes 22.0 s\n",
      "process 23100 peaks takes 22.0 s\n",
      "process 23150 peaks takes 22.0 s\n",
      "process 23200 peaks takes 22.1 s\n",
      "process 23250 peaks takes 22.1 s\n",
      "process 23300 peaks takes 22.2 s\n",
      "process 23350 peaks takes 22.2 s\n",
      "process 23400 peaks takes 22.3 s\n",
      "process 23450 peaks takes 22.3 s\n",
      "process 23500 peaks takes 22.3 s\n",
      "process 23550 peaks takes 22.4 s\n",
      "process 23600 peaks takes 22.4 s\n",
      "process 23650 peaks takes 22.5 s\n",
      "process 23700 peaks takes 22.5 s\n",
      "process 23750 peaks takes 22.6 s\n",
      "process 23800 peaks takes 22.6 s\n",
      "process 23850 peaks takes 22.7 s\n",
      "process 23900 peaks takes 22.7 s\n",
      "process 23950 peaks takes 22.8 s\n",
      "process 24000 peaks takes 22.8 s\n",
      "process 24050 peaks takes 22.9 s\n",
      "process 24100 peaks takes 22.9 s\n",
      "process 24150 peaks takes 22.9 s\n",
      "process 24200 peaks takes 23.0 s\n",
      "process 24250 peaks takes 23.1 s\n",
      "process 24300 peaks takes 23.1 s\n",
      "process 24350 peaks takes 23.1 s\n",
      "process 24400 peaks takes 23.2 s\n",
      "process 24450 peaks takes 23.2 s\n",
      "process 24500 peaks takes 23.3 s\n",
      "process 24550 peaks takes 23.3 s\n",
      "process 24600 peaks takes 23.4 s\n",
      "process 24650 peaks takes 23.4 s\n",
      "process 24700 peaks takes 23.5 s\n",
      "process 24750 peaks takes 23.5 s\n",
      "process 24800 peaks takes 23.6 s\n",
      "process 24850 peaks takes 23.6 s\n",
      "process 24900 peaks takes 23.7 s\n",
      "process 24950 peaks takes 23.7 s\n",
      "process 25000 peaks takes 23.8 s\n",
      "process 25050 peaks takes 23.8 s\n",
      "process 25100 peaks takes 23.9 s\n",
      "process 25150 peaks takes 23.9 s\n",
      "process 25200 peaks takes 24.0 s\n",
      "process 25250 peaks takes 24.0 s\n",
      "process 25300 peaks takes 24.1 s\n",
      "process 25350 peaks takes 24.1 s\n",
      "process 25400 peaks takes 24.1 s\n",
      "process 25450 peaks takes 24.2 s\n",
      "process 25500 peaks takes 24.2 s\n",
      "process 25550 peaks takes 24.3 s\n",
      "process 25600 peaks takes 24.3 s\n",
      "process 25650 peaks takes 24.4 s\n",
      "process 25700 peaks takes 24.4 s\n",
      "process 25750 peaks takes 24.4 s\n",
      "process 25800 peaks takes 24.5 s\n",
      "process 25850 peaks takes 24.6 s\n",
      "process 25900 peaks takes 24.6 s\n",
      "process 25950 peaks takes 24.6 s\n",
      "process 26000 peaks takes 24.7 s\n",
      "process 26050 peaks takes 24.7 s\n",
      "process 26100 peaks takes 24.8 s\n",
      "process 26150 peaks takes 24.8 s\n",
      "process 26200 peaks takes 24.9 s\n",
      "process 26250 peaks takes 24.9 s\n",
      "process 26300 peaks takes 25.0 s\n",
      "process 26350 peaks takes 25.0 s\n",
      "process 26400 peaks takes 25.1 s\n",
      "process 26450 peaks takes 25.1 s\n",
      "process 26500 peaks takes 25.2 s\n",
      "process 26550 peaks takes 25.2 s\n",
      "process 26600 peaks takes 25.3 s\n",
      "process 26650 peaks takes 25.3 s\n",
      "process 26700 peaks takes 25.4 s\n",
      "process 26750 peaks takes 25.4 s\n",
      "process 26800 peaks takes 25.5 s\n",
      "process 26850 peaks takes 25.5 s\n",
      "process 26900 peaks takes 25.6 s\n",
      "process 26950 peaks takes 25.6 s\n",
      "process 27000 peaks takes 25.7 s\n",
      "process 27050 peaks takes 25.7 s\n",
      "process 27100 peaks takes 25.8 s\n",
      "process 27150 peaks takes 25.8 s\n",
      "process 27200 peaks takes 25.8 s\n",
      "process 27250 peaks takes 25.9 s\n",
      "process 27300 peaks takes 26.0 s\n",
      "process 27350 peaks takes 26.0 s\n",
      "process 27400 peaks takes 26.0 s\n",
      "process 27450 peaks takes 26.1 s\n",
      "process 27500 peaks takes 26.1 s\n",
      "process 27550 peaks takes 26.2 s\n",
      "process 27600 peaks takes 26.2 s\n",
      "process 27650 peaks takes 26.3 s\n",
      "process 27700 peaks takes 26.3 s\n",
      "process 27750 peaks takes 26.4 s\n",
      "process 27800 peaks takes 26.4 s\n",
      "process 27850 peaks takes 26.4 s\n",
      "process 27900 peaks takes 26.5 s\n",
      "process 27950 peaks takes 26.5 s\n",
      "process 28000 peaks takes 26.6 s\n",
      "process 28050 peaks takes 26.6 s\n",
      "process 28100 peaks takes 26.7 s\n",
      "process 28150 peaks takes 26.7 s\n",
      "process 28200 peaks takes 26.8 s\n",
      "process 28250 peaks takes 26.8 s\n",
      "process 28300 peaks takes 26.9 s\n",
      "process 28350 peaks takes 26.9 s\n",
      "process 28400 peaks takes 27.0 s\n",
      "process 28450 peaks takes 27.0 s\n",
      "process 28500 peaks takes 27.0 s\n",
      "process 28550 peaks takes 27.1 s\n",
      "process 28600 peaks takes 27.1 s\n",
      "process 28650 peaks takes 27.2 s\n",
      "process 28700 peaks takes 27.2 s\n",
      "process 28750 peaks takes 27.3 s\n",
      "process 28800 peaks takes 27.3 s\n",
      "process 28850 peaks takes 27.3 s\n",
      "process 28900 peaks takes 27.4 s\n",
      "process 28950 peaks takes 27.4 s\n",
      "process 29000 peaks takes 27.5 s\n",
      "process 29050 peaks takes 27.5 s\n",
      "process 29100 peaks takes 27.6 s\n",
      "process 29150 peaks takes 27.6 s\n",
      "process 29200 peaks takes 27.7 s\n",
      "process 29250 peaks takes 27.7 s\n",
      "process 29300 peaks takes 27.8 s\n",
      "process 29350 peaks takes 27.8 s\n",
      "process 29400 peaks takes 27.9 s\n",
      "process 29450 peaks takes 27.9 s\n",
      "process 29500 peaks takes 28.0 s\n",
      "process 29550 peaks takes 28.0 s\n",
      "process 29600 peaks takes 28.0 s\n",
      "process 29650 peaks takes 28.1 s\n",
      "process 29700 peaks takes 28.1 s\n",
      "process 29750 peaks takes 28.2 s\n",
      "process 29800 peaks takes 28.2 s\n",
      "process 29850 peaks takes 28.3 s\n",
      "process 29900 peaks takes 28.3 s\n",
      "process 29950 peaks takes 28.4 s\n",
      "\n",
      "train\n",
      "27001 540\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.0 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.1 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.2 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.3 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.4 s\n",
      "process 1450 peaks takes 1.4 s\n",
      "process 1500 peaks takes 1.5 s\n",
      "process 1550 peaks takes 1.5 s\n",
      "process 1600 peaks takes 1.6 s\n",
      "process 1650 peaks takes 1.6 s\n",
      "process 1700 peaks takes 1.7 s\n",
      "process 1750 peaks takes 1.7 s\n",
      "process 1800 peaks takes 1.8 s\n",
      "process 1850 peaks takes 1.8 s\n",
      "process 1900 peaks takes 1.9 s\n",
      "process 1950 peaks takes 1.9 s\n",
      "process 2000 peaks takes 2.0 s\n",
      "process 2050 peaks takes 2.0 s\n",
      "process 2100 peaks takes 2.1 s\n",
      "process 2150 peaks takes 2.1 s\n",
      "process 2200 peaks takes 2.2 s\n",
      "process 2250 peaks takes 2.2 s\n",
      "process 2300 peaks takes 2.3 s\n",
      "process 2350 peaks takes 2.3 s\n",
      "process 2400 peaks takes 2.4 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.5 s\n",
      "process 2550 peaks takes 2.5 s\n",
      "process 2600 peaks takes 2.6 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.7 s\n",
      "process 2750 peaks takes 2.7 s\n",
      "process 2800 peaks takes 2.8 s\n",
      "process 2850 peaks takes 2.8 s\n",
      "process 2900 peaks takes 2.9 s\n",
      "process 2950 peaks takes 2.9 s\n",
      "process 3000 peaks takes 3.0 s\n",
      "process 3050 peaks takes 3.0 s\n",
      "process 3100 peaks takes 3.1 s\n",
      "process 3150 peaks takes 3.1 s\n",
      "process 3200 peaks takes 3.2 s\n",
      "process 3250 peaks takes 3.2 s\n",
      "process 3300 peaks takes 3.2 s\n",
      "process 3350 peaks takes 3.3 s\n",
      "process 3400 peaks takes 3.3 s\n",
      "process 3450 peaks takes 3.4 s\n",
      "process 3500 peaks takes 3.4 s\n",
      "process 3550 peaks takes 3.5 s\n",
      "process 3600 peaks takes 3.5 s\n",
      "process 3650 peaks takes 3.5 s\n",
      "process 3700 peaks takes 3.6 s\n",
      "process 3750 peaks takes 3.7 s\n",
      "process 3800 peaks takes 3.7 s\n",
      "process 3850 peaks takes 3.7 s\n",
      "process 3900 peaks takes 3.8 s\n",
      "process 3950 peaks takes 3.8 s\n",
      "process 4000 peaks takes 3.9 s\n",
      "process 4050 peaks takes 3.9 s\n",
      "process 4100 peaks takes 4.0 s\n",
      "process 4150 peaks takes 4.0 s\n",
      "process 4200 peaks takes 4.1 s\n",
      "process 4250 peaks takes 4.1 s\n",
      "process 4300 peaks takes 4.1 s\n",
      "process 4350 peaks takes 4.2 s\n",
      "process 4400 peaks takes 4.2 s\n",
      "process 4450 peaks takes 4.3 s\n",
      "process 4500 peaks takes 4.3 s\n",
      "process 4550 peaks takes 4.4 s\n",
      "process 4600 peaks takes 4.4 s\n",
      "process 4650 peaks takes 4.4 s\n",
      "process 4700 peaks takes 4.5 s\n",
      "process 4750 peaks takes 4.5 s\n",
      "process 4800 peaks takes 4.6 s\n",
      "process 4850 peaks takes 4.6 s\n",
      "process 4900 peaks takes 4.7 s\n",
      "process 4950 peaks takes 4.7 s\n",
      "process 5000 peaks takes 4.8 s\n",
      "process 5050 peaks takes 4.8 s\n",
      "process 5100 peaks takes 4.8 s\n",
      "process 5150 peaks takes 4.9 s\n",
      "process 5200 peaks takes 4.9 s\n",
      "process 5250 peaks takes 5.0 s\n",
      "process 5300 peaks takes 5.0 s\n",
      "process 5350 peaks takes 5.1 s\n",
      "process 5400 peaks takes 5.1 s\n",
      "process 5450 peaks takes 5.1 s\n",
      "process 5500 peaks takes 5.2 s\n",
      "process 5550 peaks takes 5.2 s\n",
      "process 5600 peaks takes 5.3 s\n",
      "process 5650 peaks takes 5.3 s\n",
      "process 5700 peaks takes 5.4 s\n",
      "process 5750 peaks takes 5.4 s\n",
      "process 5800 peaks takes 5.5 s\n",
      "process 5850 peaks takes 5.5 s\n",
      "process 5900 peaks takes 5.6 s\n",
      "process 5950 peaks takes 5.6 s\n",
      "process 6000 peaks takes 5.6 s\n",
      "process 6050 peaks takes 5.7 s\n",
      "process 6100 peaks takes 5.7 s\n",
      "process 6150 peaks takes 5.8 s\n",
      "process 6200 peaks takes 5.8 s\n",
      "process 6250 peaks takes 5.8 s\n",
      "process 6300 peaks takes 5.9 s\n",
      "process 6350 peaks takes 5.9 s\n",
      "process 6400 peaks takes 6.0 s\n",
      "process 6450 peaks takes 6.0 s\n",
      "process 6500 peaks takes 6.1 s\n",
      "process 6550 peaks takes 6.1 s\n",
      "process 6600 peaks takes 6.2 s\n",
      "process 6650 peaks takes 6.2 s\n",
      "process 6700 peaks takes 6.3 s\n",
      "process 6750 peaks takes 6.3 s\n",
      "process 6800 peaks takes 6.4 s\n",
      "process 6850 peaks takes 6.4 s\n",
      "process 6900 peaks takes 6.5 s\n",
      "process 6950 peaks takes 6.5 s\n",
      "process 7000 peaks takes 6.6 s\n",
      "process 7050 peaks takes 6.6 s\n",
      "process 7100 peaks takes 6.7 s\n",
      "process 7150 peaks takes 6.7 s\n",
      "process 7200 peaks takes 6.8 s\n",
      "process 7250 peaks takes 6.9 s\n",
      "process 7300 peaks takes 6.9 s\n",
      "process 7350 peaks takes 7.0 s\n",
      "process 7400 peaks takes 7.0 s\n",
      "process 7450 peaks takes 7.0 s\n",
      "process 7500 peaks takes 7.1 s\n",
      "process 7550 peaks takes 7.2 s\n",
      "process 7600 peaks takes 7.2 s\n",
      "process 7650 peaks takes 7.3 s\n",
      "process 7700 peaks takes 7.3 s\n",
      "process 7750 peaks takes 7.3 s\n",
      "process 7800 peaks takes 7.4 s\n",
      "process 7850 peaks takes 7.4 s\n",
      "process 7900 peaks takes 7.5 s\n",
      "process 7950 peaks takes 7.6 s\n",
      "process 8000 peaks takes 7.6 s\n",
      "process 8050 peaks takes 7.7 s\n",
      "process 8100 peaks takes 7.7 s\n",
      "process 8150 peaks takes 7.8 s\n",
      "process 8200 peaks takes 7.8 s\n",
      "process 8250 peaks takes 7.9 s\n",
      "process 8300 peaks takes 7.9 s\n",
      "process 8350 peaks takes 8.0 s\n",
      "process 8400 peaks takes 8.0 s\n",
      "process 8450 peaks takes 8.1 s\n",
      "process 8500 peaks takes 8.1 s\n",
      "process 8550 peaks takes 8.2 s\n",
      "process 8600 peaks takes 8.2 s\n",
      "process 8650 peaks takes 8.3 s\n",
      "process 8700 peaks takes 8.3 s\n",
      "process 8750 peaks takes 8.4 s\n",
      "process 8800 peaks takes 8.4 s\n",
      "process 8850 peaks takes 8.4 s\n",
      "process 8900 peaks takes 8.5 s\n",
      "process 8950 peaks takes 8.5 s\n",
      "process 9000 peaks takes 8.6 s\n",
      "process 9050 peaks takes 8.6 s\n",
      "process 9100 peaks takes 8.7 s\n",
      "process 9150 peaks takes 8.7 s\n",
      "process 9200 peaks takes 8.8 s\n",
      "process 9250 peaks takes 8.8 s\n",
      "process 9300 peaks takes 8.9 s\n",
      "process 9350 peaks takes 8.9 s\n",
      "process 9400 peaks takes 9.0 s\n",
      "process 9450 peaks takes 9.0 s\n",
      "process 9500 peaks takes 9.1 s\n",
      "process 9550 peaks takes 9.1 s\n",
      "process 9600 peaks takes 9.1 s\n",
      "process 9650 peaks takes 9.2 s\n",
      "process 9700 peaks takes 9.2 s\n",
      "process 9750 peaks takes 9.3 s\n",
      "process 9800 peaks takes 9.3 s\n",
      "process 9850 peaks takes 9.4 s\n",
      "process 9900 peaks takes 9.4 s\n",
      "process 9950 peaks takes 9.4 s\n",
      "process 10000 peaks takes 9.5 s\n",
      "process 10050 peaks takes 9.5 s\n",
      "process 10100 peaks takes 9.6 s\n",
      "process 10150 peaks takes 9.6 s\n",
      "process 10200 peaks takes 9.7 s\n",
      "process 10250 peaks takes 9.7 s\n",
      "process 10300 peaks takes 9.8 s\n",
      "process 10350 peaks takes 9.8 s\n",
      "process 10400 peaks takes 9.9 s\n",
      "process 10450 peaks takes 9.9 s\n",
      "process 10500 peaks takes 10.0 s\n",
      "process 10550 peaks takes 10.0 s\n",
      "process 10600 peaks takes 10.1 s\n",
      "process 10650 peaks takes 10.1 s\n",
      "process 10700 peaks takes 10.2 s\n",
      "process 10750 peaks takes 10.2 s\n",
      "process 10800 peaks takes 10.3 s\n",
      "process 10850 peaks takes 10.3 s\n",
      "process 10900 peaks takes 10.4 s\n",
      "process 10950 peaks takes 10.4 s\n",
      "process 11000 peaks takes 10.4 s\n",
      "process 11050 peaks takes 10.5 s\n",
      "process 11100 peaks takes 10.5 s\n",
      "process 11150 peaks takes 10.6 s\n",
      "process 11200 peaks takes 10.6 s\n",
      "process 11250 peaks takes 10.7 s\n",
      "process 11300 peaks takes 10.7 s\n",
      "process 11350 peaks takes 10.8 s\n",
      "process 11400 peaks takes 10.8 s\n",
      "process 11450 peaks takes 10.9 s\n",
      "process 11500 peaks takes 10.9 s\n",
      "process 11550 peaks takes 10.9 s\n",
      "process 11600 peaks takes 11.0 s\n",
      "process 11650 peaks takes 11.0 s\n",
      "process 11700 peaks takes 11.1 s\n",
      "process 11750 peaks takes 11.1 s\n",
      "process 11800 peaks takes 11.2 s\n",
      "process 11850 peaks takes 11.2 s\n",
      "process 11900 peaks takes 11.2 s\n",
      "process 11950 peaks takes 11.3 s\n",
      "process 12000 peaks takes 11.3 s\n",
      "process 12050 peaks takes 11.4 s\n",
      "process 12100 peaks takes 11.4 s\n",
      "process 12150 peaks takes 11.5 s\n",
      "process 12200 peaks takes 11.5 s\n",
      "process 12250 peaks takes 11.6 s\n",
      "process 12300 peaks takes 11.6 s\n",
      "process 12350 peaks takes 11.6 s\n",
      "process 12400 peaks takes 11.7 s\n",
      "process 12450 peaks takes 11.7 s\n",
      "process 12500 peaks takes 11.8 s\n",
      "process 12550 peaks takes 11.8 s\n",
      "process 12600 peaks takes 11.9 s\n",
      "process 12650 peaks takes 11.9 s\n",
      "process 12700 peaks takes 11.9 s\n",
      "process 12750 peaks takes 12.0 s\n",
      "process 12800 peaks takes 12.1 s\n",
      "process 12850 peaks takes 12.1 s\n",
      "process 12900 peaks takes 12.1 s\n",
      "process 12950 peaks takes 12.2 s\n",
      "process 13000 peaks takes 12.2 s\n",
      "process 13050 peaks takes 12.3 s\n",
      "process 13100 peaks takes 12.3 s\n",
      "process 13150 peaks takes 12.4 s\n",
      "process 13200 peaks takes 12.4 s\n",
      "process 13250 peaks takes 12.5 s\n",
      "process 13300 peaks takes 12.5 s\n",
      "process 13350 peaks takes 12.6 s\n",
      "process 13400 peaks takes 12.6 s\n",
      "process 13450 peaks takes 12.7 s\n",
      "process 13500 peaks takes 12.7 s\n",
      "process 13550 peaks takes 12.7 s\n",
      "process 13600 peaks takes 12.8 s\n",
      "process 13650 peaks takes 12.8 s\n",
      "process 13700 peaks takes 12.9 s\n",
      "process 13750 peaks takes 12.9 s\n",
      "process 13800 peaks takes 13.0 s\n",
      "process 13850 peaks takes 13.0 s\n",
      "process 13900 peaks takes 13.1 s\n",
      "process 13950 peaks takes 13.1 s\n",
      "process 14000 peaks takes 13.1 s\n",
      "process 14050 peaks takes 13.2 s\n",
      "process 14100 peaks takes 13.2 s\n",
      "process 14150 peaks takes 13.3 s\n",
      "process 14200 peaks takes 13.3 s\n",
      "process 14250 peaks takes 13.4 s\n",
      "process 14300 peaks takes 13.4 s\n",
      "process 14350 peaks takes 13.5 s\n",
      "process 14400 peaks takes 13.5 s\n",
      "process 14450 peaks takes 13.6 s\n",
      "process 14500 peaks takes 13.6 s\n",
      "process 14550 peaks takes 13.7 s\n",
      "process 14600 peaks takes 13.7 s\n",
      "process 14650 peaks takes 13.8 s\n",
      "process 14700 peaks takes 13.8 s\n",
      "process 14750 peaks takes 13.8 s\n",
      "process 14800 peaks takes 13.9 s\n",
      "process 14850 peaks takes 13.9 s\n",
      "process 14900 peaks takes 14.0 s\n",
      "process 14950 peaks takes 14.0 s\n",
      "process 15000 peaks takes 14.1 s\n",
      "process 15050 peaks takes 14.1 s\n",
      "process 15100 peaks takes 14.2 s\n",
      "process 15150 peaks takes 14.2 s\n",
      "process 15200 peaks takes 14.2 s\n",
      "process 15250 peaks takes 14.3 s\n",
      "process 15300 peaks takes 14.3 s\n",
      "process 15350 peaks takes 14.4 s\n",
      "process 15400 peaks takes 14.4 s\n",
      "process 15450 peaks takes 14.5 s\n",
      "process 15500 peaks takes 14.5 s\n",
      "process 15550 peaks takes 14.6 s\n",
      "process 15600 peaks takes 14.6 s\n",
      "process 15650 peaks takes 14.7 s\n",
      "process 15700 peaks takes 14.7 s\n",
      "process 15750 peaks takes 14.8 s\n",
      "process 15800 peaks takes 14.8 s\n",
      "process 15850 peaks takes 14.8 s\n",
      "process 15900 peaks takes 14.9 s\n",
      "process 15950 peaks takes 14.9 s\n",
      "process 16000 peaks takes 15.0 s\n",
      "process 16050 peaks takes 15.0 s\n",
      "process 16100 peaks takes 15.1 s\n",
      "process 16150 peaks takes 15.1 s\n",
      "process 16200 peaks takes 15.1 s\n",
      "process 16250 peaks takes 15.2 s\n",
      "process 16300 peaks takes 15.2 s\n",
      "process 16350 peaks takes 15.3 s\n",
      "process 16400 peaks takes 15.3 s\n",
      "process 16450 peaks takes 15.4 s\n",
      "process 16500 peaks takes 15.4 s\n",
      "process 16550 peaks takes 15.5 s\n",
      "process 16600 peaks takes 15.5 s\n",
      "process 16650 peaks takes 15.6 s\n",
      "process 16700 peaks takes 15.6 s\n",
      "process 16750 peaks takes 15.7 s\n",
      "process 16800 peaks takes 15.7 s\n",
      "process 16850 peaks takes 15.7 s\n",
      "process 16900 peaks takes 15.8 s\n",
      "process 16950 peaks takes 15.8 s\n",
      "process 17000 peaks takes 15.9 s\n",
      "process 17050 peaks takes 15.9 s\n",
      "process 17100 peaks takes 16.0 s\n",
      "process 17150 peaks takes 16.0 s\n",
      "process 17200 peaks takes 16.0 s\n",
      "process 17250 peaks takes 16.1 s\n",
      "process 17300 peaks takes 16.1 s\n",
      "process 17350 peaks takes 16.2 s\n",
      "process 17400 peaks takes 16.2 s\n",
      "process 17450 peaks takes 16.3 s\n",
      "process 17500 peaks takes 16.3 s\n",
      "process 17550 peaks takes 16.4 s\n",
      "process 17600 peaks takes 16.4 s\n",
      "process 17650 peaks takes 16.4 s\n",
      "process 17700 peaks takes 16.5 s\n",
      "process 17750 peaks takes 16.5 s\n",
      "process 17800 peaks takes 16.6 s\n",
      "process 17850 peaks takes 16.6 s\n",
      "process 17900 peaks takes 16.7 s\n",
      "process 17950 peaks takes 16.7 s\n",
      "process 18000 peaks takes 16.8 s\n",
      "process 18050 peaks takes 16.8 s\n",
      "process 18100 peaks takes 16.9 s\n",
      "process 18150 peaks takes 16.9 s\n",
      "process 18200 peaks takes 16.9 s\n",
      "process 18250 peaks takes 17.0 s\n",
      "process 18300 peaks takes 17.0 s\n",
      "process 18350 peaks takes 17.1 s\n",
      "process 18400 peaks takes 17.1 s\n",
      "process 18450 peaks takes 17.2 s\n",
      "process 18500 peaks takes 17.2 s\n",
      "process 18550 peaks takes 17.3 s\n",
      "process 18600 peaks takes 17.3 s\n",
      "process 18650 peaks takes 17.4 s\n",
      "process 18700 peaks takes 17.4 s\n",
      "process 18750 peaks takes 17.5 s\n",
      "process 18800 peaks takes 17.5 s\n",
      "process 18850 peaks takes 17.6 s\n",
      "process 18900 peaks takes 17.6 s\n",
      "process 18950 peaks takes 17.7 s\n",
      "process 19000 peaks takes 17.7 s\n",
      "process 19050 peaks takes 17.8 s\n",
      "process 19100 peaks takes 17.8 s\n",
      "process 19150 peaks takes 17.8 s\n",
      "process 19200 peaks takes 17.9 s\n",
      "process 19250 peaks takes 17.9 s\n",
      "process 19300 peaks takes 18.0 s\n",
      "process 19350 peaks takes 18.0 s\n",
      "process 19400 peaks takes 18.1 s\n",
      "process 19450 peaks takes 18.1 s\n",
      "process 19500 peaks takes 18.2 s\n",
      "process 19550 peaks takes 18.2 s\n",
      "process 19600 peaks takes 18.3 s\n",
      "process 19650 peaks takes 18.4 s\n",
      "process 19700 peaks takes 18.4 s\n",
      "process 19750 peaks takes 18.5 s\n",
      "process 19800 peaks takes 18.5 s\n",
      "process 19850 peaks takes 18.5 s\n",
      "process 19900 peaks takes 18.6 s\n",
      "process 19950 peaks takes 18.6 s\n",
      "process 20000 peaks takes 18.7 s\n",
      "process 20050 peaks takes 18.7 s\n",
      "process 20100 peaks takes 18.8 s\n",
      "process 20150 peaks takes 18.8 s\n",
      "process 20200 peaks takes 18.9 s\n",
      "process 20250 peaks takes 18.9 s\n",
      "process 20300 peaks takes 19.0 s\n",
      "process 20350 peaks takes 19.0 s\n",
      "process 20400 peaks takes 19.0 s\n",
      "process 20450 peaks takes 19.1 s\n",
      "process 20500 peaks takes 19.1 s\n",
      "process 20550 peaks takes 19.2 s\n",
      "process 20600 peaks takes 19.2 s\n",
      "process 20650 peaks takes 19.3 s\n",
      "process 20700 peaks takes 19.3 s\n",
      "process 20750 peaks takes 19.4 s\n",
      "process 20800 peaks takes 19.4 s\n",
      "process 20850 peaks takes 19.5 s\n",
      "process 20900 peaks takes 19.5 s\n",
      "process 20950 peaks takes 19.6 s\n",
      "process 21000 peaks takes 19.6 s\n",
      "process 21050 peaks takes 19.6 s\n",
      "process 21100 peaks takes 19.7 s\n",
      "process 21150 peaks takes 19.7 s\n",
      "process 21200 peaks takes 19.8 s\n",
      "process 21250 peaks takes 19.8 s\n",
      "process 21300 peaks takes 19.9 s\n",
      "process 21350 peaks takes 19.9 s\n",
      "process 21400 peaks takes 20.0 s\n",
      "process 21450 peaks takes 20.0 s\n",
      "process 21500 peaks takes 20.0 s\n",
      "process 21550 peaks takes 20.1 s\n",
      "process 21600 peaks takes 20.1 s\n",
      "process 21650 peaks takes 20.2 s\n",
      "process 21700 peaks takes 20.2 s\n",
      "process 21750 peaks takes 20.3 s\n",
      "process 21800 peaks takes 20.3 s\n",
      "process 21850 peaks takes 20.4 s\n",
      "process 21900 peaks takes 20.4 s\n",
      "process 21950 peaks takes 20.5 s\n",
      "process 22000 peaks takes 20.5 s\n",
      "process 22050 peaks takes 20.5 s\n",
      "process 22100 peaks takes 20.6 s\n",
      "process 22150 peaks takes 20.6 s\n",
      "process 22200 peaks takes 20.7 s\n",
      "process 22250 peaks takes 20.7 s\n",
      "process 22300 peaks takes 20.8 s\n",
      "process 22350 peaks takes 20.8 s\n",
      "process 22400 peaks takes 20.8 s\n",
      "process 22450 peaks takes 20.9 s\n",
      "process 22500 peaks takes 20.9 s\n",
      "process 22550 peaks takes 21.0 s\n",
      "process 22600 peaks takes 21.0 s\n",
      "process 22650 peaks takes 21.1 s\n",
      "process 22700 peaks takes 21.1 s\n",
      "process 22750 peaks takes 21.2 s\n",
      "process 22800 peaks takes 21.2 s\n",
      "process 22850 peaks takes 21.3 s\n",
      "process 22900 peaks takes 21.3 s\n",
      "process 22950 peaks takes 21.3 s\n",
      "process 23000 peaks takes 21.4 s\n",
      "process 23050 peaks takes 21.4 s\n",
      "process 23100 peaks takes 21.5 s\n",
      "process 23150 peaks takes 21.5 s\n",
      "process 23200 peaks takes 21.6 s\n",
      "process 23250 peaks takes 21.6 s\n",
      "process 23300 peaks takes 21.6 s\n",
      "process 23350 peaks takes 21.7 s\n",
      "process 23400 peaks takes 21.7 s\n",
      "process 23450 peaks takes 21.8 s\n",
      "process 23500 peaks takes 21.8 s\n",
      "process 23550 peaks takes 21.9 s\n",
      "process 23600 peaks takes 21.9 s\n",
      "process 23650 peaks takes 22.0 s\n",
      "process 23700 peaks takes 22.0 s\n",
      "process 23750 peaks takes 22.1 s\n",
      "process 23800 peaks takes 22.1 s\n",
      "process 23850 peaks takes 22.2 s\n",
      "process 23900 peaks takes 22.2 s\n",
      "process 23950 peaks takes 22.2 s\n",
      "process 24000 peaks takes 22.3 s\n",
      "process 24050 peaks takes 22.3 s\n",
      "process 24100 peaks takes 22.4 s\n",
      "process 24150 peaks takes 22.4 s\n",
      "process 24200 peaks takes 22.5 s\n",
      "process 24250 peaks takes 22.5 s\n",
      "process 24300 peaks takes 22.6 s\n",
      "process 24350 peaks takes 22.6 s\n",
      "process 24400 peaks takes 22.7 s\n",
      "process 24450 peaks takes 22.7 s\n",
      "process 24500 peaks takes 22.7 s\n",
      "process 24550 peaks takes 22.8 s\n",
      "process 24600 peaks takes 22.8 s\n",
      "process 24650 peaks takes 22.9 s\n",
      "process 24700 peaks takes 22.9 s\n",
      "process 24750 peaks takes 23.0 s\n",
      "process 24800 peaks takes 23.0 s\n",
      "process 24850 peaks takes 23.1 s\n",
      "process 24900 peaks takes 23.1 s\n",
      "process 24950 peaks takes 23.1 s\n",
      "process 25000 peaks takes 23.2 s\n",
      "process 25050 peaks takes 23.2 s\n",
      "process 25100 peaks takes 23.3 s\n",
      "process 25150 peaks takes 23.3 s\n",
      "process 25200 peaks takes 23.4 s\n",
      "process 25250 peaks takes 23.4 s\n",
      "process 25300 peaks takes 23.5 s\n",
      "process 25350 peaks takes 23.5 s\n",
      "process 25400 peaks takes 23.6 s\n",
      "process 25450 peaks takes 23.6 s\n",
      "process 25500 peaks takes 23.7 s\n",
      "process 25550 peaks takes 23.7 s\n",
      "process 25600 peaks takes 23.8 s\n",
      "process 25650 peaks takes 23.8 s\n",
      "process 25700 peaks takes 23.9 s\n",
      "process 25750 peaks takes 23.9 s\n",
      "process 25800 peaks takes 24.0 s\n",
      "process 25850 peaks takes 24.0 s\n",
      "process 25900 peaks takes 24.1 s\n",
      "process 25950 peaks takes 24.1 s\n",
      "process 26000 peaks takes 24.1 s\n",
      "process 26050 peaks takes 24.2 s\n",
      "process 26100 peaks takes 24.2 s\n",
      "process 26150 peaks takes 24.3 s\n",
      "process 26200 peaks takes 24.3 s\n",
      "process 26250 peaks takes 24.4 s\n",
      "process 26300 peaks takes 24.4 s\n",
      "process 26350 peaks takes 24.5 s\n",
      "process 26400 peaks takes 24.5 s\n",
      "process 26450 peaks takes 24.6 s\n",
      "process 26500 peaks takes 24.6 s\n",
      "process 26550 peaks takes 24.6 s\n",
      "process 26600 peaks takes 24.7 s\n",
      "process 26650 peaks takes 24.7 s\n",
      "process 26700 peaks takes 24.8 s\n",
      "process 26750 peaks takes 24.8 s\n",
      "process 26800 peaks takes 24.9 s\n",
      "process 26850 peaks takes 24.9 s\n",
      "process 26900 peaks takes 25.0 s\n",
      "process 26950 peaks takes 25.0 s\n",
      "\n",
      "test\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "\n",
      "val\n",
      "1499 29\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.5 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.6 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.7 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs10000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs10000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:43:20.810782: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:43:20.914730: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:43:20.918076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:20.918108: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:43:21.447177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:21.447248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:21.447254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:43:23.298842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:43:23.298945: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:43:23.299299: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:43:23.299822: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 10000)     330000      ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 10000)    0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10000)        0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,849,810\n",
      "Trainable params: 4,843,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "211/211 [==============================] - 366s 2s/step - loss: 0.0988 - auc: 0.4993 - auc_1: 0.0080 - val_loss: 0.0452 - val_auc: 0.4979 - val_auc_1: 0.0090\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs10000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "pancreatic_endocrinogenesis episcanpy /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs1000_e1/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "(1000, 3000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000 --batch 50\n",
      "2024-05-13 07:49:32.089152: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:49:32.221944: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:49:32.228497: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:32.228540: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:49:32.791513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:32.791629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:32.791641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[2701, 150, 149]\n",
      "3000 60\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.8 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.9 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 2.0 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.1 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.2 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.4 s\n",
      "process 2050 peaks takes 2.4 s\n",
      "process 2100 peaks takes 2.5 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.6 s\n",
      "process 2250 peaks takes 2.7 s\n",
      "process 2300 peaks takes 2.7 s\n",
      "process 2350 peaks takes 2.8 s\n",
      "process 2400 peaks takes 2.9 s\n",
      "process 2450 peaks takes 2.9 s\n",
      "process 2500 peaks takes 3.0 s\n",
      "process 2550 peaks takes 3.0 s\n",
      "process 2600 peaks takes 3.1 s\n",
      "process 2650 peaks takes 3.2 s\n",
      "process 2700 peaks takes 3.2 s\n",
      "process 2750 peaks takes 3.3 s\n",
      "process 2800 peaks takes 3.3 s\n",
      "process 2850 peaks takes 3.4 s\n",
      "process 2900 peaks takes 3.5 s\n",
      "process 2950 peaks takes 3.5 s\n",
      "\n",
      "train\n",
      "2701 54\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.6 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.2 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.4 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.5 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.6 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.7 s\n",
      "process 1450 peaks takes 1.8 s\n",
      "process 1500 peaks takes 1.8 s\n",
      "process 1550 peaks takes 1.9 s\n",
      "process 1600 peaks takes 1.9 s\n",
      "process 1650 peaks takes 2.0 s\n",
      "process 1700 peaks takes 2.0 s\n",
      "process 1750 peaks takes 2.1 s\n",
      "process 1800 peaks takes 2.2 s\n",
      "process 1850 peaks takes 2.2 s\n",
      "process 1900 peaks takes 2.3 s\n",
      "process 1950 peaks takes 2.3 s\n",
      "process 2000 peaks takes 2.4 s\n",
      "process 2050 peaks takes 2.4 s\n",
      "process 2100 peaks takes 2.5 s\n",
      "process 2150 peaks takes 2.5 s\n",
      "process 2200 peaks takes 2.6 s\n",
      "process 2250 peaks takes 2.7 s\n",
      "process 2300 peaks takes 2.7 s\n",
      "process 2350 peaks takes 2.8 s\n",
      "process 2400 peaks takes 2.8 s\n",
      "process 2450 peaks takes 2.9 s\n",
      "process 2500 peaks takes 2.9 s\n",
      "process 2550 peaks takes 3.0 s\n",
      "process 2600 peaks takes 3.1 s\n",
      "process 2650 peaks takes 3.1 s\n",
      "\n",
      "test\n",
      "150 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "149 2\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs1000_e1/poisson\n",
      "about to train...\n",
      "2024-05-13 07:49:41.751528: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:49:41.876141: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:49:41.879342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:41.879377: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:49:42.409143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:42.409246: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:42.409255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 07:49:44.095427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:49:44.095541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095736: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:49:44.095877: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:49:44.096201: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "22/22 [==============================] - 49s 2s/step - loss: 0.2562 - auc: 0.4853 - auc_1: 0.0042 - val_loss: 0.0429 - val_auc: 0.1586 - val_auc_1: 0.0067\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs1000_e1/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs1000_e1/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad\n",
      "(1000, 3000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/pancreas_multiome_2022_processed_atac_obs1000_var3000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000 --batch 50\n",
      "2024-05-13 07:50:36.333602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:50:36.448573: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:50:36.451543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:36.451575: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:50:36.930304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:36.930380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:36.930387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[2701, 150, 149]\n",
      "3000 60\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.4 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.5 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.6 s\n",
      "process 2400 peaks takes 2.6 s\n",
      "process 2450 peaks takes 2.7 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.8 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 3.0 s\n",
      "process 2750 peaks takes 3.0 s\n",
      "process 2800 peaks takes 3.1 s\n",
      "process 2850 peaks takes 3.1 s\n",
      "process 2900 peaks takes 3.2 s\n",
      "process 2950 peaks takes 3.2 s\n",
      "\n",
      "train\n",
      "2701 54\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.5 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.6 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "process 1500 peaks takes 1.7 s\n",
      "process 1550 peaks takes 1.8 s\n",
      "process 1600 peaks takes 1.8 s\n",
      "process 1650 peaks takes 1.9 s\n",
      "process 1700 peaks takes 1.9 s\n",
      "process 1750 peaks takes 2.0 s\n",
      "process 1800 peaks takes 2.0 s\n",
      "process 1850 peaks takes 2.1 s\n",
      "process 1900 peaks takes 2.1 s\n",
      "process 1950 peaks takes 2.2 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.3 s\n",
      "process 2100 peaks takes 2.4 s\n",
      "process 2150 peaks takes 2.4 s\n",
      "process 2200 peaks takes 2.5 s\n",
      "process 2250 peaks takes 2.5 s\n",
      "process 2300 peaks takes 2.6 s\n",
      "process 2350 peaks takes 2.7 s\n",
      "process 2400 peaks takes 2.7 s\n",
      "process 2450 peaks takes 2.8 s\n",
      "process 2500 peaks takes 2.8 s\n",
      "process 2550 peaks takes 2.9 s\n",
      "process 2600 peaks takes 2.9 s\n",
      "process 2650 peaks takes 3.0 s\n",
      "\n",
      "test\n",
      "150 3\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "\n",
      "val\n",
      "149 2\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_input/obs1000 --epochs 1 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs1000_e1/bce\n",
      "about to train...\n",
      "2024-05-13 07:50:45.357462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:50:45.480557: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:50:45.483514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:45.483543: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:50:45.969243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:45.969329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:45.969335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 07:50:47.530800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:50:47.530910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531237: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:50:47.531254: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:50:47.531604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1000)      33000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 1000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "22/22 [==============================] - 40s 2s/step - loss: 0.4028 - auc: 0.4939 - auc_1: 0.0040 - val_loss: 0.0545 - val_auc: 0.1577 - val_auc_1: 0.0069\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/episcanpy/scbasset_output/obs1000_e1/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500\n",
      "out True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e10/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "(500, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --batch 50\n",
      "2024-05-13 07:51:30.328473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:51:30.433356: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:51:30.436570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:30.436604: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:51:30.933554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:30.933652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:30.933673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "process 0 peaks takes 0.0 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "process 1350 peaks takes 1.6 s\n",
      "process 1400 peaks takes 1.7 s\n",
      "process 1450 peaks takes 1.7 s\n",
      "\n",
      "train\n",
      "1351 27\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.7 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.8 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 1.0 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.1 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.3 s\n",
      "process 1100 peaks takes 1.3 s\n",
      "process 1150 peaks takes 1.4 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.5 s\n",
      "process 1300 peaks takes 1.5 s\n",
      "\n",
      "test\n",
      "75 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "val\n",
      "74 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e10/poisson\n",
      "about to train...\n",
      "2024-05-13 07:51:36.248659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:51:36.350948: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:51:36.354394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:36.354444: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:51:36.873042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:36.873123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:36.873159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 07:51:38.402429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:51:38.402547: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402659: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402838: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:51:38.402902: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:51:38.403236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.4449 - auc: 0.5876 - auc_1: 0.0718 - val_loss: 0.4428 - val_auc: 0.6360 - val_auc_1: 0.1667\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.2529 - auc: 0.6775 - auc_1: 0.1489 - val_loss: 0.2657 - val_auc: 0.6837 - val_auc_1: 0.1333\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.2076 - auc: 0.7416 - auc_1: 0.2183 - val_loss: 0.2598 - val_auc: 0.6657 - val_auc_1: 0.1062\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 17s 1s/step - loss: 0.1966 - auc: 0.7353 - auc_1: 0.2346 - val_loss: 0.2841 - val_auc: 0.6816 - val_auc_1: 0.1207\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1921 - auc: 0.7534 - auc_1: 0.2564 - val_loss: 0.4963 - val_auc: 0.3489 - val_auc_1: 0.0499\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.1935 - auc: 0.7482 - auc_1: 0.2314 - val_loss: 0.2235 - val_auc: 0.7105 - val_auc_1: 0.1615\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1906 - auc: 0.7564 - auc_1: 0.2432 - val_loss: 0.1823 - val_auc: 0.7418 - val_auc_1: 0.3193\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.1897 - auc: 0.7470 - auc_1: 0.2475 - val_loss: 0.1848 - val_auc: 0.7344 - val_auc_1: 0.3211\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1892 - auc: 0.7589 - auc_1: 0.2574 - val_loss: 0.1943 - val_auc: 0.7319 - val_auc_1: 0.2580\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.1882 - auc: 0.7445 - auc_1: 0.2715 - val_loss: 0.1909 - val_auc: 0.7374 - val_auc_1: 0.3016\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e10/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500\n",
      "out True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e10/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad\n",
      "(500, 1500)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs500_var1500.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --batch 50\n",
      "2024-05-13 07:55:14.866230: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:55:14.971790: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:55:14.975096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:14.975138: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:55:15.450311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:15.450385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:15.450391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[1351, 75, 74]\n",
      "1500 30\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "\n",
      "train\n",
      "1351 27\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.1 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.2 s\n",
      "process 250 peaks takes 0.3 s\n",
      "process 300 peaks takes 0.3 s\n",
      "process 350 peaks takes 0.4 s\n",
      "process 400 peaks takes 0.4 s\n",
      "process 450 peaks takes 0.5 s\n",
      "process 500 peaks takes 0.5 s\n",
      "process 550 peaks takes 0.6 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.7 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.8 s\n",
      "process 800 peaks takes 0.8 s\n",
      "process 850 peaks takes 0.9 s\n",
      "process 900 peaks takes 0.9 s\n",
      "process 950 peaks takes 1.0 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.1 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "\n",
      "test\n",
      "75 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "val\n",
      "74 1\n",
      "process 0 peaks takes 0.1 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs500 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e10/bce\n",
      "about to train...\n",
      "2024-05-13 07:55:20.465544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:55:20.570787: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:55:20.573618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:20.573647: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:55:21.070329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:21.070409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:21.070416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-05-13 07:55:22.601377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:55:22.601512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:55:22.601894: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:55:22.602281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 500)       16500       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 500)      0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 500)          0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,536,310\n",
      "Trainable params: 4,530,460\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.6070 - auc: 0.5819 - auc_1: 0.0726 - val_loss: 0.9412 - val_auc: 0.5771 - val_auc_1: 0.1715\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.3356 - auc: 0.6657 - auc_1: 0.1039 - val_loss: 0.2918 - val_auc: 0.5340 - val_auc_1: 0.1220\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.2186 - auc: 0.6971 - auc_1: 0.1702 - val_loss: 0.2397 - val_auc: 0.6581 - val_auc_1: 0.1211\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 17s 1s/step - loss: 0.2117 - auc: 0.7225 - auc_1: 0.1942 - val_loss: 0.2254 - val_auc: 0.7124 - val_auc_1: 0.2327\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.2071 - auc: 0.7361 - auc_1: 0.2244 - val_loss: 0.2148 - val_auc: 0.6870 - val_auc_1: 0.2258\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.1958 - auc: 0.7375 - auc_1: 0.2438 - val_loss: 0.1965 - val_auc: 0.7166 - val_auc_1: 0.3008\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1915 - auc: 0.7384 - auc_1: 0.2304 - val_loss: 0.1790 - val_auc: 0.7175 - val_auc_1: 0.2577\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 17s 1s/step - loss: 0.1859 - auc: 0.7497 - auc_1: 0.2578 - val_loss: 0.1884 - val_auc: 0.7208 - val_auc_1: 0.2360\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 17s 1s/step - loss: 0.1859 - auc: 0.7548 - auc_1: 0.2485 - val_loss: 0.1846 - val_auc: 0.7069 - val_auc_1: 0.2415\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 17s 1s/step - loss: 0.1853 - auc: 0.7433 - auc_1: 0.2471 - val_loss: 0.1902 - val_auc: 0.7247 - val_auc_1: 0.2487\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs500_e10/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e10/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 07:58:50.808216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:58:50.922820: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:58:50.925721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:58:50.925755: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:58:51.466790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:58:51.466899: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:58:51.466907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.8 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 0.9 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.0 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.2 s\n",
      "process 1200 peaks takes 1.3 s\n",
      "process 1250 peaks takes 1.3 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.4 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.2 s\n",
      "process 2050 peaks takes 2.2 s\n",
      "process 2100 peaks takes 2.3 s\n",
      "process 2150 peaks takes 2.3 s\n",
      "process 2200 peaks takes 2.4 s\n",
      "process 2250 peaks takes 2.4 s\n",
      "process 2300 peaks takes 2.5 s\n",
      "process 2350 peaks takes 2.5 s\n",
      "process 2400 peaks takes 2.6 s\n",
      "process 2450 peaks takes 2.6 s\n",
      "process 2500 peaks takes 2.7 s\n",
      "process 2550 peaks takes 2.7 s\n",
      "process 2600 peaks takes 2.8 s\n",
      "process 2650 peaks takes 2.9 s\n",
      "process 2700 peaks takes 2.9 s\n",
      "process 2750 peaks takes 3.0 s\n",
      "process 2800 peaks takes 3.0 s\n",
      "process 2850 peaks takes 3.1 s\n",
      "process 2900 peaks takes 3.1 s\n",
      "process 2950 peaks takes 3.2 s\n",
      "process 3000 peaks takes 3.3 s\n",
      "process 3050 peaks takes 3.3 s\n",
      "process 3100 peaks takes 3.4 s\n",
      "process 3150 peaks takes 3.4 s\n",
      "process 3200 peaks takes 3.5 s\n",
      "process 3250 peaks takes 3.5 s\n",
      "process 3300 peaks takes 3.6 s\n",
      "process 3350 peaks takes 3.6 s\n",
      "process 3400 peaks takes 3.7 s\n",
      "process 3450 peaks takes 3.8 s\n",
      "process 3500 peaks takes 3.8 s\n",
      "process 3550 peaks takes 3.9 s\n",
      "process 3600 peaks takes 3.9 s\n",
      "process 3650 peaks takes 4.0 s\n",
      "process 3700 peaks takes 4.0 s\n",
      "process 3750 peaks takes 4.0 s\n",
      "process 3800 peaks takes 4.1 s\n",
      "process 3850 peaks takes 4.1 s\n",
      "process 3900 peaks takes 4.2 s\n",
      "process 3950 peaks takes 4.3 s\n",
      "process 4000 peaks takes 4.3 s\n",
      "process 4050 peaks takes 4.3 s\n",
      "process 4100 peaks takes 4.4 s\n",
      "process 4150 peaks takes 4.5 s\n",
      "process 4200 peaks takes 4.5 s\n",
      "process 4250 peaks takes 4.5 s\n",
      "process 4300 peaks takes 4.6 s\n",
      "process 4350 peaks takes 4.6 s\n",
      "process 4400 peaks takes 4.7 s\n",
      "process 4450 peaks takes 4.8 s\n",
      "process 4500 peaks takes 4.8 s\n",
      "process 4550 peaks takes 4.9 s\n",
      "process 4600 peaks takes 4.9 s\n",
      "process 4650 peaks takes 5.0 s\n",
      "process 4700 peaks takes 5.0 s\n",
      "process 4750 peaks takes 5.1 s\n",
      "process 4800 peaks takes 5.1 s\n",
      "process 4850 peaks takes 5.2 s\n",
      "process 4900 peaks takes 5.2 s\n",
      "process 4950 peaks takes 5.3 s\n",
      "process 5000 peaks takes 5.3 s\n",
      "process 5050 peaks takes 5.4 s\n",
      "process 5100 peaks takes 5.5 s\n",
      "process 5150 peaks takes 5.5 s\n",
      "process 5200 peaks takes 5.5 s\n",
      "process 5250 peaks takes 5.6 s\n",
      "process 5300 peaks takes 5.7 s\n",
      "process 5350 peaks takes 5.7 s\n",
      "process 5400 peaks takes 5.8 s\n",
      "process 5450 peaks takes 5.8 s\n",
      "process 5500 peaks takes 5.8 s\n",
      "process 5550 peaks takes 5.9 s\n",
      "process 5600 peaks takes 6.0 s\n",
      "process 5650 peaks takes 6.0 s\n",
      "process 5700 peaks takes 6.1 s\n",
      "process 5750 peaks takes 6.1 s\n",
      "process 5800 peaks takes 6.2 s\n",
      "process 5850 peaks takes 6.2 s\n",
      "process 5900 peaks takes 6.3 s\n",
      "process 5950 peaks takes 6.3 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.4 s\n",
      "process 300 peaks takes 0.4 s\n",
      "process 350 peaks takes 0.5 s\n",
      "process 400 peaks takes 0.5 s\n",
      "process 450 peaks takes 0.6 s\n",
      "process 500 peaks takes 0.6 s\n",
      "process 550 peaks takes 0.7 s\n",
      "process 600 peaks takes 0.7 s\n",
      "process 650 peaks takes 0.8 s\n",
      "process 700 peaks takes 0.9 s\n",
      "process 750 peaks takes 0.9 s\n",
      "process 800 peaks takes 1.0 s\n",
      "process 850 peaks takes 1.0 s\n",
      "process 900 peaks takes 1.1 s\n",
      "process 950 peaks takes 1.1 s\n",
      "process 1000 peaks takes 1.2 s\n",
      "process 1050 peaks takes 1.2 s\n",
      "process 1100 peaks takes 1.2 s\n",
      "process 1150 peaks takes 1.3 s\n",
      "process 1200 peaks takes 1.4 s\n",
      "process 1250 peaks takes 1.4 s\n",
      "process 1300 peaks takes 1.4 s\n",
      "process 1350 peaks takes 1.5 s\n",
      "process 1400 peaks takes 1.5 s\n",
      "process 1450 peaks takes 1.6 s\n",
      "process 1500 peaks takes 1.6 s\n",
      "process 1550 peaks takes 1.7 s\n",
      "process 1600 peaks takes 1.7 s\n",
      "process 1650 peaks takes 1.8 s\n",
      "process 1700 peaks takes 1.8 s\n",
      "process 1750 peaks takes 1.9 s\n",
      "process 1800 peaks takes 1.9 s\n",
      "process 1850 peaks takes 2.0 s\n",
      "process 1900 peaks takes 2.0 s\n",
      "process 1950 peaks takes 2.1 s\n",
      "process 2000 peaks takes 2.1 s\n",
      "process 2050 peaks takes 2.1 s\n",
      "process 2100 peaks takes 2.2 s\n",
      "process 2150 peaks takes 2.2 s\n",
      "process 2200 peaks takes 2.3 s\n",
      "process 2250 peaks takes 2.3 s\n",
      "process 2300 peaks takes 2.4 s\n",
      "process 2350 peaks takes 2.4 s\n",
      "process 2400 peaks takes 2.5 s\n",
      "process 2450 peaks takes 2.5 s\n",
      "process 2500 peaks takes 2.6 s\n",
      "process 2550 peaks takes 2.6 s\n",
      "process 2600 peaks takes 2.7 s\n",
      "process 2650 peaks takes 2.7 s\n",
      "process 2700 peaks takes 2.8 s\n",
      "process 2750 peaks takes 2.8 s\n",
      "process 2800 peaks takes 2.9 s\n",
      "process 2850 peaks takes 2.9 s\n",
      "process 2900 peaks takes 3.0 s\n",
      "process 2950 peaks takes 3.0 s\n",
      "process 3000 peaks takes 3.1 s\n",
      "process 3050 peaks takes 3.1 s\n",
      "process 3100 peaks takes 3.2 s\n",
      "process 3150 peaks takes 3.2 s\n",
      "process 3200 peaks takes 3.3 s\n",
      "process 3250 peaks takes 3.3 s\n",
      "process 3300 peaks takes 3.4 s\n",
      "process 3350 peaks takes 3.5 s\n",
      "process 3400 peaks takes 3.5 s\n",
      "process 3450 peaks takes 3.5 s\n",
      "process 3500 peaks takes 3.6 s\n",
      "process 3550 peaks takes 3.6 s\n",
      "process 3600 peaks takes 3.7 s\n",
      "process 3650 peaks takes 3.7 s\n",
      "process 3700 peaks takes 3.8 s\n",
      "process 3750 peaks takes 3.8 s\n",
      "process 3800 peaks takes 3.9 s\n",
      "process 3850 peaks takes 3.9 s\n",
      "process 3900 peaks takes 4.0 s\n",
      "process 3950 peaks takes 4.0 s\n",
      "process 4000 peaks takes 4.1 s\n",
      "process 4050 peaks takes 4.1 s\n",
      "process 4100 peaks takes 4.2 s\n",
      "process 4150 peaks takes 4.2 s\n",
      "process 4200 peaks takes 4.3 s\n",
      "process 4250 peaks takes 4.3 s\n",
      "process 4300 peaks takes 4.4 s\n",
      "process 4350 peaks takes 4.4 s\n",
      "process 4400 peaks takes 4.4 s\n",
      "process 4450 peaks takes 4.5 s\n",
      "process 4500 peaks takes 4.5 s\n",
      "process 4550 peaks takes 4.6 s\n",
      "process 4600 peaks takes 4.6 s\n",
      "process 4650 peaks takes 4.7 s\n",
      "process 4700 peaks takes 4.7 s\n",
      "process 4750 peaks takes 4.8 s\n",
      "process 4800 peaks takes 4.8 s\n",
      "process 4850 peaks takes 4.9 s\n",
      "process 4900 peaks takes 4.9 s\n",
      "process 4950 peaks takes 5.0 s\n",
      "process 5000 peaks takes 5.0 s\n",
      "process 5050 peaks takes 5.1 s\n",
      "process 5100 peaks takes 5.1 s\n",
      "process 5150 peaks takes 5.1 s\n",
      "process 5200 peaks takes 5.2 s\n",
      "process 5250 peaks takes 5.2 s\n",
      "process 5300 peaks takes 5.3 s\n",
      "process 5350 peaks takes 5.3 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.2 s\n",
      "process 200 peaks takes 0.3 s\n",
      "process 250 peaks takes 0.3 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.1 s\n",
      "process 100 peaks takes 0.2 s\n",
      "process 150 peaks takes 0.3 s\n",
      "process 200 peaks takes 0.3 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e10/poisson\n",
      "about to train...\n",
      "2024-05-13 07:59:05.835651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 07:59:05.937478: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 07:59:05.940450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:05.940479: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 07:59:06.446171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:06.446242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:06.446262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 07:59:08.051446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 07:59:08.051560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051603: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051718: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051754: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051839: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 07:59:08.051856: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 07:59:08.052194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 72s 2s/step - loss: 0.2846 - auc: 0.6588 - auc_1: 0.0981 - val_loss: 0.5225 - val_auc: 0.7260 - val_auc_1: 0.3155\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 84s 2s/step - loss: 0.1989 - auc: 0.7327 - auc_1: 0.2226 - val_loss: 0.2207 - val_auc: 0.7772 - val_auc_1: 0.3464\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 83s 2s/step - loss: 0.1943 - auc: 0.7383 - auc_1: 0.2366 - val_loss: 0.2026 - val_auc: 0.7708 - val_auc_1: 0.3464\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 82s 2s/step - loss: 0.1920 - auc: 0.7419 - auc_1: 0.2434 - val_loss: 0.2036 - val_auc: 0.7786 - val_auc_1: 0.3605\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 70s 2s/step - loss: 0.1910 - auc: 0.7455 - auc_1: 0.2526 - val_loss: 0.2082 - val_auc: 0.7856 - val_auc_1: 0.3533\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 85s 2s/step - loss: 0.1903 - auc: 0.7510 - auc_1: 0.2535 - val_loss: 0.2005 - val_auc: 0.7856 - val_auc_1: 0.3582\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 82s 2s/step - loss: 0.1907 - auc: 0.7473 - auc_1: 0.2572 - val_loss: 0.1994 - val_auc: 0.7842 - val_auc_1: 0.3570\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 95s 2s/step - loss: 0.1896 - auc: 0.7521 - auc_1: 0.2608 - val_loss: 0.2079 - val_auc: 0.7729 - val_auc_1: 0.3433\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 122s 3s/step - loss: 0.1896 - auc: 0.7507 - auc_1: 0.2576 - val_loss: 0.2169 - val_auc: 0.7829 - val_auc_1: 0.3497\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 127s 3s/step - loss: 0.1890 - auc: 0.7546 - auc_1: 0.2601 - val_loss: 0.1992 - val_auc: 0.7815 - val_auc_1: 0.3579\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e10/poisson/running_time.pkl\n",
      "\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e10/bce\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad\n",
      "(2000, 6000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs2000_var6000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --batch 50\n",
      "2024-05-13 08:14:16.141316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 08:14:16.391407: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 08:14:16.400559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:16.400659: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 08:14:17.794842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:17.795017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:17.795066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[5401, 300, 299]\n",
      "6000 120\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.3 s\n",
      "process 100 peaks takes 0.4 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.6 s\n",
      "process 250 peaks takes 0.8 s\n",
      "process 300 peaks takes 0.8 s\n",
      "process 350 peaks takes 0.9 s\n",
      "process 400 peaks takes 1.0 s\n",
      "process 450 peaks takes 1.2 s\n",
      "process 500 peaks takes 1.2 s\n",
      "process 550 peaks takes 1.3 s\n",
      "process 600 peaks takes 1.4 s\n",
      "process 650 peaks takes 1.6 s\n",
      "process 700 peaks takes 1.7 s\n",
      "process 750 peaks takes 1.8 s\n",
      "process 800 peaks takes 1.9 s\n",
      "process 850 peaks takes 2.0 s\n",
      "process 900 peaks takes 2.1 s\n",
      "process 950 peaks takes 2.2 s\n",
      "process 1000 peaks takes 2.3 s\n",
      "process 1050 peaks takes 2.5 s\n",
      "process 1100 peaks takes 2.6 s\n",
      "process 1150 peaks takes 2.9 s\n",
      "process 1200 peaks takes 3.0 s\n",
      "process 1250 peaks takes 3.1 s\n",
      "process 1300 peaks takes 3.2 s\n",
      "process 1350 peaks takes 3.3 s\n",
      "process 1400 peaks takes 3.4 s\n",
      "process 1450 peaks takes 3.5 s\n",
      "process 1500 peaks takes 3.6 s\n",
      "process 1550 peaks takes 3.7 s\n",
      "process 1600 peaks takes 3.8 s\n",
      "process 1650 peaks takes 3.9 s\n",
      "process 1700 peaks takes 4.0 s\n",
      "process 1750 peaks takes 4.1 s\n",
      "process 1800 peaks takes 4.2 s\n",
      "process 1850 peaks takes 4.3 s\n",
      "process 1900 peaks takes 4.4 s\n",
      "process 1950 peaks takes 4.5 s\n",
      "process 2000 peaks takes 4.6 s\n",
      "process 2050 peaks takes 4.7 s\n",
      "process 2100 peaks takes 4.8 s\n",
      "process 2150 peaks takes 4.9 s\n",
      "process 2200 peaks takes 5.0 s\n",
      "process 2250 peaks takes 5.1 s\n",
      "process 2300 peaks takes 5.2 s\n",
      "process 2350 peaks takes 5.3 s\n",
      "process 2400 peaks takes 5.3 s\n",
      "process 2450 peaks takes 5.5 s\n",
      "process 2500 peaks takes 5.6 s\n",
      "process 2550 peaks takes 5.7 s\n",
      "process 2600 peaks takes 5.7 s\n",
      "process 2650 peaks takes 5.9 s\n",
      "process 2700 peaks takes 6.0 s\n",
      "process 2750 peaks takes 6.1 s\n",
      "process 2800 peaks takes 6.1 s\n",
      "process 2850 peaks takes 6.2 s\n",
      "process 2900 peaks takes 6.4 s\n",
      "process 2950 peaks takes 6.4 s\n",
      "process 3000 peaks takes 6.5 s\n",
      "process 3050 peaks takes 6.7 s\n",
      "process 3100 peaks takes 6.8 s\n",
      "process 3150 peaks takes 6.9 s\n",
      "process 3200 peaks takes 7.0 s\n",
      "process 3250 peaks takes 7.1 s\n",
      "process 3300 peaks takes 7.2 s\n",
      "process 3350 peaks takes 7.3 s\n",
      "process 3400 peaks takes 7.4 s\n",
      "process 3450 peaks takes 7.5 s\n",
      "process 3500 peaks takes 7.6 s\n",
      "process 3550 peaks takes 7.8 s\n",
      "process 3600 peaks takes 7.9 s\n",
      "process 3650 peaks takes 8.0 s\n",
      "process 3700 peaks takes 8.2 s\n",
      "process 3750 peaks takes 8.4 s\n",
      "process 3800 peaks takes 8.6 s\n",
      "process 3850 peaks takes 8.7 s\n",
      "process 3900 peaks takes 8.8 s\n",
      "process 3950 peaks takes 8.9 s\n",
      "process 4000 peaks takes 9.0 s\n",
      "process 4050 peaks takes 9.1 s\n",
      "process 4100 peaks takes 9.2 s\n",
      "process 4150 peaks takes 9.3 s\n",
      "process 4200 peaks takes 9.4 s\n",
      "process 4250 peaks takes 9.5 s\n",
      "process 4300 peaks takes 9.6 s\n",
      "process 4350 peaks takes 9.7 s\n",
      "process 4400 peaks takes 9.8 s\n",
      "process 4450 peaks takes 9.9 s\n",
      "process 4500 peaks takes 10.0 s\n",
      "process 4550 peaks takes 10.1 s\n",
      "process 4600 peaks takes 10.2 s\n",
      "process 4650 peaks takes 10.4 s\n",
      "process 4700 peaks takes 10.5 s\n",
      "process 4750 peaks takes 10.6 s\n",
      "process 4800 peaks takes 10.7 s\n",
      "process 4850 peaks takes 10.8 s\n",
      "process 4900 peaks takes 10.9 s\n",
      "process 4950 peaks takes 11.0 s\n",
      "process 5000 peaks takes 11.1 s\n",
      "process 5050 peaks takes 11.2 s\n",
      "process 5100 peaks takes 11.3 s\n",
      "process 5150 peaks takes 11.4 s\n",
      "process 5200 peaks takes 11.5 s\n",
      "process 5250 peaks takes 11.6 s\n",
      "process 5300 peaks takes 11.7 s\n",
      "process 5350 peaks takes 11.8 s\n",
      "process 5400 peaks takes 12.0 s\n",
      "process 5450 peaks takes 12.2 s\n",
      "process 5500 peaks takes 12.3 s\n",
      "process 5550 peaks takes 12.4 s\n",
      "process 5600 peaks takes 12.5 s\n",
      "process 5650 peaks takes 12.6 s\n",
      "process 5700 peaks takes 12.7 s\n",
      "process 5750 peaks takes 12.9 s\n",
      "process 5800 peaks takes 12.9 s\n",
      "process 5850 peaks takes 13.0 s\n",
      "process 5900 peaks takes 13.2 s\n",
      "process 5950 peaks takes 13.3 s\n",
      "\n",
      "train\n",
      "5401 108\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.3 s\n",
      "process 100 peaks takes 0.4 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.6 s\n",
      "process 250 peaks takes 0.7 s\n",
      "process 300 peaks takes 0.8 s\n",
      "process 350 peaks takes 0.9 s\n",
      "process 400 peaks takes 0.9 s\n",
      "process 450 peaks takes 1.0 s\n",
      "process 500 peaks takes 1.1 s\n",
      "process 550 peaks takes 1.2 s\n",
      "process 600 peaks takes 1.3 s\n",
      "process 650 peaks takes 1.4 s\n",
      "process 700 peaks takes 1.5 s\n",
      "process 750 peaks takes 1.6 s\n",
      "process 800 peaks takes 1.7 s\n",
      "process 850 peaks takes 1.8 s\n",
      "process 900 peaks takes 1.9 s\n",
      "process 950 peaks takes 2.0 s\n",
      "process 1000 peaks takes 2.1 s\n",
      "process 1050 peaks takes 2.3 s\n",
      "process 1100 peaks takes 2.6 s\n",
      "process 1150 peaks takes 3.1 s\n",
      "process 1200 peaks takes 3.2 s\n",
      "process 1250 peaks takes 3.4 s\n",
      "process 1300 peaks takes 3.5 s\n",
      "process 1350 peaks takes 3.6 s\n",
      "process 1400 peaks takes 3.7 s\n",
      "process 1450 peaks takes 3.8 s\n",
      "process 1500 peaks takes 3.9 s\n",
      "process 1550 peaks takes 4.0 s\n",
      "process 1600 peaks takes 4.1 s\n",
      "process 1650 peaks takes 4.2 s\n",
      "process 1700 peaks takes 4.3 s\n",
      "process 1750 peaks takes 4.5 s\n",
      "process 1800 peaks takes 4.8 s\n",
      "process 1850 peaks takes 5.2 s\n",
      "process 1900 peaks takes 5.4 s\n",
      "process 1950 peaks takes 5.4 s\n",
      "process 2000 peaks takes 5.5 s\n",
      "process 2050 peaks takes 5.6 s\n",
      "process 2100 peaks takes 5.7 s\n",
      "process 2150 peaks takes 5.8 s\n",
      "process 2200 peaks takes 6.0 s\n",
      "process 2250 peaks takes 6.0 s\n",
      "process 2300 peaks takes 6.1 s\n",
      "process 2350 peaks takes 6.2 s\n",
      "process 2400 peaks takes 6.3 s\n",
      "process 2450 peaks takes 6.4 s\n",
      "process 2500 peaks takes 6.5 s\n",
      "process 2550 peaks takes 6.6 s\n",
      "process 2600 peaks takes 6.8 s\n",
      "process 2650 peaks takes 6.9 s\n",
      "process 2700 peaks takes 7.0 s\n",
      "process 2750 peaks takes 7.1 s\n",
      "process 2800 peaks takes 7.2 s\n",
      "process 2850 peaks takes 7.3 s\n",
      "process 2900 peaks takes 7.5 s\n",
      "process 2950 peaks takes 7.6 s\n",
      "process 3000 peaks takes 7.8 s\n",
      "process 3050 peaks takes 7.9 s\n",
      "process 3100 peaks takes 8.1 s\n",
      "process 3150 peaks takes 8.2 s\n",
      "process 3200 peaks takes 8.3 s\n",
      "process 3250 peaks takes 8.4 s\n",
      "process 3300 peaks takes 8.5 s\n",
      "process 3350 peaks takes 8.6 s\n",
      "process 3400 peaks takes 8.7 s\n",
      "process 3450 peaks takes 8.8 s\n",
      "process 3500 peaks takes 8.9 s\n",
      "process 3550 peaks takes 9.0 s\n",
      "process 3600 peaks takes 9.1 s\n",
      "process 3650 peaks takes 9.1 s\n",
      "process 3700 peaks takes 9.2 s\n",
      "process 3750 peaks takes 9.3 s\n",
      "process 3800 peaks takes 9.5 s\n",
      "process 3850 peaks takes 9.6 s\n",
      "process 3900 peaks takes 9.7 s\n",
      "process 3950 peaks takes 9.8 s\n",
      "process 4000 peaks takes 9.9 s\n",
      "process 4050 peaks takes 10.0 s\n",
      "process 4100 peaks takes 10.1 s\n",
      "process 4150 peaks takes 10.2 s\n",
      "process 4200 peaks takes 10.3 s\n",
      "process 4250 peaks takes 10.5 s\n",
      "process 4300 peaks takes 10.6 s\n",
      "process 4350 peaks takes 10.7 s\n",
      "process 4400 peaks takes 11.0 s\n",
      "process 4450 peaks takes 11.1 s\n",
      "process 4500 peaks takes 11.1 s\n",
      "process 4550 peaks takes 11.2 s\n",
      "process 4600 peaks takes 11.3 s\n",
      "process 4650 peaks takes 11.5 s\n",
      "process 4700 peaks takes 11.7 s\n",
      "process 4750 peaks takes 11.8 s\n",
      "process 4800 peaks takes 11.9 s\n",
      "process 4850 peaks takes 12.0 s\n",
      "process 4900 peaks takes 12.1 s\n",
      "process 4950 peaks takes 12.2 s\n",
      "process 5000 peaks takes 12.3 s\n",
      "process 5050 peaks takes 12.5 s\n",
      "process 5100 peaks takes 12.6 s\n",
      "process 5150 peaks takes 12.7 s\n",
      "process 5200 peaks takes 12.9 s\n",
      "process 5250 peaks takes 13.0 s\n",
      "process 5300 peaks takes 13.2 s\n",
      "process 5350 peaks takes 13.3 s\n",
      "\n",
      "test\n",
      "300 6\n",
      "process 0 peaks takes 0.2 s\n",
      "process 50 peaks takes 0.3 s\n",
      "process 100 peaks takes 0.4 s\n",
      "process 150 peaks takes 0.4 s\n",
      "process 200 peaks takes 0.5 s\n",
      "process 250 peaks takes 0.6 s\n",
      "\n",
      "val\n",
      "299 5\n",
      "process 0 peaks takes 0.1 s\n",
      "process 50 peaks takes 0.2 s\n",
      "process 100 peaks takes 0.3 s\n",
      "process 150 peaks takes 0.5 s\n",
      "process 200 peaks takes 0.6 s\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs2000 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e10/bce\n",
      "about to train...\n",
      "2024-05-13 08:14:49.808956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 08:14:49.974121: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 08:14:49.978964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:49.979012: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 08:14:50.983444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:50.983637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:50.983685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "cpu memory used: 0.5GB.\n",
      "2024-05-13 08:14:54.350002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-13 08:14:54.350376: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.350530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.350642: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.350763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.350883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.351003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.351115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.351223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:14:54.351269: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-13 08:14:54.351757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2000)      66000       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2000)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2000)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "      5/Unknown - 22s 2s/step - loss: 0.7034 - auc: 0.5206 - auc_1: 0.0695^C\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs2000_e10/bce/running_time.pkl\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "pancreatic_endocrinogenesis random /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "in /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000\n",
      "out False /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e10/poisson\n",
      "mm10\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000/train_seqs.h5\n",
      "preparing data using path....\n",
      "/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad\n",
      "(5000, 15000)\n",
      "/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/pancreas_multiome_2022_processed_atac_obs5000_var15000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/mm10/genome/mm10.fa --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000 --batch 50\n",
      "2024-05-13 08:15:24.309552: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 08:15:24.527238: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 08:15:24.532683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:15:24.532756: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 08:15:25.502412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:15:25.502536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:15:25.502566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[13501, 750, 749]\n",
      "15000 300\n",
      "process 0 peaks takes 0.4 s\n",
      "process 50 peaks takes 1.1 s\n",
      "process 100 peaks takes 1.3 s\n",
      "process 150 peaks takes 1.4 s\n",
      "process 200 peaks takes 1.5 s\n",
      "process 250 peaks takes 1.6 s\n",
      "process 300 peaks takes 1.7 s\n",
      "process 350 peaks takes 1.8 s\n",
      "process 400 peaks takes 1.8 s\n",
      "process 450 peaks takes 2.0 s\n",
      "process 500 peaks takes 2.1 s\n",
      "process 550 peaks takes 2.2 s\n",
      "process 600 peaks takes 2.2 s\n",
      "process 650 peaks takes 2.3 s\n",
      "process 700 peaks takes 2.4 s\n",
      "process 750 peaks takes 2.5 s\n",
      "process 800 peaks takes 2.6 s\n",
      "process 850 peaks takes 2.7 s\n",
      "process 900 peaks takes 2.8 s\n",
      "process 950 peaks takes 2.9 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1000 peaks takes 2.9 s\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 167, in make_h5_sparse\n",
      "    dna_array_dense = [dna_1hot_2vec(x) for x in seqs_dna]\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 167, in <listcomp>\n",
      "    dna_array_dense = [dna_1hot_2vec(x) for x in seqs_dna]\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 100, in dna_1hot_2vec\n",
      "    nt = seq[i - seq_start]\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_input/obs5000 --epochs 10 --out_path /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/random/scbasset_output/obs5000_e10/poisson\n",
      "about to train...\n",
      "2024-05-13 08:15:33.003483: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 08:15:33.384757: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 08:15:33.404196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-13 08:15:33.405014: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import anndata\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "overwrite_prepare = False\n",
    "overwrite_train = True\n",
    "query_epochs = [1, 10, 20, 50, 100] #  5, 10, 50, 100]\n",
    "\n",
    "genomes_path = '/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/%s/genome/%s.fa'\n",
    "\n",
    "for k in path_by_dataset:\n",
    "    try:\n",
    "        print(k)\n",
    "        # if not 'noack_2022' in k:\n",
    "        #     continue\n",
    "        for n_epochs in query_epochs:\n",
    "            for ad_path in glob.glob(path_by_dataset[k]):\n",
    "                if 'ALL' in ad_path: #  and not '_obs500_' in ad_path: #  or not '/random/' in ad_path:\n",
    "                    continue\n",
    "                print(os.path.exists(ad_path), ad_path)\n",
    "                # print('\\nnext path')\n",
    "                print(k, ad_path)\n",
    "                n_cells = ad_path.split('_')[-2]\n",
    "                sampling_method = ad_path.split('/')[-2]\n",
    "\n",
    "                print(k, sampling_method, ad_path)\n",
    "\n",
    "                species = 'hg38' if (k != 'noack_2022' and k != 'pancreatic_endocrinogenesis') else 'mm10'\n",
    "\n",
    "                filename = os.path.basename(ad_path)\n",
    "                input_dir = os.path.join(ad_path.replace(filename, 'scbasset_input'), n_cells)\n",
    "\n",
    "\n",
    "                for use_poisson in [1, 0]:\n",
    "                    out_dir = os.path.join(ad_path.replace(filename,\n",
    "                                                        'scbasset_output'),\n",
    "                                                        n_cells + '_e%i' % n_epochs, 'poisson' if use_poisson else 'bce')\n",
    "                    \n",
    "                    print('in', input_dir)\n",
    "                    print('out', os.path.exists(out_dir), out_dir)\n",
    "                    # assert False\n",
    "\n",
    "                    if not os.path.exists(input_dir):\n",
    "                        os.makedirs(input_dir)\n",
    "                    if not os.path.exists(out_dir):\n",
    "                        os.makedirs(out_dir)\n",
    "                    \n",
    "                    print(species)\n",
    "                    train_path = os.path.join(input_dir, 'ad.h5ad')\n",
    "                    train_seqs_path = os.path.join(input_dir, 'train_seqs.h5')\n",
    "\n",
    "                    print(os.path.exists(train_path), train_path)\n",
    "                    print(os.path.exists(train_seqs_path), train_seqs_path)\n",
    "                    # assert False\n",
    "\n",
    "                    outpath_time = os.path.join(out_dir, 'running_time.pkl')\n",
    "\n",
    "                    if not os.path.exists(train_path) or not os.path.exists(train_seqs_path) or not os.path.exists(outpath_time) or overwrite_prepare:\n",
    "                        print('preparing data using path....')\n",
    "                        print(ad_path)\n",
    "                        adata = anndata.read_h5ad(ad_path)\n",
    "                        print(adata.shape)\n",
    "\n",
    "                        # assert False\n",
    "                        adata.var['chr'] = np.where(adata.var_names.str.contains(':'), adata.var_names.str.split(':').str[0], adata.var_names.str.split('-').str[0])\n",
    "                        adata.var['chr'] = np.where(~adata.var['chr'].str.contains('chr'), 'chr', '') + adata.var['chr']\n",
    "                        adata.var['start'] = adata.var_names.str.split('-').str[1]\n",
    "                        adata.var['end'] = np.where(~adata.var_names.str.contains(':'), adata.var_names.str.split('-').str[2], adata.var_names.str.split('-').str[1])\n",
    "                        adata.write(ad_path, compression='lzf')\n",
    "                        genome_fasta = genomes_path % (species, species)\n",
    "                        os.path.exists(genome_fasta)\n",
    "                        print(genome_fasta)\n",
    "                        # preprocess fasta\n",
    "                        print('')\n",
    "                        !echo $pythonbin scbasset_preprocess.py --ad_file $ad_path --input_fasta $genome_fasta --out_path $input_dir --batch 50\n",
    "                        !$pythonbin scbasset_preprocess.py --ad_file $ad_path --input_fasta $genome_fasta --out_path $input_dir --batch 50\n",
    "                        print('')\n",
    "                    else:\n",
    "                        print('skip prepare (already done...)')\n",
    "                    \n",
    "                    best_model_path = os.path.join(out_dir, 'best_model.h5')\n",
    "                    if not os.path.exists(best_model_path) or overwrite_train:\n",
    "                        print('')\n",
    "\n",
    "                        !echo $pythonbin scbasset_train.py --input_folder $input_dir --epochs $n_epochs --out_path $out_dir\n",
    "                        print('about to train...')\n",
    "\n",
    "                        t1 = datetime.datetime.now()\n",
    "                        # assert False\n",
    "                        !$pythonbin scbasset_train.py --input_folder $input_dir --epochs $n_epochs --out_path $out_dir --use_poisson $use_poisson\n",
    "                        print('')\n",
    "                        t2 = datetime.datetime.now()\n",
    "                        time_diff = (t2 - t1)\n",
    "\n",
    "                        pickle.dump(outpath_time, open(outpath_time, 'wb'))\n",
    "                        print(os.path.exists(outpath_time), outpath_time)\n",
    "                        # assert False\n",
    "                    else:\n",
    "                        print('skip train (already done...)')\n",
    "                    print('')\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbasset",
   "language": "python",
   "name": "scbasset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
