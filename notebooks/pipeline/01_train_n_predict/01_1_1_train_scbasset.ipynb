{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List datasets that will be used for training with scBasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe anndata and others required\n",
    "# !pip install anndata h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "h5py.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anndata\n",
    "anndata.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scbasset\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "d = '/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/theislab/mubind-pipeline/notebooks/pipeline/01_train_n_predict'\n",
    "os.chdir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets used in the core benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organoids': '/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad',\n",
       " 'gbm': '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad',\n",
       " 'noack_2022': '/mnt/f/workspace/theislab/mubind/data/noack_2022/*/merged_scATAC_integrated_cicero_faye_chong_obs*_var*.h5ad',\n",
       " 'pancreatic_endocrinogenesis': '/mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/*/pancreas_multiome_2022_processed_atac_obs*_var*.h5ad',\n",
       " 'pbmc': '/mnt/f/workspace/theislab/mubind/data/pbmc/*/processed_laura_2023_obs*_var*.h5ad'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_by_dataset = utils.get_datasets()\n",
    "path_by_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scbasset/bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run python using the scbasset environment. If not found, please set up manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythonbin = '/home/ilibarra/.conda/envs/scbasset/bin/python' # ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = anndata.read_h5ad(ad_path)\n",
    "# print(adata.shape)\n",
    "# adata.var['chr'] = adata.var_names.str.split('-').str[0]\n",
    "# adata.var['chr'] = np.where(~adata.var['chr'].str.contains('chr'), 'chr', '') + adata.var['chr']\n",
    "# adata.var['start'] = adata.var_names.str.split('-').str[1]\n",
    "# adata.var['end'] = adata.var_names.str.split('-').str[2]\n",
    "# adata.write(ad_path, compression='lzf')\n",
    "# genome_fasta = '/mnt/c/Users/ignacio.ibarra/Dropbox/annotations/%s/genome/%s.fa' % (species, species)\n",
    "# os.path.exists(genome_fasta)\n",
    "# print(genome_fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/*/merged_scATAC_integrated_cicero_faye_chong_obs*_var*.h5ad\n",
      "pancreatic_endocrinogenesis /mnt/f/workspace/theislab/mubind/data/pancreatic_endocrinogenesis/*/pancreas_multiome_2022_processed_atac_obs*_var*.h5ad\n",
      "pbmc /mnt/f/workspace/theislab/mubind/data/pbmc/*/processed_laura_2023_obs*_var*.h5ad\n"
     ]
    }
   ],
   "source": [
    "for k in path_by_dataset:\n",
    "    print(k, path_by_dataset[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_paths = [[k, ad_path] for k in path_by_dataset for ad_path in glob.glob(path_by_dataset[k])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>path</th>\n",
       "      <th>n_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>organoids</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/organoid...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>noack_2022</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/noack_20...</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pancreatic_endocrinogenesis</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pancreat...</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/ran...</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pbmc</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/pbmc/epi...</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbm</td>\n",
       "      <td>/mnt/f/workspace/theislab/mubind/data/gbm_mult...</td>\n",
       "      <td>compressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dataset  \\\n",
       "19  pancreatic_endocrinogenesis   \n",
       "28  pancreatic_endocrinogenesis   \n",
       "37                         pbmc   \n",
       "44                         pbmc   \n",
       "6                    noack_2022   \n",
       "11                   noack_2022   \n",
       "17  pancreatic_endocrinogenesis   \n",
       "26  pancreatic_endocrinogenesis   \n",
       "35                         pbmc   \n",
       "39                         pbmc   \n",
       "5                    noack_2022   \n",
       "10                   noack_2022   \n",
       "16  pancreatic_endocrinogenesis   \n",
       "25  pancreatic_endocrinogenesis   \n",
       "34                         pbmc   \n",
       "42                         pbmc   \n",
       "20  pancreatic_endocrinogenesis   \n",
       "29  pancreatic_endocrinogenesis   \n",
       "3                    noack_2022   \n",
       "8                    noack_2022   \n",
       "0                     organoids   \n",
       "14  pancreatic_endocrinogenesis   \n",
       "23  pancreatic_endocrinogenesis   \n",
       "32                         pbmc   \n",
       "40                         pbmc   \n",
       "21  pancreatic_endocrinogenesis   \n",
       "30  pancreatic_endocrinogenesis   \n",
       "2                    noack_2022   \n",
       "13  pancreatic_endocrinogenesis   \n",
       "22  pancreatic_endocrinogenesis   \n",
       "31                         pbmc   \n",
       "38                         pbmc   \n",
       "4                    noack_2022   \n",
       "9                    noack_2022   \n",
       "15  pancreatic_endocrinogenesis   \n",
       "24  pancreatic_endocrinogenesis   \n",
       "33                         pbmc   \n",
       "41                         pbmc   \n",
       "7                    noack_2022   \n",
       "12                   noack_2022   \n",
       "18  pancreatic_endocrinogenesis   \n",
       "27  pancreatic_endocrinogenesis   \n",
       "36                         pbmc   \n",
       "43                         pbmc   \n",
       "1                           gbm   \n",
       "\n",
       "                                                 path     n_cells  \n",
       "19  /mnt/f/workspace/theislab/mubind/data/pancreat...         100  \n",
       "28  /mnt/f/workspace/theislab/mubind/data/pancreat...         100  \n",
       "37  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...         100  \n",
       "44  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...         100  \n",
       "6   /mnt/f/workspace/theislab/mubind/data/noack_20...        1000  \n",
       "11  /mnt/f/workspace/theislab/mubind/data/noack_20...        1000  \n",
       "17  /mnt/f/workspace/theislab/mubind/data/pancreat...        1000  \n",
       "26  /mnt/f/workspace/theislab/mubind/data/pancreat...        1000  \n",
       "35  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...        1000  \n",
       "39  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...        1000  \n",
       "5   /mnt/f/workspace/theislab/mubind/data/noack_20...       10000  \n",
       "10  /mnt/f/workspace/theislab/mubind/data/noack_20...       10000  \n",
       "16  /mnt/f/workspace/theislab/mubind/data/pancreat...       10000  \n",
       "25  /mnt/f/workspace/theislab/mubind/data/pancreat...       10000  \n",
       "34  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...       10000  \n",
       "42  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...       10000  \n",
       "20  /mnt/f/workspace/theislab/mubind/data/pancreat...         200  \n",
       "29  /mnt/f/workspace/theislab/mubind/data/pancreat...         200  \n",
       "3   /mnt/f/workspace/theislab/mubind/data/noack_20...        2000  \n",
       "8   /mnt/f/workspace/theislab/mubind/data/noack_20...        2000  \n",
       "0   /mnt/f/workspace/theislab/mubind/data/organoid...        2000  \n",
       "14  /mnt/f/workspace/theislab/mubind/data/pancreat...        2000  \n",
       "23  /mnt/f/workspace/theislab/mubind/data/pancreat...        2000  \n",
       "32  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...        2000  \n",
       "40  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...        2000  \n",
       "21  /mnt/f/workspace/theislab/mubind/data/pancreat...         300  \n",
       "30  /mnt/f/workspace/theislab/mubind/data/pancreat...         300  \n",
       "2   /mnt/f/workspace/theislab/mubind/data/noack_20...         500  \n",
       "13  /mnt/f/workspace/theislab/mubind/data/pancreat...         500  \n",
       "22  /mnt/f/workspace/theislab/mubind/data/pancreat...         500  \n",
       "31  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...         500  \n",
       "38  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...         500  \n",
       "4   /mnt/f/workspace/theislab/mubind/data/noack_20...        5000  \n",
       "9   /mnt/f/workspace/theislab/mubind/data/noack_20...        5000  \n",
       "15  /mnt/f/workspace/theislab/mubind/data/pancreat...        5000  \n",
       "24  /mnt/f/workspace/theislab/mubind/data/pancreat...        5000  \n",
       "33  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...        5000  \n",
       "41  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...        5000  \n",
       "7   /mnt/f/workspace/theislab/mubind/data/noack_20...         ALL  \n",
       "12  /mnt/f/workspace/theislab/mubind/data/noack_20...         ALL  \n",
       "18  /mnt/f/workspace/theislab/mubind/data/pancreat...         ALL  \n",
       "27  /mnt/f/workspace/theislab/mubind/data/pancreat...         ALL  \n",
       "36  /mnt/f/workspace/theislab/mubind/data/pbmc/ran...         ALL  \n",
       "43  /mnt/f/workspace/theislab/mubind/data/pbmc/epi...         ALL  \n",
       "1   /mnt/f/workspace/theislab/mubind/data/gbm_mult...  compressed  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import anndata\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "overwrite_prepare = False\n",
    "overwrite_train = False\n",
    "query_epochs = [50,] #  10, 20] # 50] #  100] #  ,50, 100] #   10, 20, 50, 100] #  5, 10, 50, 100]\n",
    "\n",
    "genomes_path = '/mnt/c/Users/IgnacioIbarra/Dropbox/annotations/%s/genome/%s.fa'\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(ad_paths, columns=['dataset', 'path'])\n",
    "obs = [f.split('_')[-2] for f in list(df['path'].str.split('/').str[-1])]\n",
    "obs = [o.replace('obs', '') for o in obs]\n",
    "df['n_cells'] = obs\n",
    "df.sort_values(['n_cells', 'dataset'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# custom query (500 cells)\n",
    "sel_df = df # df[df['n_cells'] == '500']\n",
    "sel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organoids'\n",
      " '/mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad'\n",
      " '2000']\n",
      "here...\n",
      "organoids /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/RNA_ATAC_metacells_sce_peaks_obs2000_var4000.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "here...\n",
      "organoids False\n",
      "skip prepare (already done...)\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/poisson/best_model.h5\n",
      "error...\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_input/obs2000/train_seqs.h5\n",
      "here...\n",
      "organoids False\n",
      "skip prepare (already done...)\n",
      "True /mnt/f/workspace/theislab/mubind/data/organoids_treutlein_dataset/scbasset_output/obs2000_e50/bce/best_model.h5\n",
      "error...\n",
      "['gbm'\n",
      " '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad'\n",
      " 'compressed']\n",
      "here...\n",
      "gbm /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "here...\n",
      "gbm True\n",
      "(1000, 1500)\n",
      "parsing...\n",
      "preprocess fasta\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 5\n",
      "2024-06-04 00:55:01.672906: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:01.672975: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[1351, 75, 74]\n",
      "1500 300\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 32, in make_bed_seqs_from_df\n",
      "    end = int(input_bed.iloc[i,2])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/poisson/best_model.h5\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/poisson\n",
      "about to train...\n",
      "2024-06-04 00:55:21.039252: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:21.039589: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-06-04 00:55:33.539075: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 00:55:33.542373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-04 00:55:33.636632: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-04 00:55:33.636770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA T1200 Laptop GPU computeCapability: 7.5\n",
      "coreClock: 1.425GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2024-06-04 00:55:33.636992: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:33.637133: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:33.637272: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:33.641893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-04 00:55:33.642784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-04 00:55:33.647149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-04 00:55:33.647494: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:33.647651: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:33.647716: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-04 00:55:33.648296: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 00:55:33.653455: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 00:55:33.653549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-04 00:55:33.653603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1344, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_reverse_complement ( ((None, 1344, 4), () 0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_shift (StochasticShi (None, 1344, 4)      0           stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "gelu (GELU)                     (None, 1344, 4)      0           stochastic_shift[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1344, 288)    19584       gelu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1344, 288)    1152        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 448, 288)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "gelu_1 (GELU)                   (None, 448, 288)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 448, 288)     414720      gelu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 448, 288)     1152        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_2 (GELU)                   (None, 224, 288)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 224, 323)     465120      gelu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 224, 323)     1292        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_3 (GELU)                   (None, 112, 323)     0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 112, 363)     586245      gelu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 363)     1452        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_4 (GELU)                   (None, 56, 363)      0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 56, 407)      738705      gelu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 407)      1628        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_5 (GELU)                   (None, 28, 407)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 28, 456)      927960      gelu_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 456)      1824        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_6 (GELU)                   (None, 14, 456)      0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 14, 512)      1167360     gelu_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 14, 512)      2048        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_7 (GELU)                   (None, 7, 512)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 7, 256)       131072      gelu_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 256)       1024        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gelu_8 (GELU)                   (None, 7, 256)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1792)      0           gelu_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 32)        57344       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 32)        128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 32)        0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_9 (GELU)                   (None, 1, 32)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1000)      33000       gelu_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "switch_reverse (SwitchReverse)  (None, 1, 1000)      0           dense_1[0][0]                    \n",
      "                                                                 stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1000)         0           switch_reverse[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "2024-06-04 00:55:37.215145: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2024-06-04 00:55:37.215254: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2024-06-04 00:55:37.215395: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2024-06-04 00:55:37.215836: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:37.217183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so\n",
      "2024-06-04 00:55:37.222217: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2024-06-04 00:55:37.222519: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "Epoch 1/50\n",
      "2024-06-04 00:55:44.301737: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-06-04 00:55:44.325643: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n",
      "2024-06-04 00:55:45.069572: W tensorflow/core/framework/op_kernel.cc:1751] Unknown: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 888, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError:  FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_5849]\n",
      "\n",
      "Function call stack:\n",
      "train_function\n",
      "\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/poisson/running_time.pkl\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/ad.h5ad\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5\n",
      "here...\n",
      "gbm True\n",
      "(1000, 1500)\n",
      "parsing...\n",
      "preprocess fasta\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_preprocess.py --ad_file /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad --input_fasta /mnt/c/Users/IgnacioIbarra/Dropbox/annotations/hg38/genome/hg38.fa --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --batch 5\n",
      "2024-06-04 00:55:48.628938: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:48.629011: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[1351, 75, 74]\n",
      "1500 300\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_preprocess.py\", line 68, in <module>\n",
      "    main()\n",
      "  File \"scbasset_preprocess.py\", line 58, in main\n",
      "    make_h5_sparse(ad, '%s/all_seqs.h5'%output_path, input_fasta, batch_size=args.batch)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 165, in make_h5_sparse\n",
      "    seq_len=seq_len,\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 32, in make_bed_seqs_from_df\n",
      "    end = int(input_bed.iloc[i,2])\n",
      "ValueError: cannot convert float NaN to integer\n",
      "False /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/bce/best_model.h5\n",
      "/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/23_01_23_atac_compressed_n1000.h5ad\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/bce\n",
      "about to train...\n",
      "2024-06-04 00:55:52.558461: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:52.558529: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-06-04 00:55:56.011651: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 00:55:56.014684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-04 00:55:56.079889: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-04 00:55:56.079981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA T1200 Laptop GPU computeCapability: 7.5\n",
      "coreClock: 1.425GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2024-06-04 00:55:56.080132: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:56.080205: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:56.080281: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:56.081965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-04 00:55:56.082397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-04 00:55:56.083834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-04 00:55:56.084005: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:56.084087: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:56.084117: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-04 00:55:56.084509: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 00:55:56.087750: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 00:55:56.087800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-04 00:55:56.087823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1344, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_reverse_complement ( ((None, 1344, 4), () 0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_shift (StochasticShi (None, 1344, 4)      0           stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "gelu (GELU)                     (None, 1344, 4)      0           stochastic_shift[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1344, 288)    19584       gelu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1344, 288)    1152        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 448, 288)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "gelu_1 (GELU)                   (None, 448, 288)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 448, 288)     414720      gelu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 448, 288)     1152        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_2 (GELU)                   (None, 224, 288)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 224, 323)     465120      gelu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 224, 323)     1292        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_3 (GELU)                   (None, 112, 323)     0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 112, 363)     586245      gelu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 363)     1452        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_4 (GELU)                   (None, 56, 363)      0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 56, 407)      738705      gelu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 407)      1628        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_5 (GELU)                   (None, 28, 407)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 28, 456)      927960      gelu_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 456)      1824        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_6 (GELU)                   (None, 14, 456)      0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 14, 512)      1167360     gelu_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 14, 512)      2048        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_7 (GELU)                   (None, 7, 512)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 7, 256)       131072      gelu_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 256)       1024        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gelu_8 (GELU)                   (None, 7, 256)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1792)      0           gelu_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 32)        57344       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 32)        128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 32)        0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_9 (GELU)                   (None, 1, 32)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1000)      33000       gelu_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "switch_reverse (SwitchReverse)  (None, 1, 1000)      0           dense_1[0][0]                    \n",
      "                                                                 stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1000)         0           switch_reverse[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,552,810\n",
      "Trainable params: 4,546,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "2024-06-04 00:55:56.959471: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2024-06-04 00:55:56.959543: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2024-06-04 00:55:56.959584: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2024-06-04 00:55:56.959846: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:55:56.960569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so\n",
      "2024-06-04 00:55:56.964345: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2024-06-04 00:55:56.964637: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "Epoch 1/50\n",
      "2024-06-04 00:56:03.041172: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-06-04 00:56:03.085461: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n",
      "2024-06-04 00:56:04.536509: W tensorflow/core/framework/op_kernel.cc:1751] Unknown: FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 131, in main\n",
      "    validation_data=val_ds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 888, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.UnknownError:  FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 345, in __call__\n",
      "    with h5py.File(self.file, 'r') as hf:\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_input/compressed/train_seqs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]] [Op:__inference_train_function_5923]\n",
      "\n",
      "Function call stack:\n",
      "train_function\n",
      "\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/gbm_multiome_scdori/scbasset_output/compressed_e50/bce/running_time.pkl\n",
      "['noack_2022'\n",
      " '/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad'\n",
      " '500']\n",
      "here...\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs500_var1500.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/train_seqs.h5\n",
      "here...\n",
      "noack_2022 False\n",
      "skip prepare (already done...)\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e50/poisson/best_model.h5\n",
      "error...\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs500/train_seqs.h5\n",
      "here...\n",
      "noack_2022 False\n",
      "skip prepare (already done...)\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs500_e50/bce/best_model.h5\n",
      "error...\n",
      "['noack_2022'\n",
      " '/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad'\n",
      " '2000']\n",
      "here...\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/train_seqs.h5\n",
      "here...\n",
      "noack_2022 False\n",
      "skip prepare (already done...)\n",
      "False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/best_model.h5\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000 --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson\n",
      "about to train...\n",
      "2024-06-04 00:56:11.523936: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:11.524060: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-06-04 00:56:29.358405: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 00:56:29.361274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-04 00:56:29.454593: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-04 00:56:29.454727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA T1200 Laptop GPU computeCapability: 7.5\n",
      "coreClock: 1.425GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2024-06-04 00:56:29.455001: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:29.455189: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:29.455428: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:29.459141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-04 00:56:29.460128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-04 00:56:29.463445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-04 00:56:29.463848: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:29.464096: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:29.464159: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-04 00:56:29.464771: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 00:56:29.468978: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 00:56:29.469097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-04 00:56:29.469151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1344, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_reverse_complement ( ((None, 1344, 4), () 0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_shift (StochasticShi (None, 1344, 4)      0           stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "gelu (GELU)                     (None, 1344, 4)      0           stochastic_shift[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1344, 288)    19584       gelu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1344, 288)    1152        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 448, 288)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "gelu_1 (GELU)                   (None, 448, 288)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 448, 288)     414720      gelu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 448, 288)     1152        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_2 (GELU)                   (None, 224, 288)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 224, 323)     465120      gelu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 224, 323)     1292        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_3 (GELU)                   (None, 112, 323)     0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 112, 363)     586245      gelu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 363)     1452        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_4 (GELU)                   (None, 56, 363)      0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 56, 407)      738705      gelu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 407)      1628        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_5 (GELU)                   (None, 28, 407)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 28, 456)      927960      gelu_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 456)      1824        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_6 (GELU)                   (None, 14, 456)      0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 14, 512)      1167360     gelu_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 14, 512)      2048        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_7 (GELU)                   (None, 7, 512)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 7, 256)       131072      gelu_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 256)       1024        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gelu_8 (GELU)                   (None, 7, 256)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1792)      0           gelu_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 32)        57344       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 32)        128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 32)        0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "gelu_9 (GELU)                   (None, 1, 32)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 2000)      66000       gelu_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "switch_reverse (SwitchReverse)  (None, 1, 2000)      0           dense_1[0][0]                    \n",
      "                                                                 stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2000)         0           switch_reverse[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,585,810\n",
      "Trainable params: 4,579,960\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Activating a Poisson Loss...\n",
      "2024-06-04 00:56:33.539822: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2024-06-04 00:56:33.539907: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2024-06-04 00:56:33.539994: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2024-06-04 00:56:33.540374: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 00:56:33.541457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so\n",
      "2024-06-04 00:56:33.548405: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2024-06-04 00:56:33.548805: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "Epoch 1/50\n",
      "2024-06-04 00:56:45.779426: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-06-04 00:56:45.841627: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n",
      "      1/Unknown - 21s 21s/step - loss: 0.5575 - auc: 0.4950 - auc_1: 0.08042024-06-04 00:56:54.767814: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2024-06-04 00:56:54.767887: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "      2/Unknown - 29s 8s/step - loss: 0.5525 - auc: 0.4972 - auc_1: 0.0764 2024-06-04 00:57:02.634758: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2024-06-04 00:57:02.635179: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "2024-06-04 00:57:02.748362: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2024-06-04 00:57:02.758583: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2024-06-04 00:57:03.229402: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02\n",
      "2024-06-04 00:57:03.450841: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.trace.json.gz\n",
      "2024-06-04 00:57:03.504722: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02\n",
      "2024-06-04 00:57:03.520758: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.memory_profile.json.gz\n",
      "2024-06-04 00:57:03.605000: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02Dumped tool data for xplane.pb to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/train/plugins/profile/2024_06_04_00_57_02/NB085081.kernel_stats.pb\n",
      "\n",
      "43/43 [==============================] - 462s 11s/step - loss: 0.4057 - auc: 0.5547 - auc_1: 0.0807 - val_loss: 0.3041 - val_auc: 0.6521 - val_auc_1: 0.1428\n",
      "Epoch 2/50\n",
      " 9/43 [=====>........................] - ETA: 5:22 - loss: 0.2458 - auc: 0.6335 - auc_1: 0.1792^C\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/poisson/running_time.pkl\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000/train_seqs.h5\n",
      "here...\n",
      "noack_2022 False\n",
      "skip prepare (already done...)\n",
      "False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/bce/best_model.h5\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs2000_var6000.h5ad\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs2000 --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/bce\n",
      "about to train...\n",
      "2024-06-04 01:06:01.978561: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 01:06:01.978657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "cpu memory used: 0.4GB.\n",
      "2024-06-04 01:06:10.034124: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 01:06:10.037452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-04 01:06:10.159797: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-04 01:06:10.160031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA T1200 Laptop GPU computeCapability: 7.5\n",
      "coreClock: 1.425GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2024-06-04 01:06:10.160590: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-04 01:06:10.160947: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 01:06:10.161235: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 01:06:10.166530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-04 01:06:10.167516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-04 01:06:10.171506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-04 01:06:10.171992: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-06-04 01:06:10.172265: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-06-04 01:06:10.172356: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-04 01:06:10.173249: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 01:06:10.184293: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-04 01:06:10.184505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-04 01:06:10.184617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"scbasset_train.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"scbasset_train.py\", line 96, in main\n",
      "    model = make_model(bottleneck_size, n_cells)\n",
      "  File \"/mnt/c/Users/IgnacioIbarra/Dropbox/workspace/scBasset/scbasset/utils.py\", line 238, in make_model\n",
      "    current = tf.keras.layers.Flatten()(current)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\", line 656, in __init__\n",
      "    super(Flatten, self).__init__(**kwargs)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 408, in __init__\n",
      "    self._init_call_fn_args()\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 2959, in _init_call_fn_args\n",
      "    self._call_accepts_kwargs)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/site-packages/tensorflow/python/keras/utils/layer_utils.py\", line 465, in wrapped\n",
      "    cache[item] = output = f(item)\n",
      "  File \"/home/ilibarra/.conda/envs/scbasset/lib/python3.7/weakref.py\", line 409, in __setitem__\n",
      "    self.data[ref(key, self._remove)] = value\n",
      "KeyboardInterrupt\n",
      "\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs2000_e50/bce/running_time.pkl\n",
      "['noack_2022'\n",
      " '/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad'\n",
      " '5000']\n",
      "here...\n",
      "noack_2022 /mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000/ad.h5ad\n",
      "True /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000/train_seqs.h5\n",
      "here...\n",
      "noack_2022 False\n",
      "skip prepare (already done...)\n",
      "False /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e50/poisson/best_model.h5\n",
      "/mnt/f/workspace/theislab/mubind/data/noack_2022/random/merged_scATAC_integrated_cicero_faye_chong_obs5000_var15000.h5ad\n",
      "/home/ilibarra/.conda/envs/scbasset/bin/python scbasset_train.py --input_folder /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_input/obs5000 --epochs 50 --out_path /mnt/f/workspace/theislab/mubind/data/noack_2022/random/scbasset_output/obs5000_e50/poisson\n",
      "about to train...\n"
     ]
    }
   ],
   "source": [
    "n_missing = 0\n",
    "for n_epochs in query_epochs:\n",
    "    for ri, r in sel_df.iterrows(): # [sel_df['n_cells'].isin({'100', '200', '300'})].iterrows():\n",
    "        k, ad_path = r['dataset'], r['path']\n",
    "\n",
    "        print(r.values)\n",
    "\n",
    "        # if k != 'pbmc':\n",
    "        #     continue\n",
    "\n",
    "        print('here...')\n",
    "        # try:\n",
    "        # print(k)\n",
    "        # if not 'noack_2022' in k:\n",
    "        #     continue\n",
    "        # if 'ALL' in ad_path: #  and not '_obs500_' in ad_path: #  or not '/random/' in ad_path:\n",
    "        #     continue\n",
    "        # print(os.path.exists(ad_path), ad_path)\n",
    "        # print('\\nnext path')\n",
    "        print(k, ad_path)\n",
    "        n_cells = ad_path.split('_')[-2]\n",
    "        sampling_method = ad_path.split('/')[-2]\n",
    "\n",
    "        # print(k, sampling_method, ad_path)\n",
    "\n",
    "        species = 'hg38' if (k != 'noack_2022' and k != 'pancreatic_endocrinogenesis') else 'mm10'\n",
    "\n",
    "        filename = os.path.basename(ad_path)\n",
    "        input_dir = os.path.join(ad_path.replace(filename, 'scbasset_input'), n_cells)\n",
    "\n",
    "\n",
    "        for use_poisson in [1, 0]:\n",
    "            out_dir = os.path.join(ad_path.replace(filename,\n",
    "                                                'scbasset_output'),\n",
    "                                                n_cells + '_e%i' % n_epochs, 'poisson' if use_poisson else 'bce')\n",
    "            \n",
    "            # print('in', input_dir)\n",
    "            # print('out', os.path.exists(out_dir), out_dir)\n",
    "            # assert False\n",
    "\n",
    "            if not os.path.exists(input_dir):\n",
    "                os.makedirs(input_dir)\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "            \n",
    "            # print(species)\n",
    "            train_path = os.path.join(input_dir, 'ad.h5ad')\n",
    "            train_seqs_path = os.path.join(input_dir, 'train_seqs.h5')\n",
    "\n",
    "            print(os.path.exists(train_path), train_path)\n",
    "            print(os.path.exists(train_seqs_path), train_seqs_path)\n",
    "            # assert False\n",
    "\n",
    "            outpath_time = os.path.join(out_dir, 'running_time.pkl')\n",
    "\n",
    "            time_ok = False\n",
    "            if os.path.exists(outpath_time):\n",
    "                running_time = pickle.load(open(outpath_time, 'rb'))\n",
    "                time_ok = isinstance(running_time, datetime.timedelta)\n",
    "                # print('time ok?', time_ok, running_time)\n",
    "\n",
    "            print('here...')\n",
    "            \n",
    "            print(k, not os.path.exists(train_path) or not os.path.exists(train_seqs_path) or overwrite_prepare)\n",
    "            if not os.path.exists(train_path) or not os.path.exists(train_seqs_path) or overwrite_prepare:\n",
    "                # print('preparing data using path....')\n",
    "                # print(ad_path)\n",
    "                adata = anndata.read_h5ad(ad_path)\n",
    "                # assert False\n",
    "\n",
    "                print(adata.shape)\n",
    "                print('parsing...')\n",
    "\n",
    "                # print(adata.var[['chr', 'start', 'end']])\n",
    "                adata.var['chr'] = np.where(adata.var_names.str.contains(':'), adata.var_names.str.split(':').str[0], adata.var_names.str.split('-').str[0])\n",
    "                adata.var['chr'] = np.where(~adata.var['chr'].str.contains('chr'), 'chr', '') + adata.var['chr']\n",
    "                # adata.var['start'] = np.where(~adata.var_names.str.contains(':'), adata.var_names.str.split('-').str[1], adata.var_names.str.split(':').str[1].str.split('-').str[0])\n",
    "                # adata.var['end'] = np.where(~adata.var_names.str.contains(':'), adata.var_names.str.split('-').str[2], adata.var_names.str.split('-').str[1])\n",
    "\n",
    "                colon_found = adata.var_names.str.contains(':').any()\n",
    "                colon_found\n",
    "                if colon_found:\n",
    "                    adata.var['start'] =   adata.var_names.str.split(':').str[1].str.split('-').str[0]\n",
    "                    adata.var['end'] = adata.var_names.str.split(':').str[1].str.split('-').str[1]\n",
    "                else:\n",
    "                    adata.var['start'] = adata.var_names.str.split('-').str[1]\n",
    "                    adata.var['end'] = adata.var_names.str.split('-').str[2]\n",
    "                    \n",
    "                # remove non-canonical chromosomes\n",
    "\n",
    "                adata = adata[:,~adata.var['chr'].str.contains('chrGL') & ~adata.var['chr'].str.contains('chrK')].copy()\n",
    "                adata.write(ad_path, compression='lzf')\n",
    "                genome_fasta = genomes_path % (species, species)\n",
    "                # os.path.exists(genome_fasta)\n",
    "                # print(genome_fasta)\n",
    "                # preprocess fasta\n",
    "                print('preprocess fasta')\n",
    "\n",
    "                # batch = 5 assures preparing a small batch\n",
    "                !echo $pythonbin scbasset_preprocess.py --ad_file $ad_path --input_fasta $genome_fasta --out_path $input_dir --batch 5\n",
    "                !$pythonbin scbasset_preprocess.py --ad_file $ad_path --input_fasta $genome_fasta --out_path $input_dir --batch 5\n",
    "                # print('')\n",
    "            else:\n",
    "                # continue\n",
    "                print('skip prepare (already done...)')\n",
    "            \n",
    "            best_model_path = os.path.join(out_dir, 'best_model.h5')\n",
    "            print(os.path.exists(best_model_path), best_model_path)\n",
    "            if not os.path.exists(best_model_path) or overwrite_train or not os.path.exists(outpath_time) or not time_ok: \n",
    "                # print('')\n",
    "                print(ad_path)\n",
    "\n",
    "                !echo $pythonbin scbasset_train.py --input_folder $input_dir --epochs $n_epochs --out_path $out_dir\n",
    "                print('about to train...')\n",
    "\n",
    "                t1 = datetime.datetime.now()\n",
    "\n",
    "                n_missing += 1\n",
    "                # continue\n",
    "                # assert False\n",
    "                !$pythonbin scbasset_train.py --input_folder $input_dir --epochs $n_epochs --out_path $out_dir --use_poisson $use_poisson\n",
    "                print('')\n",
    "                t2 = datetime.datetime.now()\n",
    "                time_diff = (t2 - t1)\n",
    "\n",
    "                pickle.dump(time_diff, open(outpath_time, 'wb'))\n",
    "                print(os.path.exists(outpath_time), outpath_time)\n",
    "                # assert False\n",
    "            else:\n",
    "                print('error...')\n",
    "                continue\n",
    "                print('skip train (already done...)')\n",
    "            # print('')\n",
    "        # except Exception:\n",
    "        #     pass\n",
    "\n",
    "    # print('')\n",
    "\n",
    "print('n_missing = %i' % n_missing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbasset_gpu",
   "language": "python",
   "name": "scbasset_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
